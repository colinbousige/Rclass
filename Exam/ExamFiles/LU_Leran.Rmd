---
title : "Reproducible data treatment with R<br>Exam"
author: "NAME Firstname"
date  : "2019/12/03"
output: 
    html_document:
        toc: yes
        toc_float: TRUE
---

```{r}
# DO NOT TOUCH THIS CODE CHUNK
library(ggplot2)
library(tidyverse)
theme_set(theme_bw())
```

-------

# Exercise 1 (4 points)

> Print the 6 first lines of the R-built-in data.frame `trees`

```{r}
trees[1:6,]
```

> Print only the column names

```{r}
colnames(trees)
```

> What is the dimension of `trees`?

```{r}
dim(trees)
```

> Plot the trees height and volume as a function of their girth in two different graphs. Make sure the axis labels are clear

```{r}
ggplot(data = trees) + geom_point(mapping = aes(x = Girth, y = Height))
ggplot(data = trees) + geom_point(mapping = aes(x = Girth, y = Volume))
```

> In each graph, add a red dashed line corresponding to the relevant correlation that you observe (average value, linear correlation...)

```{r}
hfit = lm(Height~Girth, data = trees)
ggplot(data = trees, mapping = aes(x = Girth)) +
  geom_point(mapping = aes(y = Height)) +
  geom_line(mapping = aes(y = predict(hfit)), color = "red", linetype = 2)

vfit = lm(Volume~Girth, data = trees)
ggplot(data = trees, mapping = aes(x = Girth)) +
  geom_point(mapping = aes(y = Volume)) +
  geom_line(mapping = aes(y = predict(vfit)), color = "red", linetype = 2)
```

> Explain your choice and write the corresponding values (average value and standard deviation, or slope, intercept and corresponding errors). Round the values to 2 decimals.

As the girth increases, the height increase slightly, and the linear relation between them is very weak. The slope is 1.05 with standard error 0.32, the intercept is 62.03 with standard error 4.38.

As for the volume, the linear dependency of it on the girth is more obvious.
The slope is 5.07 with standard error 0.25, the intercept is -36.94 with standard error 3.36.

-------

# Exercise 2 (6 points)

> Print the 3 first lines of the R-built-in data.frame `USArrests`. This data set contains statistics about violent crime rates by US state. The numbers are given per 100 000 inhabitants, except for `UrbanPop` which is a percentage.

```{r}
USArrests[1:3,]
```

> What is the average murder rate in the whole country?

```{r}
mean(USArrests$Murder)
```

> What is the state with the highest assault rate?

```{r}
rownames(USArrests)[which.max(USArrests$Assault)]
```

> Create a subset of `USArrests` gathering the data for states with an urban population above (including) 80%.

```{r}
urbanpop80 <- USArrests %>%
  subset(UrbanPop >= 80)
urbanpop80
```

> How many states does that correspond to?

```{r}
nrow(urbanpop80)
```

> Within these states, what is the state with the smallest rape rate?

```{r}
rownames(urbanpop80)[which.min(urbanpop80$Rape)]
```

> Print this subset ordered by decreasing urban population.

```{r}
dUP <- order(urbanpop80$UrbanPop, decreasing = TRUE)
urbanpop80[dUP,]
```

> Print this subset ordered by decreasing urban population and increasing murder rate.

```{r}
iMR <- order(urbanpop80$Murder)
tmp <- urbanpop80[iMR,]
dUP <- order(tmp$UrbanPop, decreasing = TRUE)
tmp[dUP,]
```

> Plot an histogram of the percentage of urban population with a binning of 5%. Add a vertical red line marking the average value. Make sure the x axis shows the [0,100] range.

```{r}

hist(USArrests$UrbanPop, breaks = seq(min(USArrests$UrbanPop), max(USArrests$UrbanPop)+5, 5), xlab = "Urban Population", main = "Histogram of Urban Populations")
tmp <- mean(USArrests$UrbanPop)
abline(v = tmp, col = "red")
```

> Is there a correlation between the percentage of urban population and the various violent crime rates? argument your answer with plots.

```{r}
ggplot(data = USArrests, mapping = aes(x = UrbanPop, y = Murder)) +
  geom_point() + geom_smooth()
ggplot(data = USArrests, mapping = aes(x = UrbanPop, y = Assault)) +
  geom_point() + geom_smooth()
ggplot(data = USArrests, mapping = aes(x = UrbanPop, y = Rape)) +
  geom_point() + geom_smooth()
```

There is no apparent correlations between urban population and any kinds of voilent crime rates.

-------

# Exercise 3 (10 points)

> In high-pressure experiments, the pressure in the Diamond Anvil Cell (DAC) is calibrated through the measure of the Raman shift of a tiny ruby crystal placed in the pressure transmitting medium next to the measured sample.

> Write a function returning the pressure $P$ as a function of the ruby Raman shift position $\omega$ and the excitation laser wavelength $\lambda_l$:
$$P(\omega, \lambda_l) = \frac{A}{B}\left[\left(\frac{\lambda}{\lambda_0}\right)^B-1\right] (GPa)$$
where $A=1876$ and $B=10.71$, $\lambda$ is the the measured wavelength of the ruby $R_1$ line (the most energetic one) and $\lambda_0=694.24$ nm is the zero-pressure value at 298 K[^1]. The relationship between the wavenumber $\nu$ in cm$^{-1}$ and the wavelength $\lambda$ in nm is given by $\nu(\text{cm}^{-1})=\frac{10^7}{\lambda(\text{nm})}$, and the Raman shift $\omega=\Delta\nu=\nu_l-\nu=\frac{10^7}{\lambda_l}-\frac{10^7}{\lambda}$ (cm$^{-1}$).

```{r}
raman <- function(omega, lambda_l) {
  A <- 1876
  B <- 10.71
  lambda0 <- 694.24
  lambda <- 1e7/(1e7/lambda_l - omega)
  P <- A/B*((lambda/lambda0)^B-1)
  return(P)
}
```

> Write a function returning a normalized Lorentzian as a function of its center $x_0$ and its full width at half maximum $\Gamma$:
> $$L(x,x_0,\Gamma)=\frac{\Gamma}{2\pi}\frac{1}{\frac{\Gamma^2}{4}+\left(x-x_0\right)^2}$$

```{r}
normLorentz <- function(x0, gamma) {
  return(function(x) {
    gamma/(2*pi)*1/(gamma^2/4+(x-x0)^2)
    })
}
```

> Store the list of files containing `ruby` in their name in the `Data/` folder into a variable `flist`. Print its length.

```{r}
flist <- list.files("./Data/", pattern = "ruby")
flist
```

> Plot with points the first file in `flist`. Find the position of its maximum and store it in `xmax`. Guess roughly the parameters needed to fit the experimental data by `y0+A1*L(x,x1,FW1)+A2*L(x,x2,FW2)`, and add a blue line on the plot to represent this function.

```{r}
ruby1 <- read.table(paste0("./Data/",flist[1]))
names(ruby1) <- c("wavelength", "intensity")
xmax = ruby1$wavelength
y0 <- 10
A1 <- 1.4e5
L1 <- normLorentz(4375, 10)
A2 <- 3.5e5
L2 = normLorentz(4400, 15)
ggplot(data = ruby1) +
  geom_line(aes(x = wavelength, y = intensity)) +
  geom_line(aes(x = wavelength, y = y0+A1*L1(wavelength)+A2*L2(wavelength)), color = "blue")
```

> Using `nls()`, fit the first spectrum in `flist` by `y0+A1*L(x,x1,FW1)+A2*L(x,x2,FW2)` and using the starting parameters you defined before. Plot the experimental data again and add the fitted spectrum as a red line.

```{r}
L <- function(x, x0, gamma) {
    gamma/(2*pi)*1/(gamma^2/4+(x-x0)^2)
}
fitfun <- function(x, y0, A1, x1, FW1, A2, x2, FW2) {
  y0 + A1*L(x, x1, FW1) + A2*L(x, x2, FW2)
}
lfit <- nls(intensity~fitfun(wavelength, y0, A1, x1, FW1, A2, x2, FW2),
            data = ruby1,
            start = list(y0 = 10,
                         A1 = 1.4e5, x1 = 4375, FW1 = 10,
                         A2 = 3.5e5, x2 = 4400, FW2 = 15))
ggplot(data = ruby1, mapping = aes(x = wavelength)) +
  geom_line(aes(y = intensity)) +
  geom_line(aes(y = predict(lfit)), color = "red")
```

> Based on the above procedure, for each file in `flist` (so, use a `for` loop), fit the Raman spectrum by the sum of two Lorentzian functions, and store the fitting parameters into a data.frame called `ruby_fit` also containing the names of the corresponding files. Attention: the initial guesses for amplitudes and widths can be constant, but the peaks positions should evolve for each spectrum. The difference between the two peaks is always roughly 30 cm$^{-1}$, and the largest peak is always the most energetic one. Check that your fits are correct by printing the experimental data and the fitted result at each iteration (add the name of the file as the plot title).

```{r}
peak1 <- c(4375, 4375, 4410, 4440, 4475)
peak2 <- c(4400, 4425, 4450, 4475, 4525)
y0 <- c()
A1 <- c()
x1 <- c()
FW1 <- c()
A2 <- c()
x2 <- c()
FW2 <- c()
for (i in seq(1,5)) {
  file <- flist[i]
  ruby <- read.table(paste0("./Data/", file))
  names(ruby) <- c("wavelength", "intensity")
  lfit <- nls(intensity~fitfun(wavelength, y0, A1, x1, FW1, A2, x2, FW2),
            data = ruby,
            start = list(y0 = 10,
                         A1 = 1.4e5, x1 = peak1[i], FW1 = 10,
                         A2 = 3.5e5, x2 = peak2[i], FW2 = 15))
  ggplot(data = ruby, mapping = aes(x = wavelength)) +
    geom_line(aes(y = intensity)) +
    geom_line(aes(y = predict(lfit)), color = "red")
  y0 <- c(y0, coef(lfit)[[1]])
  A1 <- c(A1, coef(lfit)[[2]])
  x1 <- c(x1, coef(lfit)[[3]])
  FW1 <- c(FW1, coef(lfit)[[4]])
  A2 <- c(A2, coef(lfit)[[5]])
  x2 <- c(x2, coef(lfit)[[6]])
  FW2 <- c(FW2, coef(lfit)[[7]])
}
ruby_fit <- data.frame(file = flist, y0, A1, x1, FW1, A2, x2, FW2)
```

> Add a column in `ruby_fit` corresponding to the estimated pressure rounded to 1 decimal. The excitation wavelength in this experiment was 532 nm. Print the resulting `ruby_fit` table using `knitr::kable(ruby_fit)`

```{r}
ruby_fit$P = raman(1e7/ruby_fit$x1-1e7/ruby_fit$x2,532)
knitr::kable(ruby_fit)
```

> Store all file names containing "RBM" into a variable `fRBM`. Load all the corresponding spectra into a single `data.frame` called `spec` with 3 columns: Raman shift $\omega$, Intensity, Pressure. Of course, the indexes in the file names between the ruby and RBM files match. In the Intensity column, store the intensity normalized to [0,1].

```{r}
fRBM <- list.files("./Data/", pattern = "RBM")
spec <- data.frame()
for (file in fRBM) {
    
}
```

> Using `ggplot2`, plot with points the stacked normalized RBM band spectra vertically shifted by P, with a color for each spectrum corresponding to the pressure. Make the plot interactive.

```{r}

```

[^1]: [Chijioke _et al._, ‘The ruby pressure standard to 150 GPa’. _J Appl Phys_ __98__, 114905 (2005).](http://doi.org/10.1063/1.2135877)
