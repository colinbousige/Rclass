---
title : "R Exercises - COVID"
author: Hayri OKCU
date  : "`r Sys.Date()`"
output: 
    html_document:
        toc            : true
        toc_float      : true
        toc_depth      : 4
        highlight      : tango
        number_sections: true
---


<style type="text/css">
blockquote {
  background: #E9F9FF;
  border-left: 5px solid #026086;
  margin: 1.5em 10px;
  padding: 0.5em 10px;
  font-size: 1em;
}
</style>


The COVID-19 pandemics is a lot of bad things, but it's also a source of data to play with...

Here we're gonna use the data gathered by the John's Hopkins Hospital and published on [GitHub](https://github.com/CSSEGISandData/COVID-19), for [confirmed cases](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv) and [deaths](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv).

In case the links above die at some point, here is a version of these files as of April 21st, 2020:

- [confirmed cases](Data/time_series_covid19_confirmed_global.csv)
- [deaths](Data/time_series_covid19_deaths_global.csv)

In fact, a [quick lookup](https://www.statsandr.com/blog/top-r-resources-on-covid-19-coronavirus/#r-shiny-apps) on the Internet will now return plenty of versions for this data, with even cleaner (tidy) versions, including country population, etc. There are even R packages to get this.
The point here is to learn how to read a given dataset, clean it and use it, so we'll stay with the JHU dataset.


# Data wrangling

- First, load the `tidyverse` and `lubridate` packages

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
library(tidyverse)
library(lubridate)
```

- Load the raw .csv files from the links above and store them in `confirmed_raw` and `deaths_raw`. You can provide `read_csv()`{.R} with an url. The numbers given in these tables are cumulative numbers of confirmed cases and deaths.

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
urlConfirmed <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
urlDeaths <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"

confirmed_raw <- read_csv("time_series_covid19_confirmed_global.csv")
deaths_raw <- read_csv("time_series_covid19_deaths_global.csv")
```

- Using successive operations with the pipe operator `%>%`{.R} create a function `tidyfy_jhh(df, name)`{.R}, that, given a tibble `df` (_i.e._, the data from JHH we just loaded), will:
    + Rename the columns `Province/State` and `Country/Region` to `state` and `country`
    + Remove the lines from the `Diamond Princess`
    + Remove the columns from `state`, `Lat` and `Long`
    + Make the table tidy by having 3 columns : `country`, `date` and `count`
    + Remove any duplicated lines
    + Using the `mdy()`{.R} function from the `lubridate` package, convert the `date` column to a R Date format
    + Some countries appear several times as their numbers are separated by provinces or states. Summarize the counts per country and per date as the total number of cases per country and per day. 
        + Give this column the name of the type of case we look at (confirmed or deaths, string that id provided in the `name` parameter of the function `tidyfy_jhh(df, name)`{.R}. For this, use the notation `summarize(!!sym(name):= your_result_here)`{.R} to tell R that `name` should be used as a column name)

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
deaths_raw<- tibble(deaths_raw)
confirmed_raw <- tibble(confirmed_raw)
#creating function
tidyfy_fyy <- function(df,name){
 # Rename column names
  colnames(df)[1]="states";colnames(df)[1]
  colnames(df)[2]="country";colnames(df)[2]
  # Find the target row to delete and delete from the table  
  n1 <- which(df[1]=="Diamond Princess")
  n2 <- which(df[2]=="Diamond Princess")
  df <- df[-c(n1,n2),-c(1,3,4)]
  # Make the table tidy
  df <- df %>%
    pivot_longer(cols=-country,
                 names_to="date",
                 values_to="count")
  # delete duplicated lines
  n3 <- which(duplicated(df))
  df <- df[-c(n3),]
  # Change date format
  df <- df %>% mutate(date=mdy(date))
  # Summarizing the count by countries and by date
  df <- df %>%
  group_by(country,date) %>%
  summarise_all(sum)
  df <- df %>%
  summarize(!!sym(name):=date, count)
  df
  }

tidyfy_jhh <- function(df, name) {
    df %>% 
        rename(state   = `Province/State`,
               country = `Country/Region`) %>%
        filter(country != "Diamond Princess") %>%
        select(-c(state, Lat, Long)) %>%
        pivot_longer(cols      = -country,
                     names_to  = "date",
                     values_to = "count") %>% 
        mutate(date = mdy(date)) %>% 
        group_by(country, date) %>% 
        summarize(!!sym(name):=sum(count)) %>% 
        ungroup()
}
```

- Apply this function to the raw tibbles to get tidy `confirmed` and `deaths` tibbles.

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
deaths <- tidyfy_fyy(deaths_raw,"deaths")
confirmed <- tidyfy_fyy(confirmed_raw,"confirmed")
```

> In case you didn't manage to get there, here are the csv files containing:
> 
> - [confirmed](Data/covid_confirmed.csv)
> - [deaths](Data/covid_deaths.csv)

Now, join these three tibbles in `alldata`, and successively:

- Add the columns `newcases` and `newdeaths` containing the number of new cases and deaths every day, as `confirmed` and `deaths` contain cumulative numbers. For this look into the `lag()`{.R} function.
- Filter rows to remove data for which the number of cases is lower than the minimum number of cases in China (for easier comparison). This day will be considered as `Day 1`.
- Add a `day` column containing the day number since `Day 1`.
- Filter rows to have only countries for which we have at least one week of data

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
# Conbining "confirmed" and "deaths" tables
alldata<- cbind(confirmed,deaths)
alldata<-alldata[,-c(4,5)]
colnames(alldata)<- c("country","date","confirmed","deaths")
# Adding "newcases" and "newdeaths" columns
alldata$newcases<-lag(lead(alldata$confirmed,1)-alldata$confirmed)
alldata$newcases[alldata$newcases<0]<-0
alldata$newdeaths<-lag(lead(alldata$deaths,1)-alldata$deaths)
alldata$newdeaths[alldata$newdeaths<0]<- 0
# Defining China's minimum confirmed value
min_china <- alldata %>%
  filter(country == "China")
min_china <- min_china$confirmed[1]
# Removing the rows smaller than China's minimum confirmed value
alldata <- alldata %>%
  filter(confirmed > min_china-1)
# Creating "Day" column
alldata <- alldata %>%
  group_by(country) %>%
  mutate(day = row_number())
#
i <- c(1:nrow(b))
b <- alldata %>%
  group_by(country) %>%
  filter(newcases==0)
  ifelse(sum(b$newcases[i],b$newcases[i+1],b$newcases[i+2])=0,TRUE,FALSE)
  
sum(alldata$newcases)
if(sum(1,2,3)==6,paste("Y"),paste("N"))
a <- sum(1,2,3)
ifelse(a==6,paste("Y"),paste("N"))
a <- sum(b$newcases[i],b$newcases[i+1],b$newcases[i+2])


```

> In case you didn't manage to get there, [here is a csv file](Data/covid_alldata.csv) containing `alldata` so that you can continue with the exercise.


# Plotting

- Using `ggplot2`, plot (P1) **side by side** the number of **confirmed** cases and **deaths** vs time in 5 countries of your choice.
    - Using `ggrepel`, add the country names as annotation
    - Do the plot using linear scale, then a log scale

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=.8}
# Defining Selected Countries
slc_countries <- 
  alldata %>%
  filter(country == "Turkey" |
           country == "China" |
           country == "France" |
           country == "Germany"|
           country == "Russia")%>%
  mutate(should_be_labeled = ifelse(day %in% "200",TRUE, FALSE))
# Installing Libraries
install.packages("ggrepel")
library(ggplot2)         
library(ggrepel)
# Creating linear confirmed cases plot
p1_lin<- slc_countries %>% 
    ggplot(aes(x=date,
               y=confirmed,
               col=country)) + 
    geom_line(alpha=0.5,size=1) +
    ggtitle("confirmed")+
  geom_label_repel(data = filter(slc_countries, should_be_labeled == TRUE), (aes(label = country)))+
    labs(x="date", y="count") +
    theme_bw();p1_lin
# Creating linear death cases plot
p2_lin<- slc_countries %>% 
    ggplot(aes(x=date,
               y=deaths,
               col=country)) + 
    geom_line(alpha=0.5,size=1) +
    ggtitle("deaths")+
  geom_label_repel(data = filter(slc_countries, should_be_labeled == TRUE), (aes(label = country)))+
    labs(x="date", y="count") +
    theme_bw()
# Creating logarithmic confirmed cases plot
p1_log <- 
slc_countries %>% 
    ggplot(aes(x=date,
               y=log(confirmed),
               col=country)) +
    geom_line(alpha=0.5,size=1) +
    ggtitle("confirmed")+
    geom_label_repel(data = filter(slc_countries, should_be_labeled == TRUE), (aes(label = country)))+
    labs(x="date", y="count") +
    theme_bw()
# Creating logarithmic death cases plot
p2_log <- 
slc_countries %>% 
    ggplot(aes(x=date,
               y=log(deaths),
               col=country)) + 
    geom_line(alpha=0.5,size=1)+
    ggtitle("deaths")+
    geom_label_repel(data = filter(slc_countries, should_be_labeled == TRUE), (aes(label = country)))+
    labs(x="date", y="count") +
    theme_bw()
# Merging the tables
library(patchwork)
P1_lin <- p1_lin+p2_lin;P1_lin
P1_log <- p1_log+p2_log;P1_log

```

- Plot (P2) the death ratio (*i.e.* deaths per confirmed cases) per country averaged over time as a barplot, for 50 random countries.
    + Try ordering the countries per decreasing ratio using `reorder()`{.R}
    + Flip the plot to have horizontal bars
    + Is there anything wrong?

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.7}
# Death Ratio for all countries
dratio <- data.frame(alldata[1:nrow(alldata),4]/alldata[1:nrow(alldata),3])
colnames(dratio) = "dratio"
# Binding Death Ratio to alldata as column
alldata <- cbind(alldata,data.frame(dratio))
# Getting mean value of death ratio per country
dratio_mean <- alldata %>%
  group_by(country) %>%
  summarise(dratio_mean=mean(dratio))
# Choosing arbitrary row number
nranrow <-sample(1:nrow(dratio_mean), 
                 size=50,
                 replace=FALSE)
# Using those random row numbers to create random countries
ran_cont <- dratio_mean %>% slice(nranrow)
colnames(ran_cont)[2]="death_ratio"

# Reordering and Plotting
P2 <- ran_cont %>%
  ggplot(aes(x = reorder(country, death_ratio), y = death_ratio))+
  geom_bar(stat="identity", color='skyblue',fill='steelblue')+
  theme(axis.text.x=element_text(angle=45, hjust=1))+
  coord_flip();P2


```

- To better see the effect of confinement regulation, it's probably more interesting to plot the number of new confirmed cases. 
    - Plot as a barplot the number of new confirmed cases per day for 2 countries of your choice, and add a vertical line corresponding to the date of application of confinement rules. For example, in France and Italy it was on March 17th and March 10th, respectively.
    - Add a smooth line to smooth out the effect or irregular numbers reporting. You can play with the `span` parameter to have a more or less smooth curve.

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
# Defining two countries
two_countries <- alldata %>% filter(country == 'France'|
                                       country == 'Turkey')
as.tibble(two_countries)
# Plotting
two_countries %>%
  ggplot(aes(x = date, y = newcases, color=country)) +
  geom_bar(stat="identity", fill="white")+
  theme(axis.text.x=element_text(angle=45, hjust=1))+
  geom_vline(aes(xintercept = as.numeric(ymd("2020-03-17"))),color="red", size=2, lty=2)+
  geom_vline(aes(xintercept = as.numeric(ymd("2020-04-02"))),color="green", size=2, lty=2)+
  geom_smooth(n=500,span=.2,level=.4)+
  theme_classic()
```


# Fitting

+ Load the library `broom` ([vignette](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)). `broom` allows tidying the output of fit functions such as `lm()` or `nls()`, taking the text output and making it into a tibble. Example:

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE}
library(broom)

fit<-slc_countries%>%
  nest(data=-country) %>% 
  mutate(fit=map(data, ~ nls(data = .,
                             confirmed~A/(1+exp(-B*day)), 
                             start=list(A=500, B=1))),
         tidied = map(fit, tidy),
         augmented = map(fit, augment))
  
  
  
######## Couldn't Completed ########
  
  
nest(data=-country) %>% 
   mutate(fit = map(data, ~lm(data, data = confirmed~A/(1+exp(-B*day)),
                              start=list(A=500, B=1))),
          start=list(A=500, B=1),
         tidied = map(fit, tidy),
         augmented = map(fit, augment))

mutate(fit = map(data, ~ t.test(.$mpg)))
```


Here, by combining `nest()` and `purrr::map()`, we can apply the fit to each group. The result is a tibble containing the fit result for each group. Then, using `broom`'s function `augment()` and `tidy()`, we respectively get the fitted values and residues, and the fitting parameters.

- Now then, using the same procedure as in the example above, fit the total Confirmed cases for the 5 countries you chose earlier **for the 100 first days** using a [logistic function](https://en.wikipedia.org/wiki/Logistic_function), and plot the data and their fit, and show the results of the fits.

```{r echo=params$solution, warning = FALSE, message=FALSE, cache=FALSE}
fit %>% unnest(augmented)
fit %>% unnest(tidied)
fit %>% unnest(tidied) %>% 
  select(country, term, estimate, std.error) %>% 
  pivot_wider(names_from = term, 
              values_from = c(estimate,std.error))
ggplot(data=slc_countries, aes(x=date, y=confirmed, col=country))+
    geom_point(alpha=0.5) + 
    geom_line(data=d_fit %>% unnest(augmented), 
        aes(x=x,y=.fitted, col=country))
```

In fact, this exponential model is rather wrong... A better model of epidemics dynamics is done by the SIR model, for Susceptible, Infectious, Recovered. A description of the SIR modeling through R can be found [here](https://staff.math.su.se/hoehle/blog/2020/03/16/flatteningthecurve.html), for example.
