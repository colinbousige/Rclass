[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"","code":""},{"path":"index.html","id":"author","chapter":"Welcome","heading":"Author","text":"Colin BOUSIGE – CNRS Researcher, Laboratoire des Multimatériaux et Interfaces, Lyon, France","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"book code samples licensed Creative Commons Attribution-ShareAlike 3.0 License.","code":""},{"path":"about-the-class.html","id":"about-the-class","chapter":"1 About the class","heading":"1 About the class","text":"","code":""},{"path":"about-the-class.html","id":"objectives-of-the-class","chapter":"1 About the class","heading":"1.1 Objectives of the class","text":"goal class end, students able :Treat data free open source language R, .e.:\nRead, browse, manipulate plot data\nModel simulate data\nRead, browse, manipulate plot dataModel simulate dataMake automatic reporting RmarkdownBuild graphical interface Shiny interact data output something (value, pdf report, graph…)learn useful scientific domain. examples course however mainly coming type data might encounter Materials Science , well, ’s hand…","code":""},{"path":"about-the-class.html","id":"prerequisites","chapter":"1 About the class","heading":"1.2 Prerequisites","text":"Coding skills: none expected.students come laptop admin rights (.e. able install stuff).","code":""},{"path":"about-the-class.html","id":"motivations","chapter":"1 About the class","heading":"1.3 Motivations","text":"","code":""},{"path":"about-the-class.html","id":"reproducible-data-treatment-why-it-matters","chapter":"1 About the class","heading":"1.3.1 Reproducible data treatment: why it matters","text":"introduction Wikipedia page reproducible research:2016, Nature conducted survey 1576 researchers took brief online questionnaire reproducibility research. According survey, 70% researchers tried failed reproduce another scientist’s experiments, half failed reproduce experiments. […] Although 52% surveyed agree significant ‘crisis’ reproducibility, less 31% think failure reproduce published results means result probably wrong, say still trust published literature.1Replicability reproducibility keys scientific integrity. Establishing workflow data always treated manner necessity, way :Minimize errors inherent human manipulationKeep track treatments perform data document methodology: allows others reproduce data, also .Help make sense data, avoid disregarding data (hence help keep scientific integrity)Gain tremendous amounts timeIt objective class provide tools necessary work within philosophy.","code":""},{"path":"about-the-class.html","id":"why-with-r-and-not-python","chapter":"1 About the class","heading":"1.3.2 Why with R and not python?","text":"eternal question… R originally designed statisticians statisticians might still suffers “statistics ” label sticks .Python wide spectrum programming language efficient numerical libraries used computer science community.R focused data treatment, statistics representation. R, object data, base R allows read, treat, fit plot data easily – although still certainly need additional packages.python, can everything, including treating analyzing scientific data – right packages. R, can less well , opinion seamlessly (probably learned used R years starting python…). opinion, xkcd comic python environment slightly exaggerated… R, installation maintenance sooooo easy comparison…language strengths weaknesses. tastes, say python R compare like (although pythonist probably say opposite):Well, ’s subjective, really.\nend, still use languages, one different purpose:Let’s say want produce initial atomic configuration molecular dynamics simulation, read molecular dynamics trajectory compute quantities pair correlation mean square displacement, perform image-based machine learning: python (even C, need treat large trajectories).Now want make sense experimental measurements results simulations, fits produce publication-quality graphs experimental reports: R.languages great able use best thing can happen (relatively speaking) – especially since can combine Rmarkdown using reticulate package, see later class., since goal provide tools seamlessly read, make sense, plot data reproducible science philosophy, let’s go R. Also, R great IDE (Rstudio) really eases working data code. nice IDE still lacking python.","code":""},{"path":"about-the-class.html","id":"further-reading","chapter":"1 About the class","heading":"1.4 Further reading","text":"class indented provide students tools handle R, Rmarkdown Shiny, provide extensive review everything possible R. go :R\nR manual CRAN\ncheatsheets\ntidyverse website\nTibbles.\nTidy data\nTips improve code\nR manual CRANSome cheatsheetsThe tidyverse websiteTibbles.Tidy dataTips improve codePlotting\nR Graph Gallery\nR Graph Cookbook\nggplot cheatsheet\nAnother one\nAnother one quite extensive\nAnother one\n\nR Graph GalleryThe R Graph CookbookThe ggplot cheatsheet\nAnother one\nAnother one quite extensive\nAnother one\nAnother oneAnother one quite extensiveAnother oneRmarkdown\nRmarkdown complete guide\nRmarkdown cheatsheet\nRmarkdown cookbook\nRmarkdown code chunks\nRmarkdown mixing languages\nRmarkdown complete guideRmarkdown cheatsheetRmarkdown cookbookRmarkdown code chunksRmarkdown mixing languagesShiny\nShiny cheatsheet\nGuide application layout\nShiny Gallery: find want adapt needs\nofficial Shiny video tutorial\nShiny cheatsheetGuide application layoutThe Shiny Gallery: find want adapt needsThe official Shiny video tutorialAnd always, question, Google friend!","code":""},{"path":"about-the-class.html","id":"teaser","chapter":"1 About the class","heading":"1.5 Teaser","text":"want able produce interactive plots like automatic experimental report?want produce publication-quality graphs like ?want able build graphical interfaces like help data treatment?Stay tuned! ’ve come right place.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"a-little-reminder-on-statistics","chapter":"2 A little reminder on Statistics","heading":"2 A little reminder on Statistics","text":"","code":""},{"path":"a-little-reminder-on-statistics.html","id":"why-are-statistical-tools-necessary-in-physical-science","chapter":"2 A little reminder on Statistics","heading":"2.1 Why are statistical tools necessary in physical science?","text":"Science, one fully grasp concept physical measurement. Let’s take example visualize importance concept.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"a-practical-example","chapter":"2 A little reminder on Statistics","heading":"2.1.1 A practical example","text":"Let’s say want communicate someone temperature, tell person temperature “38”. random person street, might think: “nice, let’s go beach today!”. random person USA, ’re gonna think: “damn, put coat?”. person happens physician, might think: “kid’s got slight fever”. physicist cryostat experiment, might think “let’s check tank level”… see one important part measurement missing: unit. Units people understand exchanging data, see 38 Celsius, 38 Fahrenheit 38 Kelvin quite different, quantity mean different things different contexts. physical quantity given without unit absolutely meaningless (unless, course, looking unit-less quantity, like count).Now let’s consider body temperature 38 °C given physician. measure temperature? mercury graduated thermometer thermocouple? first case, can probably assume value given measurement error least 1 °C, meaning temperature give physician (38±1) °C, .e. physician won’t able decide whether concerned . second case, temperature often given 0.1 °C precision, physician, seeing body temperature (38±0.1) °C, probably tell take aspirin rest instead giving something stronger treat possible infection. Given uncertainty given value 0.1 °C, one fact give temperature matching decimal precision, .e. (38.0±0.1) °C. Writing (38±0.1) °C, (38.00001±0.1) °C (38.00±0.10000) °C meaningless ., see physical measurement given four parts: actual value, decimal precision, uncertainty, unit. four parts missing physical quantity wanted share, best imprecise, worst utterly meaningless.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"probabilistic-description-of-physical-systems","chapter":"2 A little reminder on Statistics","heading":"2.1.2 Probabilistic description of physical systems","text":"Let’s continue example body temperature measured thermocouple laser thermometer 0.1 °C precision.\nfirst measurement body temperature yielded (38.0±0.1) °C. Now let’s repeat measurement number times various area body (left imagination). Let’s say shows (38.1±0.1) °C, (38.0±0.1) °C, (38.3±0.1) °C, (37.9±0.1) °C, (38.2±0.1) °C, (38.1±0.1) °C, (38.1±0.1) °C, (39.8±0.1) °C. actual body temperature ? stick single measurement? course . make histogram measured values, study distribution measurements (Fig. 2.1). can see one values clearly outlier – something might gone wrong . done measurement measured value? might jumped wrong conclusion, possibly serious consequence like giving wrong medicine.\nFigure 2.1: Histogram body temperature measurements. red line mean value, orange one mode blue one median.\nexample, see physical measurement absolute. fact, physical measurement assessment probability physical value within certain range. case example, removing outlier certain measurement wrong, means measured body temperature high probability somewhere 38.0 °C 38.2 °C.\n(general) terms, one consider measurement quantity \\(X\\) probability \\(P(x - \\sigma < X < x + \\sigma )\\) quantity \\(X\\) value \\(x-\\sigma\\) \\(x+\\sigma\\). uncertainty \\(\\sigma\\) around mean value \\(x\\) usually given standard deviation distribution measurements around mean.Since physical measurements fact probabilities, can – must – use statistical tools characterize .","code":""},{"path":"a-little-reminder-on-statistics.html","id":"quantifying-the-properties-of-data","chapter":"2 A little reminder on Statistics","heading":"2.2 Quantifying the properties of data","text":"","code":""},{"path":"a-little-reminder-on-statistics.html","id":"data-representation-presenting-a-measurement","chapter":"2 A little reminder on Statistics","heading":"2.2.1 Data representation – presenting a measurement","text":"Depending data looking , various ways representing possible. can’t stress enough importance picking right representation data, expression physical sense. good representation help make sense data communicate results. bad representation, well…","code":""},{"path":"a-little-reminder-on-statistics.html","id":"histograms","chapter":"2 A little reminder on Statistics","heading":"2.2.1.1 Histograms","text":"looking discrete values want characterize distribution measurement, often good idea use histogram representation, represents frequency measurement made within certain range, called bin. Let’s take Fig. 2.1 plot various bin sizes. One can see choice bin size important, determines whether data noisy lack fine information.\nFigure 2.2: Histogram body temperature measurements different bin widths.\n","code":""},{"path":"a-little-reminder-on-statistics.html","id":"graphs","chapter":"2 A little reminder on Statistics","heading":"2.2.1.2 Graphs","text":"case want represent continuous data, say evolution quantity \\(y\\) respect quantity \\(x\\), use graph representation. saw , physical quantity given uncertainty unit. applies graph: must clearly display units quantities \\(x\\) \\(y\\), error bars usually taken standard deviation individual measurement (thus performed number times, depending looking ).\nFigure 2.3: Representing datapoints without error bars, large error bars respect data, small error bars respect data: difference meaningless data, noise, meaningful data.\ncan think set {datapoint + error bar} histogram: displayed point mean value histogram, error bar standard deviation. Therefore, plotting straight line points usually pointless. Plotting line going data points meaning line results physical model explaining variation quantity \\(y\\) evolution quantity \\(x\\) – called fit, see R class later.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"characterizing-an-ensemble-of-measurements","chapter":"2 A little reminder on Statistics","heading":"2.2.2 Characterizing an ensemble of measurements","text":"take \\(N\\) repeated measurements observable \\(x\\), natural try assess knowledge ensemble measures (1) single number representing measured quantity, (2) second number representing spread measurements. saw , observable \\(x\\) thus generally defined central (mean) value \\(\\left< x \\right>\\), spread \\(\\sigma_x\\) (standard deviation uncertainty), unit.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"central-value-mode-median-and-mean","chapter":"2 A little reminder on Statistics","heading":"2.2.2.1 Central value: mode, median and mean","text":"mode ensemble measurements frequent value. measurement question continuous variable, one bin data terms histogram order quantify modal value distribution: mode position maximum histogram.median value ensemble value \\(x\\) equal number measurements point. even number measurements, median value taken midpoint two central values.mean (arithmetic average) often used two previous quantities, usually provides better way quantify “typical” value measured. mean value denoted either \\(\\overline{x}\\) \\(\\left< x \\right>\\), given :\\[\\begin{equation}\n\\overline{x}=\\left< x \\right>=\\frac{1}{N}\\sum_{=1}^Nx_i,\n\\end{equation}\\]\n\\(x_i\\) \\(\\)-th measurement \\(x\\).Figure 2.1 shows representation sample data plotted histogram. figure shows mode, mean median. particular sample data, mean 38.3 °C, median 38.1 °C, mode 38.0 °C. fact mode smaller mean indication data asymmetric mean. usually refer distribution skewed, case data skewed right.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"quantifying-the-spread-of-data-variance-and-standard-deviation","chapter":"2 A little reminder on Statistics","heading":"2.2.2.2 Quantifying the spread of data: variance and standard deviation","text":"mean ensemble data doesn’t provide information data distributed. description set data just quoting mean value incomplete. need second number order quantify dispersion data around mean value. average deviations mean, \\(\\left< x-\\overline{x} \\right>\\), useful quantity , definition, zero symmetrically distributed sample data (always case randomly distributed data – consequence central limit theorem, see later). rather consider average value squared deviations mean measure spread ensemble measurements. called variance \\(V(x)\\), given :\\[\\begin{equation}\n\\begin{aligned}\nV(x)&=\\left< (x-\\overline{x})^2 \\right>\\\\\n    &=\\frac{1}{N}\\sum_{=1}^N(x_i-\\overline{x})^2\\\\\n    &=\\overline{x^2}-\\overline{x}^2\n\\end{aligned}\n\\tag{2.1}\n\\end{equation}\\]square root mean-squared (root-mean-squared RMS) deviation called standard deviation, given :\\[\\begin{equation}\n\\begin{aligned}\n\\sigma(x)&=\\sqrt{V(x)}\\\\\n         &=\\sqrt{\\overline{x^2}-\\overline{x}^2}\n\\end{aligned}\n\\tag{2.2}\n\\end{equation}\\]standard deviation quantifies amount reasonable measurement \\(x\\) differ mean value \\(\\overline{x}\\). Considering Gaussian distribution, expect 31.7% measurements deviating mean value 1\\(\\sigma\\), goes 4.5% measurements deviate 2\\(\\sigma\\), 0.3% measurements deviate 3\\(\\sigma\\). Thus, perform measurement deviates significant margin expected value \\(\\left< x \\right>\\pm\\sigma\\), need ask significance measurement.general, scientists often prefer using standard deviation rather variance describing data, since former units observable measured.measurement quantity \\(x\\) therefore usually presented form \\(\\left< x \\right>\\pm\\sigma_x\\), \\(\\left< x \\right>\\) arithmetic average \\(\\sigma_x\\) standard deviation data.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"caveats","chapter":"2 A little reminder on Statistics","heading":"2.2.2.3 Caveats","text":"considerations assume distribution measured values mono-modal, .e. histogram measured values centered around single value. case multimodal distribution shown Fig. 2.4, meaningless use tools fine information distribution lost.\nFigure 2.4: trimodal distribution measurements. red line shows mean value distribution: fails grasp reality distribution.\ncase, one try deconvolute distribution terms individual peaks, gather positions, widths intensities.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"useful-distributions","chapter":"2 A little reminder on Statistics","heading":"2.3 Useful distributions","text":"","code":""},{"path":"a-little-reminder-on-statistics.html","id":"probability-density-functions","chapter":"2 A little reminder on Statistics","heading":"2.3.1 Probability Density Functions","text":"now introduce notion Probability Density Function (PDF).\ndefinition, PDF distribution total area unity. variation PDF represents probability something occurring point parameter space.\ngeneral, PDF described function \\(P(x)\\), \\[\\begin{equation}\n\\int_a^b P(x)dx=1,\n\\tag{2.3}\n\\end{equation}\\]\n\\(\\) \\(b\\) limits valid domain \\(P(x)\\) function. probability obtaining result \\(x\\) \\(x + dx\\) thus \\(P(x)dx\\). Usual PDFs encountered physics Poisson distribution well Gaussian distribution, describe bit.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"pdfs-mean-and-variance","chapter":"2 A little reminder on Statistics","heading":"2.3.2 PDFs, mean and variance","text":"Let us define PDF \\(P(x)\\) describing continuous distribution.\ncan compute average value quantity computing integral quantity multiplied PDF.example, average value variable \\(x\\), distributed according PDF \\(P(x)\\) domain \\(-\\infty < x <\\infty\\), given :\\[\\begin{equation}\n\\begin{aligned}\n\\left< x \\right>&=\\int_{-\\infty}^{\\infty}xP(x)dx\\\\\n\\text{} \\left< x \\right>&=\\sum_{}x_iP(x_i) \\text{ case discrete distribution}\n\\end{aligned}\n\\tag{2.4}\n\\end{equation}\\]called first moment PDF.method can used compute average values complicated expressions. mean value \\((x - \\overline{x})^2\\), .e. variance \\(V\\), thus given \\(\\overline{x}\\)-centered second moment PDF, :\\[\\begin{equation}\n\\begin{aligned}\nV&=\\int_{-\\infty}^{\\infty}(x - \\overline{x})^2P(x)dx\\\\\n\\text{} V&=\\sum_{}(x_i - \\overline{x})^2P(x_i) \\text{ case discrete distribution}\n\\end{aligned}\n\\tag{2.5}\n\\end{equation}\\]","code":""},{"path":"a-little-reminder-on-statistics.html","id":"the-poisson-distribution","chapter":"2 A little reminder on Statistics","heading":"2.3.3 The Poisson distribution","text":"","code":""},{"path":"a-little-reminder-on-statistics.html","id":"definition","chapter":"2 A little reminder on Statistics","heading":"2.3.3.1 Definition","text":"certain reaction happens randomly time average frequency \\(\\lambda\\) given time interval, number \\(k\\) reactions time interval follow Poisson distribution:\\[\\begin{equation}\nP_\\lambda(k) = \\frac{\\lambda^ke^{-\\lambda}}{k!}\n\\tag{2.6}\n\\end{equation}\\]Examples encounters Poisson distributions various number calls received per hours call center, yearly number Prussian soldiers killed horse kicks… number particles (photons, neutrons, neutrinos…) hitting detector every second.\nFigure 2.5: Poisson distribution various parameters. asymmetric small values \\(k\\) \\(\\lambda\\), tends towards Gaussian lineshape larger values.\n","code":""},{"path":"a-little-reminder-on-statistics.html","id":"characteristics","chapter":"2 A little reminder on Statistics","heading":"2.3.3.2 Characteristics","text":"shown Fig. 2.5, small \\(\\lambda\\) distribution asymmetric skewed right. \\(\\lambda\\) increases Poisson distribution becomes symmetric.Following Eq. (2.4), average number observed events, \\(\\left< k \\right>\\), given :\\[\\begin{equation}\n\\begin{aligned}\n\\left< k \\right> &= \\sum_{k=0}^\\infty kP_\\lambda(k) = \\sum_{k=1}^\\infty k\\frac{\\lambda^ke^{-\\lambda}}{k!}\\\\\n        &= \\lambda e^{-\\lambda} \\sum_{k=1}^\\infty \\frac{\\lambda^{k-1}}{(k-1)!}= \\lambda e^{-\\lambda} \\sum_{k=0}^\\infty \\frac{\\lambda^{k}}{k!}\\\\\n        &= \\lambda\n\\end{aligned}\n\\end{equation}\\]manner using “trick” \\(x^2=x(x-1)+x\\), variance \\(\\sigma^2(k)\\) distribution given :\\[\\begin{equation}\n\\begin{aligned}\n\\sigma^2(k) &= \\sum_{k=1}^\\infty (k-\\lambda)^2\\frac{\\lambda^k e^{-\\lambda}}{k!}\\\\\n        &= \\lambda e^{-\\lambda} \\left[\\sum_{k=1}^\\infty k^2\\frac{\\lambda^{k-1}}{k!} \\underbrace{-2\\lambda\\sum_{k=1}^\\infty \\frac{\\lambda^{k-1}}{(k-1)!}}_{-2\\lambda e^\\lambda}+\\underbrace{\\sum_{k=1}^\\infty \\lambda^2\\frac{\\lambda^{k-1}}{k!}}_{\\lambda e^\\lambda}\\right]\\\\\n        &= \\lambda e^{-\\lambda} \\left[ \\underbrace{\\sum_{k=2}^\\infty k(k-1)\\frac{\\lambda^{k-1}}{k!}}_{\\lambda e^\\lambda} + \\underbrace{\\sum_{k=1}^\\infty k\\frac{\\lambda^{k-1}}{k!}}_{e^\\lambda} - \\lambda e^\\lambda\\right]\\\\\n        &=\\lambda = \\left< k \\right>\n\\end{aligned}\n\\end{equation}\\]important result , counting random events average \\(\\left< N \\right>\\), standard deviation \\(\\sigma=\\sqrt{\\left< N \\right>}\\). typically happens performing diffraction spectroscopic measurement, X-ray diffraction, Raman, IR neutron spectroscopy, etc.: longer acquire data, higher number detected “events” \\(N\\) (particle hits detector), “better statistics”. Indeed, relative error thus \\(\\sqrt{N}/N=1/\\sqrt{N}\\).consequence make factor 10 improvement relative error, one increase 100 number events. usually done increasing acquisition time, fine long short enough. irrealistic acquisition times start become necessary, one maybe try find another way increase \\(N\\): can done improving detector efficiency, increasing probe (laser, neutron/x-ray) brightness, changing experimental geometry, etc.Finally, “large” numbers (\\(\\lambda\\gtrsim 100\\)) Poisson distribution tends towards symmetric Gaussian distribution describe just .","code":""},{"path":"a-little-reminder-on-statistics.html","id":"the-gaussian-distribution","chapter":"2 A little reminder on Statistics","heading":"2.3.4 The Gaussian distribution","text":"","code":""},{"path":"a-little-reminder-on-statistics.html","id":"definition-1","chapter":"2 A little reminder on Statistics","heading":"2.3.4.1 Definition","text":"Gaussian distribution, also known normal distribution, mean value \\(\\mu\\) standard deviation \\(\\sigma\\) function variable \\(x\\) given :\\[\\begin{equation}\nP(x, \\mu, \\sigma)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/2\\sigma^2}\n\\end{equation}\\]useful transform data \\(x\\) space corresponding \\(z\\) space mean value zero, standard deviation one. transformation given mapping \\(z=\\frac{x-\\mu}{\\sigma}\\), Gaussian distribution terms \\(z\\) thus:\\[\\begin{equation}\nP(z)=\\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2}\n\\end{equation}\\]","code":""},{"path":"a-little-reminder-on-statistics.html","id":"characteristics-1","chapter":"2 A little reminder on Statistics","heading":"2.3.4.2 Characteristics","text":"\nFigure 2.6: zero-centered Gaussian distribution standard deviation 1, \\(P(z)\\). red line marks half maximum, \\(P(z_{HM})=1/2\\sqrt{2\\pi}\\), blue lines values \\(z\\) half maximum obtained, \\(z_{HM}=\\pm\\sqrt{2\\ln{2}}\\).\nSometimes instead quantifying Gaussian distribution (monomodal distribution, matter) using variance standard deviation, scientists speak full width half maximum (FWHM).\nadvantage extreme outliers distribution contribute quantification spread data. name suggests, FWHM width distribution (spread mean) points distribution reaches half maximum.Gaussian distribution \\(P(z)\\), half maximum attained \\(z_{HM}\\) :\\[\\begin{equation}\n\\begin{aligned}\n\\frac{1}{\\sqrt{2\\pi}}e^{-z_{HM}^2/2}&= \\frac{1}{2}\\frac{1}{\\sqrt{2\\pi}}\\\\\n\\Rightarrow z_{HM}&=\\pm\\sqrt{2\\ln{2}}\n\\end{aligned}\n\\end{equation}\\]FWHM \\(P(z)\\) therefore \\(FWHM=2\\sqrt{2\\ln{2}}\\simeq2.355\\). Using relation \\(z\\) \\(\\sigma\\), get relation FWHM standard deviation:\\[\\begin{equation}\nFWHM=2\\sqrt{2\\ln{2}}\\times\\sigma\n\\end{equation}\\]can seen Table 2.1, using FWHM ensures roughly 76% data comprised \\(\\mu-\\sigma\\) \\(\\mu+\\sigma\\), goes \\(\\sim95\\)% \\(\\mu-2\\sigma\\) \\(\\mu+2\\sigma\\).\nTable 2.1: Integral values various values \\(\\) \\(\\int_{-}^aP(z)dz\\).\n","code":""},{"path":"a-little-reminder-on-statistics.html","id":"uncertainty-and-errors","chapter":"2 A little reminder on Statistics","heading":"2.4 Uncertainty and errors","text":"","code":""},{"path":"a-little-reminder-on-statistics.html","id":"central-limit-theorem-on-the-gaussian-nature-of-statistical-uncertainty","chapter":"2 A little reminder on Statistics","heading":"2.4.1 Central limit theorem: on the Gaussian nature of statistical uncertainty","text":"central limit theorem states one takes \\(N\\) random independent samples distribution data describes variable \\(x\\), \\(N\\) tends infinity, distribution sum samples tends Gaussian distribution.terms: mean value large number \\(N\\) independent random variables (can distributed following distribution finite variance), obeying distribution variance \\(\\sigma_0^2\\), approaches normal distribution variance \\(\\sigma^2 = \\sigma _0^2/N\\).result fundamental implies independent measurements observable show values spread following Gaussian distribution, thus statistical uncertainties Gaussian nature.Moreover, see typical property statistical errors, relative error proportional \\(1/\\sqrt{N}\\). Increasing number observations thus decreases error, .e. increases precision.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"combination-of-errors","chapter":"2 A little reminder on Statistics","heading":"2.4.2 Combination of errors","text":"Let us consider function \\(n\\) variables, \\(f(u_1, u_2, ..., u_n)\\). can Taylor expand function various mean values \\(u_i=\\overline{u_i}\\), , first order:\\[\\begin{equation}\nf(u_1, ..., u_n) = f(\\overline{u_1}, ..., \\overline{u_n}) + \\sum_{=1}^n (u_i-\\overline{u_i})\\frac{\\partial f}{\\partial u_i}\n\\end{equation}\\]Considering variance quantity \\(f\\) given \\(\\sigma^2(f) = (f - \\overline{f} )^2\\), follows variance multivariable function given :\\[\\begin{equation}\n\\begin{aligned}\n\\sigma^2(f) &= \\left(\\sum_{=1}^n (u_i-\\overline{u_i})\\frac{\\partial f}{\\partial u_i}\\right)^2\\\\\n         &= \\sum_{=1}^n \\left(\\frac{\\partial f}{\\partial u_i}\\right)^2\\sigma_{u_i}^2 + 2\\sum_{\\ne j}\\frac{\\partial f}{\\partial u_i}\\frac{\\partial f}{\\partial u_j}\\sigma_{u_iu_j}\\\\\n\\end{aligned}\n\\end{equation}\\]\nreplaced \\((u_i-\\overline{u_i})^2\\) variance \\(\\sigma_{u_i}^2\\) \\((u_i-\\overline{u_i})(u_j-\\overline{u_j})\\) covariance \\(\\sigma_{u_iu_j}\\).variables \\(u_i\\) independent covariance \\(\\sigma_{u_iu_j}\\) null, follows general expression standard error can applied function independent variables:\\[\\begin{equation}\n\\sigma(f) = \\sqrt{\\sum_{=1}^n \\left(\\frac{\\partial f}{\\partial u_i}\\right)^2\\sigma_{u_i}^2}\n\\tag{2.7}\n\\end{equation}\\]","code":""},{"path":"a-little-reminder-on-statistics.html","id":"functions-of-one-variable","chapter":"2 A little reminder on Statistics","heading":"2.4.2.1 Functions of one variable","text":"Let us consider function \\(f\\) form depends one observable \\(x\\), example:\\[\\begin{equation}\nf = Ax + B\n\\end{equation}\\], following Eq. (2.7), standard error function given :\\[\\begin{equation}\n\\begin{aligned}\n\\sigma_f &= \\sqrt{\\left(\\frac{\\partial f}{\\partial x}\\right)^2\\sigma_x^2}\\\\\n         &= \\sigma_x\n\\end{aligned}\n\\end{equation}\\], independently offset measured observable, resulting error must corrected factor intensity.practice, let’s say measure Raman spectrum. saw , error intensity count given square root intensity count.possible shift vertically spectrum without recompute error bars.want normalize (say, 1) spectrum, multiply errors renormalization constant.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"functions-of-two-variables","chapter":"2 A little reminder on Statistics","heading":"2.4.2.2 Functions of two variables","text":"Now consider function \\(f = Ax + \\), measured mean standard deviation \\(x\\) \\(y\\), want compute standard deviation sum/subtraction. can use general formula Eq. (2.7) determine , hence:\\[\\begin{equation}\n\\begin{aligned}\n\\sigma_f &= \\sqrt{\\left(\\frac{\\partial f}{\\partial x}\\right)^2\\sigma_x^2 + \\left(\\frac{\\partial f}{\\partial y}\\right)^2\\sigma_y^2}\\\\\n         &= \\sqrt{^2\\sigma_x^2 + B^2\\sigma_y^2}\n\\end{aligned}\n\\end{equation}\\]practice, let’s say measure UV spectrum solution (molecule solvent), reference spectrum solvent. saw , error intensity count given square root intensity count. want subtract signal solvent get signal molecule.thus perform operation errors, \\(\\sigma_{result}=\\sqrt{\\sigma^2_{solution}+\\sigma^2_{reference}}\\). means order statistically sound resulting spectrum, reference needs measured good statistics order dominate resulting error.good thing think error propagation comes … don’t bother computing hand, packages , see later class.","code":""},{"path":"a-little-reminder-on-statistics.html","id":"further-reading-1","chapter":"2 A little reminder on Statistics","heading":"2.5 Further reading","text":". Bevan, Statistical Data Analysis Physical Sciences, Cambridge University Press (2013)G. Bohm, Introduction Statistics Data Analysis Physicists, Hamburg: Verl. Dt. Elektronen-Synchrotron (2010).J. Watkins, Introduction Science Statistics","code":""},{"path":"getting-ready.html","id":"getting-ready","chapter":"3 Getting ready","heading":"3 Getting ready","text":"","code":""},{"path":"getting-ready.html","id":"the-easy-way","chapter":"3 Getting ready","heading":"3.1 The easy way","text":"Download install RDownload install RstudioWindows : Download install RtoolsYou’re good go.","code":""},{"path":"getting-ready.html","id":"the-more-advanced-way","chapter":"3 Getting ready","heading":"3.2 The more advanced way","text":"don’t want use Rstudio rather want keep favorite text editor, like (Visual Studio Code Sublime Text, see configuration )still recommend downloading installing R via CRAN (packages problems due homebrew installation Mac).fully operational Rmarkdown files without using Rstudio, need install pandoc.personally use VS Code.First, install radian console.Install language server protocol package R : install.packages(\"languageserver\")VS Code, install following extensions:\nVSCode R\nR LSP Client\nVSCode RR LSP ClientEnable r.bracketedPaste using RadianSet r.rterm.windows, r.rterm.mac r.rterm.linux: Path Radian (installed radian)good go: ⌘+⏎ send current line/selection radian console ⌘+Shift+K render current Rmd file.relevant part settings.json file:Also, recommend turning session watcher (\"r.sessionWatcher\": true), adding following code .Rprofile. way, help, tables figures can viewed VS Code browser panel.personally used Sublime Text 3 long time, switched VS Code recently. used :First, install Package control.set command line launch: ln -s \"/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl\" /usr/local/bin/sublime.Install minima packages LSP, R-IDE, Terminus, SendCode, also radian console.can also add useful packages LatexTools, BracketHighlighter, RainbowBrackets, Citer, Path Tools, SidebarEnhancements, SidebarTools, Git, GitGutter, Alignment, AutoFileName.Install language server protocol package R : install.packages(\"languageserver\")create keyboard shortcut open terminal radian console R interpreter, add keybinding file:Select Terminus destination SendCodeYou good go: ⌘+⏎ send current line/selection radian console, ⌘+B render current Rmd file, ⌘+\\ set working directory current file’s folder.","code":"{\n    \"r.rterm.mac\": \"/usr/local/bin/radian\",\n    \"r.rpath.mac\": \"/usr/local/bin/R\",\n    \"r.bracketedPaste\": true,\n    \"r.lsp.diagnostics\": false,\n    \"r.sessionWatcher\": true,\n    \"r.rmarkdown.knit.useBackgroundProcess\": false,\n    \"editor.guides.bracketPairs\": true\n}\noptions(vsc.browser = \"Beside\")\noptions(vsc.viewer = \"Beside\")\noptions(vsc.page_viewer = \"Beside\")\noptions(vsc.view = \"Beside\")\noptions(vsc.helpPanel = \"Beside\")\n\nif (interactive() && Sys.getenv(\"TERM_PROGRAM\") == \"vscode\") {\n    if (\"httpgd\" %in% .packages(all.available = TRUE)) {\n        options(vsc.plot = FALSE)\n        options(device = function(...) {\n            httpgd::hgd(silent = TRUE)\n            .vsc.browser(httpgd::hgd_url(), viewer = \"Beside\")\n        })\n    }\n}[\n    {\n        \"description\": \"Create R terminal\",\n        \"key\": \"alt+cmd+r\",\n        \"command\": \"r.createRTerm\"\n    },\n    {\n        \"description\": \"Insert code block\",\n        \"key\": \"cmd+shift+i\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus && editorLangId == 'rmd'\",\n        \"args\": {\n            \"snippet\": \"``` {r}\\n$0\\n```\"\n            }\n    },\n    {\n        \"description\": \"Setwd to current file path\",\n        \"key\": \"cmd+\\\\\",\n        \"command\": \"r.runCommandWithEditorPath\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": \"setwd(dirname(\\\"$$\\\"))\"\n    },\n    {\n        \"description\": \"Insert R arrow\",\n        \"key\": \"ctrl+,\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": {\n            \"snippet\": \" <- \"\n            }\n    },\n    {\n        \"description\": \"Insert pipe\",\n        \"key\": \"ctrl+.\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": {\n            \"snippet\": \" %>% \"\n         }\n    },\n    {\n        \"description\": \"help document\",\n        \"key\": \"ctrl+h\",\n        \"command\": \"r.runCommandWithSelectionOrWord\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": \"help($$)\"\n    },\n    {\n        \"description\": \"view table\",\n        \"key\": \"cmd+shift+u\",\n        \"command\": \"r.runCommandWithSelectionOrWord\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": \"DT::datatable($$)\"\n    },\n    {\n        \"description\": \"reopen figure panel if closed\",\n        \"key\": \"ctrl+alt+p\",\n        \"command\": \"r.runCommand\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": \".vsc.browser(httpgd::hgd_url(), viewer = \\\"Beside\\\")\"\n    },\n    {\n        \"description\": \"view object\",\n        \"key\": \"cmd+u\",\n        \"command\": \"r.runCommandWithSelectionOrWord\",\n        \"when\": \"editorTextFocus && editorLangId =~ /r|rmd/\",\n        \"args\": \"View($$)\"\n    }\n]{ \"keys\": [\"super+option+r\"], # put whatever you want here\n    \"command\": \"terminus_open\",\n    \"args\": {\n        \"post_window_hooks\": [\n            [\"carry_file_to_pane\", {\"direction\": \"right\"}]\n        ],\n        \"cmd\" : \"radian\"\n    }\n}"},{"path":"getting-ready.html","id":"in-any-case-install-latex","chapter":"3 Getting ready","heading":"3.3 In any case: install LaTeX","text":"full \\(\\LaTeX\\) distribution (emphasis full) needed knit markdown files PDFs (don’t need output html files though):Windows: go download Net Installer install complete distributionMac: go type brew cask install mactex terminal Homebrew installedLinux: fore exampleAlternatively, can also work TinyTeX install needed packages fly. recommended knitr package help, problems , recommend full \\(\\LaTeX\\) distribution option don’t mind taking gigabytes disk. , just run R console:uninstall TinyTeX, run:","code":"\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\ntinytex::uninstall_tinytex()"},{"path":"getting-ready.html","id":"working-in-rstudio","chapter":"3 Getting ready","heading":"3.4 Working in Rstudio","text":"Remember: Always Work Projects!!Launch Rstudio, click File > New Project, follow dialog box (existing directory , etc.). several ongoing projects, can switch using Project navigator (see Fig. 3.1).\nFigure 3.1: Rstudio interface.\ngreat interest working Projects default working directory relative root directory Project. words, store data Data folder, can read running read_function(\"Data/your_file.txt\"). one fundamentals reproducible data treatment :won’t write absolute path towards file, like read_function(\"C://path//your_file.txt\"), path unlikely depending computer located . helps share whole project folder others, just move around computer still working code.won’t start script setwd(\"/path///data\") command (set working directory), much better reasons .Write whatever want “Source code” panel save .R (.Rmd) file, run selecting hitting ⌘+⏎ (Ctrl+⏎ Windows, Linux). text selected, hitting ⌘+⏎ launch current line. can see file contents project project’s file explorer (see bottom right corner Fig. 3.1).code output seen “R Console” panel ’s text, “Graph” panel ’s graph. list defined variables functions available “Environment” panel. can also directly write run code “R Console” panel, ’s code don’t care save script (like installing package whatever).can install packages running install.packages(\"package_name\") command R console R script, can also click “Packages” tab bottom right corner, “Install” “Update” case want install update packages. “Update” show list installed packages new published version. verified packages located CRAN (Comprehensive R Archive Network). thus really easy install packages maintain (update) packages R. also possibility install packages source want install custom packages – “homemade” packages didn’t go CRAN verification process: risks.Rstudio cheatsheet.","code":""},{"path":"getting-ready.html","id":"setting-up-the-environment","chapter":"3 Getting ready","heading":"3.5 Setting up the environment","text":"Make sure following packages installed launching following commands: copy-paste “Source code” panel (upper left crated new R script), select lines hit Ctrl+⏎ (Windows, Linux) ⌘+⏎ (Mac). main packages use class:Later , package can loaded calling:checking “Graphs” panel “Packages” tab.\nwant access function given package without loading (several packages define function want specify one use), type:want access documentation given package, click link package “Packages” tab.\ngeneral way, help function accessed typing ?function_name, help appearing “Graph” panel.","code":"\ninstall.packages(\"devtools\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"rmarkdown\")\ninstall.packages(\"knitr\")\ninstall.packages(\"shiny\")\ninstall.packages(\"patchwork\")\ninstall.packages(\"plotly\")\ninstall.packages(\"quantities\")\ninstall.packages(\"minpack.lm\")\ninstall.packages(\"tikzDevice\")\ninstall.packages(\"ggforce\")library(package_name)package_name::function_name(parameters)"},{"path":"getting-ready.html","id":"the-tutor-package","chapter":"3 Getting ready","heading":"3.6 The tutor package","text":"Finally, also made interactive exercises bundled tutor package. let go follow instructions installing – get used going GitHub install packages find information .","code":""},{"path":"variables-booleans-and-strings.html","id":"variables-booleans-and-strings","chapter":"4 Variables, booleans and strings","heading":"4 Variables, booleans and strings","text":"R, variable attribution done arrow operator <- instead = one – historical reasons. equal sign, =, still work though, just take habit using <-.reality, scalar numbers don’t exist R, simply 1 element vector: [1] printed following outputs.understand encounter class, inputs (type R script hit Ctrl+⏎ (⌘+⏎)) shaded areas syntax coloring, outputs (R returns) shaded underneath starting ## [1]. case output spans several lines, line start ## [x] x index first element printed line.Note different instructions usually given separated lines (.e. one instruction per line), several instructions can written single line separated ; sign.R code, written “#” sign comment thus interpreted.","code":""},{"path":"variables-booleans-and-strings.html","id":"scalars-and-booleans","chapter":"4 Variables, booleans and strings","heading":"4.1 Scalars and booleans","text":"Defining scalar value done :can use R console advanced calculator:Attention: typing x + 1 print result x + 1, add 1 x save new value x. actually modify x, type x <- x + 1.","code":"\nx <- 1 # attribute the value '1' to the variable 'x'\nx      # print the value of 'x'## [1] 1\n1 + 3## [1] 4\nx <- 1/2\ny <- exp(log(sin(cos(x*pi))))\nx - y## [1] 0.5"},{"path":"variables-booleans-and-strings.html","id":"special-values","chapter":"4 Variables, booleans and strings","heading":"4.1.1 Special values","text":"R handles infinity, NaN, \\(\\pi\\) defined. Missing numbers handled NA keyword.","code":"\npi## [1] 3.141593\n10/0## [1] Inf\n0/0## [1] NaN\nNA## [1] NA"},{"path":"variables-booleans-and-strings.html","id":"booleans-and-common-tests-on-values","chapter":"4 Variables, booleans and strings","heading":"4.1.2 Booleans and common tests on values","text":"Booleans handled TRUE FALSE keywords, usually obtained result test values. Let’s us create two variables x y:now let’s test assertions two variables:x equal y?x equal y?x smaller y?x smaller equal y?Operator “”Operator “”x NaN?x NA?Operator “” (inverse)number can converted boolean using .logical(): number non 0 equivalent TRUE, 0 FALSE.R also natively handles complex values:","code":"\nx <- 1\ny <- 2\nx == y## [1] FALSE\nx != y## [1] TRUE\nx < y ## [1] TRUE\nx <= y## [1] TRUE\nx == y & x < y ## [1] FALSE\nx == y | x < y ## [1] TRUE\nis.nan(x)## [1] FALSE\nis.na(x)## [1] FALSE\n!is.na(x)## [1] TRUE\nas.logical(1)## [1] TRUE\nas.logical(0)## [1] FALSE\n1+i   # not a valid complex value## Error in eval(expr, envir, enclos): object 'i' not found\n1+1i  # valid complex value## [1] 1+1i\nexp(1i*pi)## [1] -1+0i\nsqrt(-1)## Warning in sqrt(-1): NaNs produced## [1] NaN\nsqrt(-1 + 0i)## [1] 0+1i\nIm(exp(1i*pi))## [1] 1.224647e-16"},{"path":"variables-booleans-and-strings.html","id":"strings","chapter":"4 Variables, booleans and strings","heading":"4.2 Strings","text":"string defined quotation marks : \"string\". Thus \"1\" number 1, rather character “1”. operations strings :Definition string:Concatenation strings using paste():Acessing sub-string:Change case string tolower() toupper():Change first occurrence “o” “” sub():Change occurrences “o” “” gsub():Trim white spaces trimws():Get vector string separation based character strsplit():Attention!!complex operations, see stringr package cheatsheet.","code":"\nphrase <- \"Hello World \" \npaste(\"phrase\", phrase, sep=\" = \")## [1] \"phrase = Hello World \"\nsubstr(phrase, 1, 4)## [1] \"Hell\"\ntolower(phrase); toupper(phrase)## [1] \"hello world \"## [1] \"HELLO WORLD \"\nsub(\"o\", \"a\", phrase)## [1] \"Hella World \"\ngsub(\"o\", \"a\", phrase)## [1] \"Hella Warld \"\ntrimws(phrase)## [1] \"Hello World\"\nstrsplit(phrase, \" \")         # returns a list## [[1]]\n## [1] \"Hello\" \"World\"\nunlist(strsplit(phrase, \" \")) # returns a vector## [1] \"Hello\" \"World\"\nphrase2 <- \"1234\"\nphrase2 - 4321             # won't work: string - double## Error in phrase2 - 4321: non-numeric argument to binary operator\nas.numeric(phrase2) - 4321 # conversion of string to double## [1] -3087"},{"path":"variables-booleans-and-strings.html","id":"exo-variables","chapter":"4 Variables, booleans and strings","heading":"4.3 Exercises","text":"Interactive exercises can found tutor package. , simply run:","code":"\nlibrary(tutor)\ntuto(\"variables\")"},{"path":"vectors.html","id":"vectors","chapter":"5 Vectors","heading":"5 Vectors","text":"R vectorized language built-arithmetic relational operators, mathematical functions types number. means mathematical function operator works set data rather single scalar value traditional computer language , thus formal looping can usually avoided.","code":""},{"path":"vectors.html","id":"different-ways-of-defining-a-vector","chapter":"5 Vectors","heading":"5.1 Different ways of defining a vector","text":"want define vector specifying values, use function c(), like :, x vector doubles:, x converted vector strings contains string:define sequence increasing numbers, either use notation start:end sequence going start end step 1, use seq() function versatile:repeat values, use rep() function:create vectors random numbers, use rnorm() runif() normally uniformly distributed numbers, respectively:","code":"\nx <- c(1, 5, 3, 12, 4.2)\nx## [1]  1.0  5.0  3.0 12.0  4.2\nx <- c(1, 5, 3, \"hello\")\nx## [1] \"1\"     \"5\"     \"3\"     \"hello\"\n1:10##  [1]  1  2  3  4  5  6  7  8  9 10\nseq(-10, 10, by = .5)##  [1] -10.0  -9.5  -9.0  -8.5  -8.0  -7.5  -7.0  -6.5  -6.0  -5.5  -5.0  -4.5\n## [13]  -4.0  -3.5  -3.0  -2.5  -2.0  -1.5  -1.0  -0.5   0.0   0.5   1.0   1.5\n## [25]   2.0   2.5   3.0   3.5   4.0   4.5   5.0   5.5   6.0   6.5   7.0   7.5\n## [37]   8.0   8.5   9.0   9.5  10.0\nseq(-10, 10, length = 6)## [1] -10  -6  -2   2   6  10\nseq(-10, 10, along = x)## [1] -10.000000  -3.333333   3.333333  10.000000\nrep(0, 10)##  [1] 0 0 0 0 0 0 0 0 0 0\nrep(c(0, 2), 5)##  [1] 0 2 0 2 0 2 0 2 0 2\nrep(c(0, 2), each = 5)##  [1] 0 0 0 0 0 2 2 2 2 2\n# vector with 10 random values normally distributed around mean \n# with given standard deviation `sd`\nrnorm(10, mean=3, sd=1)##  [1] 1.565174 3.758116 4.279674 2.251153 3.063083 2.926550 2.206959 5.326735\n##  [9] 4.511474 1.537023\n# vector with 10 random values uniformly distributed between min and max\nrunif(10, min = 0, max = 1)##  [1] 0.9711622 0.9624766 0.7473447 0.3020470 0.8816950 0.1469064 0.2017330\n##  [8] 0.5588173 0.9354968 0.3516889"},{"path":"vectors.html","id":"numerical-and-categorical-data-types","chapter":"5 Vectors","heading":"5.2 Numerical and categorical data types","text":"Data can two different types: numerical, categorical. Let’s say measuring temperature room recording value time:T1 vector containing numerical data.Let’s say now recording temperature level, can low, high mediumT2 vector containing categorical data, .e. data example can fall either 3 categories. now, T2 however vector strings, need tell R contains categorical data using function factor():see now 3 levels, numerization T2 leads obtaining numbers 1, 2 3 according levels T2:Numerical data can converted factors way – can useful sometimes, e.g. plotting ggplot see later:","code":"\nT1 <- c(22.3, 23.5, 26.0, 30.2)\nT2 <- c(\"low\", \"low\", \"medium\", \"high\")\nT2 <- factor(T2)\nT2## [1] low    low    medium high  \n## Levels: high low medium\nas.numeric(T2)## [1] 2 2 3 1\nfactor(T1)## [1] 22.3 23.5 26   30.2\n## Levels: 22.3 23.5 26 30.2"},{"path":"vectors.html","id":"principal-operations-on-vectors","chapter":"5 Vectors","heading":"5.3 Principal operations on vectors","text":"","code":""},{"path":"vectors.html","id":"mathematical-operations","chapter":"5 Vectors","heading":"5.3.1 Mathematical operations","text":"R vectorized language, don’t need loop elements vector perform element-wise operations . Let’s say x <- 1:6, :Addition value elements:Multiplication / division elements:Integer division:Math functions apply elements:Power:Multiplication vectors size performed element element:Multiplication vectors different sizes: smaller vector automatically repeated number times needed get vector size larger one. work also longer object length multiple shorter object length, shorter object truncated ’ll get error:Modulo:Outer product vectors (result matrix):","code":"\nx + 2.5## [1] 3.5 4.5 5.5 6.5 7.5 8.5\nx*2## [1]  2  4  6  8 10 12\nx %/% 3## [1] 0 0 1 1 1 2\nsqrt(abs(cos(x)))## [1] 0.7350526 0.6450944 0.9949837 0.8084823 0.5325995 0.9798828\nx^2.5## [1]  1.000000  5.656854 15.588457 32.000000 55.901699 88.181631\ny <- c(2.3, 5, 7, 10, 12, 20)\nx*y## [1]   2.3  10.0  21.0  40.0  60.0 120.0\nx*1:2## [1]  1  4  3  8  5 12\nx*1:4## Warning in x * 1:4: longer object length is not a multiple of shorter object\n## length## [1]  1  4  9 16  5 12\nx %% 2## [1] 1 0 1 0 1 0\nx %o% y##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]  2.3    5    7   10   12   20\n## [2,]  4.6   10   14   20   24   40\n## [3,]  6.9   15   21   30   36   60\n## [4,]  9.2   20   28   40   48   80\n## [5,] 11.5   25   35   50   60  100\n## [6,] 13.8   30   42   60   72  120"},{"path":"vectors.html","id":"accessing-values","chapter":"5 Vectors","heading":"5.3.2 Accessing values","text":"Let’s work vector x:","code":"\nx <- c(5, 3, 4, 9, 3)"},{"path":"vectors.html","id":"accessing-values-by-index","chapter":"5 Vectors","heading":"5.3.2.1 Accessing values by index","text":"access values vector x, use x[] notation, index want access. can (fact, always) vector.Attention: R, indexes numbering start 1 !!!remove elements j vector x, use notation x[-j]:Writing x[-c(1,3)] just print result x[-c(1,3)], actually modify x. really modify x, ’d need write x <- x[-c(1,3)].","code":"\n# accessing by indexes\nx[3]## [1] 4\n# access index 1, 5 and 2\nx[c(1,5,2)] ## [1] 5 3 3\n# remove elements 1 and 3\nx[-c(1,3)]## [1] 3 9 3"},{"path":"vectors.html","id":"filtering-values-with-tests","chapter":"5 Vectors","heading":"5.3.2.2 Filtering values with tests","text":"can access values booleans. Values getting TRUE kept, values FALSE discarded:Therefore, can apply tests values filter easily:","code":"\nx[c(TRUE,TRUE,TRUE,FALSE,TRUE,TRUE)]## [1]  5  3  4  3 NA\nx > 4 # is a vector of booleans## [1]  TRUE FALSE FALSE  TRUE FALSE\nx[x > 4] # is a filtered vector## [1] 5 9"},{"path":"vectors.html","id":"accessing-values-by-name","chapter":"5 Vectors","heading":"5.3.2.3 Accessing values by name","text":"Finally, values vectors can named, thus can accessed name:can access names vector using names():","code":"\ny <- c(age=32, name=\"John\", pet=\"Cat\")\ny##    age   name    pet \n##   \"32\" \"John\"  \"Cat\"\ny[c('age','pet')] # prints a named vector##   age   pet \n##  \"32\" \"Cat\"\ny[['name']] # prints an un-named vector## [1] \"John\"\nnames(y)## [1] \"age\"  \"name\" \"pet\""},{"path":"vectors.html","id":"sorting-removing-duplicates-sampling","chapter":"5 Vectors","heading":"5.3.3 Sorting, removing duplicates, sampling","text":"Sorting ascending number:works strings , gtools::mixedsort() might needed strings mixing letters numbers:Sorting descending number:Inverting order vector:Find order indexes sorting:Find duplicates:Remove duplicates:Choose 3 random values:","code":"\nsort(x)## [1] 3 3 4 5 9\nsort(c(\"c\",\"a\",\"d\",\"ab\")) ## [1] \"a\"  \"ab\" \"c\"  \"d\"\nsort(c(\"c\", \"a10\", \"a2\", \"d\", \"ab\"))## [1] \"a10\" \"a2\"  \"ab\"  \"c\"   \"d\"\ngtools::mixedsort(c(\"c\", \"a10\", \"a2\", \"d\", \"ab\"))## [1] \"a2\"  \"a10\" \"ab\"  \"c\"   \"d\"\nsort(x, decreasing = TRUE) ## [1] 9 5 4 3 3\nrev(x)## [1] 3 9 4 3 5\norder(x)## [1] 2 5 3 1 4\nx[order(x)] # is thus equivalent to `sort(x)`## [1] 3 3 4 5 9\nduplicated(x)## [1] FALSE FALSE FALSE FALSE  TRUE\nunique(x)## [1] 5 3 4 9\nsample(x, 3)## [1] 3 9 4"},{"path":"vectors.html","id":"maximum-and-minimum","chapter":"5 Vectors","heading":"5.3.4 Maximum and minimum","text":"quite straightforward:","code":"\n# maximum of x and its index\nx; max(x); which.max(x) ## [1] 5 3 4 9 3## [1] 9## [1] 4\n# minimum of x and its index\nx; min(x); which.min(x)## [1] 5 3 4 9 3## [1] 3## [1] 2\n# range of a vector\nrange(x)## [1] 3 9"},{"path":"vectors.html","id":"characteristics-of-vectors","chapter":"5 Vectors","heading":"5.3.5 Characteristics of vectors","text":"Size vector:Statistics vector:Sum terms:Average value:Median value:Standard deviation:Count occurrence values:Cumulative sum:Term--term difference","code":"\nlength(x)## [1] 5\nsummary(x)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##     3.0     3.0     4.0     4.8     5.0     9.0\nsum(x)## [1] 24\nmean(x)## [1] 4.8\nmedian(x)## [1] 4\nsd(x)## [1] 2.48998\ntable(x)## x\n## 3 4 5 9 \n## 2 1 1 1\ncumsum(x)## [1]  5  8 12 21 24\ndiff(x)## [1] -2  1  5 -6"},{"path":"vectors.html","id":"concatenation-of-vectors","chapter":"5 Vectors","heading":"5.3.6 Concatenation of vectors","text":"done using c() notation: basically create vector vectors, result new vector:Another option use append() function allows options:","code":"\n# concatenate vectors\nz <- c(-1:4, NA, -x); z##  [1] -1  0  1  2  3  4 NA -5 -3 -4 -9 -3\n# append values\nappend(x, 4)    # at the end## [1] 5 3 4 9 3 4\nappend(x, 4:1, 3) # or after a given index## [1] 5 3 4 4 3 2 1 9 3"},{"path":"vectors.html","id":"exo-vectors","chapter":"5 Vectors","heading":"5.4 Exercises","text":"Interactive exercises can found tutor package. , simply run:Let’s create named vector containing age students class, names value first name students. :Compute average age standard deviationCompute median ageWhat maximum, minimum range ages class?student names class?Print sorted ages increasing decreasing orderPrint ages sorted alphabetically ordered names (increasing decreasing)Show histogram ages distribution using hist() play parameter breaks modify histogramShow boxplot ages distribution using boxplot()exercise adapted .Open Rstudio create new R script, save population.R wanted directory, say Rcourse/.Download population.csv file save working directory.csv file contains raw data stored plain text separated comma (Comma Separated Values). Open Rstudio.can course directly load file R store data appropriate format (.e. data.frame), next chapter. now, just copy-paste text Rstudio script area :Create cities vector containing cities listed population.csvCreate pop_1962 pop_2012 vectors containing populations city years. Print 2 vectors.Use names() name values pop_1962 pop_2012. Print 2 vectors . change?cities 200000 people 1962? , many residents 2012?population evolution Montpellier Nantes?Create pop_diff vector store population change 1962 2012Print cities negative changePrint cities broke 300000 people barrier 1962 2012Compute total change population 10 largest cities (1962) 1962 2012.Compute population mean year 1962Compute population mean Paris two yearsSort cities decreasing order population 1962","code":"\nlibrary(tutor)\ntuto(\"vectors\")\n# Create a `cities` vector containing all the cities listed in `population.csv`\ncities <- c(\"Angers\", \"Bordeaux\", \"Brest\", \"Dijon\", \"Grenoble\", \"Le Havre\", \n            \"Le Mans\", \"Lille\", \"Lyon\", \"Marseille\", \"Montpellier\", \"Nantes\", \n            \"Nice\", \"Paris\", \"Reims\", \"Rennes\", \"Saint-Etienne\", \"Strasbourg\", \n            \"Toulon\", \"Toulouse\")\n# Create a `pop_1962` and `pop_2012` vectors containing the populations \n# of each city at these years. Print the 2 vectors. \npop_1962 <- c(115273,278403,136104,135694,156707,187845,132181,239955,\n              535746,778071,118864,240048,292958,2790091,134856,151948,\n              210311,228971,161797,323724)\npop_2012 <- c(149017,241287,139676,152071,158346,173142,143599,228652,\n              496343,852516,268456,291604,343629,2240621,181893,209860,\n              171483,274394,164899,453317)\npop_1962; pop_2012##  [1]  115273  278403  136104  135694  156707  187845  132181  239955  535746\n## [10]  778071  118864  240048  292958 2790091  134856  151948  210311  228971\n## [19]  161797  323724##  [1]  149017  241287  139676  152071  158346  173142  143599  228652  496343\n## [10]  852516  268456  291604  343629 2240621  181893  209860  171483  274394\n## [19]  164899  453317\n# Use names() to name values of `pop_1962` and `pop_2012`. \n# Print the 2 vectors again. Are there any change?\nnames(pop_2012) <- names(pop_1962) <- cities\npop_1962; pop_2012##        Angers      Bordeaux         Brest         Dijon      Grenoble \n##        115273        278403        136104        135694        156707 \n##      Le Havre       Le Mans         Lille          Lyon     Marseille \n##        187845        132181        239955        535746        778071 \n##   Montpellier        Nantes          Nice         Paris         Reims \n##        118864        240048        292958       2790091        134856 \n##        Rennes Saint-Etienne    Strasbourg        Toulon      Toulouse \n##        151948        210311        228971        161797        323724##        Angers      Bordeaux         Brest         Dijon      Grenoble \n##        149017        241287        139676        152071        158346 \n##      Le Havre       Le Mans         Lille          Lyon     Marseille \n##        173142        143599        228652        496343        852516 \n##   Montpellier        Nantes          Nice         Paris         Reims \n##        268456        291604        343629       2240621        181893 \n##        Rennes Saint-Etienne    Strasbourg        Toulon      Toulouse \n##        209860        171483        274394        164899        453317\n# What are the cities with more than 200000 people in 1962? \n# For these, how many residents in 2012?\ncities200k <- cities[pop_1962>200000]\ncities200k; pop_2012[cities200k]##  [1] \"Bordeaux\"      \"Lille\"         \"Lyon\"          \"Marseille\"    \n##  [5] \"Nantes\"        \"Nice\"          \"Paris\"         \"Saint-Etienne\"\n##  [9] \"Strasbourg\"    \"Toulouse\"##      Bordeaux         Lille          Lyon     Marseille        Nantes \n##        241287        228652        496343        852516        291604 \n##          Nice         Paris Saint-Etienne    Strasbourg      Toulouse \n##        343629       2240621        171483        274394        453317\n# What is the population evolution of Montpellier and Nantes?\npop_2012['Montpellier'] - pop_1962['Montpellier']; pop_2012['Nantes'] - pop_1962['Nantes']## Montpellier \n##      149592## Nantes \n##  51556\n# Create a `pop_diff` vector to store population change between 1962 and 2012\npop_diff <- pop_2012 - pop_1962\n# Print cities with a negative change\ncities[pop_diff<0]## [1] \"Bordeaux\"      \"Le Havre\"      \"Lille\"         \"Lyon\"         \n## [5] \"Paris\"         \"Saint-Etienne\"\n# Print cities which broke the 300000 people barrier between 1962 and 2012\ncities[pop_2012>300000 & pop_1962<300000]## [1] \"Nice\"\n# Compute the total change in population of the 10 largest cities\n# (as of 1962) between 1962 and 2012.\nten_largest <- cities[order(pop_1962, decreasing = TRUE)[1:10]]\nsum(pop_2012[ten_largest] - pop_1962[ten_largest])## [1] -324432\n# Compute the population mean for year 1962\nmean(pop_1962)## [1] 367477.3\n# Compute the population mean of Paris\nmean(c(pop_1962['Paris'], pop_2012['Paris']))## [1] 2515356\n# Sort the cities by decreasing order of population for 1962\n(pop_1962_sorted <- sort(pop_1962, decreasing = TRUE))##         Paris     Marseille          Lyon      Toulouse          Nice \n##       2790091        778071        535746        323724        292958 \n##      Bordeaux        Nantes         Lille    Strasbourg Saint-Etienne \n##        278403        240048        239955        228971        210311 \n##      Le Havre        Toulon      Grenoble        Rennes         Brest \n##        187845        161797        156707        151948        136104 \n##         Dijon         Reims       Le Mans   Montpellier        Angers \n##        135694        134856        132181        118864        115273"},{"path":"data-frames.html","id":"data-frames","chapter":"6 Data frames","heading":"6 Data frames","text":"","code":""},{"path":"data-frames.html","id":"defining-a-data.frame","chapter":"6 Data frames","heading":"6.1 Defining a data.frame","text":"","code":""},{"path":"data-frames.html","id":"defining-a-data.frame-from-vectors","chapter":"6 Data frames","heading":"6.1.1 Defining a data.frame from vectors","text":"R, principal object data. Hence data.frame object, basically table vectors. data.frame list presented form table – .e. spreadsheet. day--day basis, either define data.frame existing vectors data.frame, define data.frame file (text, Excel…). example, use test.dat test.xlsx.define data.frame known vectors, just :information table readily accessible, like:dimension, number rows columns:Print first last 3 valuesPrint information dfPrint statistics dfIf defined creating data.frame, column names default vector names. specify column names, creating data.frame:, ’s created, using names()","code":"\nx  <- seq(-pi, pi, length = 6) \ny  <- sin(x)\ndf <- data.frame(x, y) # df is a data.frame (a table)\ndf##            x             y\n## 1 -3.1415927 -1.224647e-16\n## 2 -1.8849556 -9.510565e-01\n## 3 -0.6283185 -5.877853e-01\n## 4  0.6283185  5.877853e-01\n## 5  1.8849556  9.510565e-01\n## 6  3.1415927  1.224647e-16\ndim(df); nrow(df); ncol(df)## [1] 6 2## [1] 6## [1] 2\nhead(df, 3); tail(df, 3)##            x             y\n## 1 -3.1415927 -1.224647e-16\n## 2 -1.8849556 -9.510565e-01\n## 3 -0.6283185 -5.877853e-01##           x            y\n## 4 0.6283185 5.877853e-01\n## 5 1.8849556 9.510565e-01\n## 6 3.1415927 1.224647e-16\nstr(df)## 'data.frame':    6 obs. of  2 variables:\n##  $ x: num  -3.142 -1.885 -0.628 0.628 1.885 ...\n##  $ y: num  -1.22e-16 -9.51e-01 -5.88e-01 5.88e-01 9.51e-01 ...\nsummary(df)##        x                y          \n##  Min.   :-3.142   Min.   :-0.9511  \n##  1st Qu.:-1.571   1st Qu.:-0.4408  \n##  Median : 0.000   Median : 0.0000  \n##  Mean   : 0.000   Mean   : 0.0000  \n##  3rd Qu.: 1.571   3rd Qu.: 0.4408  \n##  Max.   : 3.142   Max.   : 0.9511\ndf <- data.frame(xxx = x, yyy = y)\nhead(df, 2)##         xxx           yyy\n## 1 -3.141593 -1.224647e-16\n## 2 -1.884956 -9.510565e-01\nnames(df)## [1] \"xxx\" \"yyy\"\nnames(df) <- c(\"X\", \"Y\")\nhead(df, 2)##           X             Y\n## 1 -3.141593 -1.224647e-16\n## 2 -1.884956 -9.510565e-01"},{"path":"data-frames.html","id":"defining-a-data.frame-from-a-file","chapter":"6 Data frames","heading":"6.1.2 Defining a data.frame from a file","text":"Let’s say test.dat looks like :, read file data.frame, use read.table(). don’t specify file contains header, read.table() default attributing column names V1, V2, V3, etc:file contains column names, use first line column names like :want skip lines starting reading, use skip:can specify column names using col.names:can type ?read.table options.can type ?read.table options.Now, read Excel file, use readxl library:Now, read Excel file, use readxl library:","code":"# Bash code:\nhead Data/test.dat## x   y\n## 1   2\n## 2   3\nread.table(\"Data/test.dat\")##   V1 V2\n## 1  x  y\n## 2  1  2\n## 3  2  3\nread.table(\"Data/test.dat\", header=TRUE)##   x y\n## 1 1 2\n## 2 2 3\nread.table(\"Data/test.dat\", skip=1)##   V1 V2\n## 1  1  2\n## 2  2  3\nread.table(\"Data/test.dat\", skip=1, col.names = c(\"A\",\"B\"))##   A B\n## 1 1 2\n## 2 2 3\nlibrary(readxl) # load readxl from tidyverse to read Excel files\nread_excel(\"Data/test.xlsx\", sheet=1)## # A tibble: 10 × 2\n##        x      y\n##    <dbl>  <dbl>\n##  1     1  5.21 \n##  2     2  6.55 \n##  3     3  3.71 \n##  4     4  0.216\n##  5     5  0.205\n##  6     6  4.60 \n##  7     7 10.3  \n##  8     8 12.9  \n##  9     9 11.1  \n## 10    10  7.28\nread_excel(\"Data/test.xlsx\", sheet=2)## # A tibble: 4 × 2\n##   hello  world   \n##   <chr>  <chr>   \n## 1 ac     th      \n## 2 asc    thh     \n## 3 ascsa  dthdh   \n## 4 ascacs dthtdhdh"},{"path":"data-frames.html","id":"accessing-values-1","chapter":"6 Data frames","heading":"6.2 Accessing values","text":"Like vectors, accessing values done using [] notation, except two indexes: df[row, column]:general however, want access given column, index:, preferably, name using $ notation:Finally, may want apply filters table:Using function subset(), conditions applied column names (need df$col_name , need expression):","code":"\ndf[3,1]## [1] -0.6283185\ndf[,1]## [1] -3.1415927 -1.8849556 -0.6283185  0.6283185  1.8849556  3.1415927\ndf[[1]]# this is a vector too## [1] -3.1415927 -1.8849556 -0.6283185  0.6283185  1.8849556  3.1415927\ndf$X## [1] -3.1415927 -1.8849556 -0.6283185  0.6283185  1.8849556  3.1415927\ndf[df$X < 0, ]##            X             Y\n## 1 -3.1415927 -1.224647e-16\n## 2 -1.8849556 -9.510565e-01\n## 3 -0.6283185 -5.877853e-01\nsubset(df, X>1)##          X            Y\n## 5 1.884956 9.510565e-01\n## 6 3.141593 1.224647e-16\nsubset(df, X>1, select = c(X))##          X\n## 5 1.884956\n## 6 3.141593"},{"path":"data-frames.html","id":"adding-columns-or-rows","chapter":"6 Data frames","heading":"6.3 Adding columns or rows","text":"","code":""},{"path":"data-frames.html","id":"adding-columns","chapter":"6 Data frames","heading":"6.3.1 Adding columns","text":"add column, just attribute value column exist yet, created:can also create data.frame data.frame:Finally, can use cbind() function bind two data.frame column-wise:","code":"\n# Adding columns\ndf   <- data.frame(x,y)\ndf$z <- df$x^2\ndf##            x             y         z\n## 1 -3.1415927 -1.224647e-16 9.8696044\n## 2 -1.8849556 -9.510565e-01 3.5530576\n## 3 -0.6283185 -5.877853e-01 0.3947842\n## 4  0.6283185  5.877853e-01 0.3947842\n## 5  1.8849556  9.510565e-01 3.5530576\n## 6  3.1415927  1.224647e-16 9.8696044\ndata.frame(df, z=df$x^2, u=cos(df$x))##            x             y         z       z.1         u\n## 1 -3.1415927 -1.224647e-16 9.8696044 9.8696044 -1.000000\n## 2 -1.8849556 -9.510565e-01 3.5530576 3.5530576 -0.309017\n## 3 -0.6283185 -5.877853e-01 0.3947842 0.3947842  0.809017\n## 4  0.6283185  5.877853e-01 0.3947842 0.3947842  0.809017\n## 5  1.8849556  9.510565e-01 3.5530576 3.5530576 -0.309017\n## 6  3.1415927  1.224647e-16 9.8696044 9.8696044 -1.000000\ndf2 <- data.frame(a = 1:length(x), b = 1:length(x))\ncbind(df, df2)##            x             y         z a b\n## 1 -3.1415927 -1.224647e-16 9.8696044 1 1\n## 2 -1.8849556 -9.510565e-01 3.5530576 2 2\n## 3 -0.6283185 -5.877853e-01 0.3947842 3 3\n## 4  0.6283185  5.877853e-01 0.3947842 4 4\n## 5  1.8849556  9.510565e-01 3.5530576 5 5\n## 6  3.1415927  1.224647e-16 9.8696044 6 6"},{"path":"data-frames.html","id":"adding-rows","chapter":"6 Data frames","heading":"6.3.2 Adding rows","text":", use rbind() function.Attention: two data.frame must number columns column names.","code":"\nrbind(df, df)##             x             y         z\n## 1  -3.1415927 -1.224647e-16 9.8696044\n## 2  -1.8849556 -9.510565e-01 3.5530576\n## 3  -0.6283185 -5.877853e-01 0.3947842\n## 4   0.6283185  5.877853e-01 0.3947842\n## 5   1.8849556  9.510565e-01 3.5530576\n## 6   3.1415927  1.224647e-16 9.8696044\n## 7  -3.1415927 -1.224647e-16 9.8696044\n## 8  -1.8849556 -9.510565e-01 3.5530576\n## 9  -0.6283185 -5.877853e-01 0.3947842\n## 10  0.6283185  5.877853e-01 0.3947842\n## 11  1.8849556  9.510565e-01 3.5530576\n## 12  3.1415927  1.224647e-16 9.8696044"},{"path":"data-frames.html","id":"deleting-rowscolumns","chapter":"6 Data frames","heading":"6.3.3 Deleting rows/columns","text":"works like vectors:","code":"\ndf[-1,]##            x             y         z\n## 2 -1.8849556 -9.510565e-01 3.5530576\n## 3 -0.6283185 -5.877853e-01 0.3947842\n## 4  0.6283185  5.877853e-01 0.3947842\n## 5  1.8849556  9.510565e-01 3.5530576\n## 6  3.1415927  1.224647e-16 9.8696044\ndf[,-1]##               y         z\n## 1 -1.224647e-16 9.8696044\n## 2 -9.510565e-01 3.5530576\n## 3 -5.877853e-01 0.3947842\n## 4  5.877853e-01 0.3947842\n## 5  9.510565e-01 3.5530576\n## 6  1.224647e-16 9.8696044"},{"path":"data-frames.html","id":"tidy-up","chapter":"6 Data frames","heading":"6.4 Tidy up!","text":"","code":""},{"path":"data-frames.html","id":"what-is-tidy-data","chapter":"6 Data frames","heading":"6.4.1 What is tidy data?","text":"good practice R tidy data. R follows set conventions makes one layout tabular data much easier work others. data easier work R follows three rules:variable data set placed columnEach observation placed rowEach value placed cell\nFigure 6.1: Illustration tidy data.\nData satisfies rules known tidy data: see thanks representation, 2D table can handle arbitrary number variables – avoids using multi-dimensional arrays multi-tab Excel documents. Note ’t matter value repeated column.example:can find information data import tidyness data-import cheatsheet tidyr package.","code":"\ndf <- read.csv(\"Data/population.csv\")\ndf # is not tidy##   year Angers Bordeaux  Brest  Dijon Grenoble LeHavre LeMans  Lille   Lyon\n## 1 1962 115273   278403 136104 135694   156707  187845 132181 239955 535746\n## 2 1968 128557   266662 154023 145357   161616  207150 143246 238554 527800\n## 3 1975 137591   223131 166826 151705   166037  217882 152285 219204 456716\n## 4 1982 136038   208159 156060 140942   156637  199388 147697 196705 413095\n## 5 1990 141404   210336 147956 146703   150758  195854 145502 198691 415487\n## 6 1999 151279   215363 149634 149867   153317  190905 146105 212597 445452\n## 7 2007 151108   235178 142722 151543   156793  179751 144164 225789 472330\n## 8 2012 149017   241287 139676 152071   158346  173142 143599 228652 496343\n##   Marseille Montpellier Nantes   Nice   Paris  Reims Rennes Saint.Etienne\n## 1    778071      118864 240048 292958 2790091 134856 151948        210311\n## 2    889029      161910 260244 322442 2590771 154534 180943        223223\n## 3    908600      191354 256693 344481 2299830 178381 198305        220181\n## 4    874436      197231 240539 337085 2176243 177234 194656        204955\n## 5    800550      207996 244995 342439 2152423 180620 197536        199396\n## 6    798430      225392 270251 342738 2125246 187206 206229        180210\n## 7    852395      253712 283025 348721 2193030 183500 207922        175318\n## 8    852516      268456 291604 343629 2240621 181893 209860        171483\n##   Strasbourg Toulon Toulouse\n## 1     228971 161797   323724\n## 2     249396 174746   370796\n## 3     253384 181801   373796\n## 4     248712 179423   347995\n## 5     252338 167619   358688\n## 6     264115 160639   390350\n## 7     272123 166537   439453\n## 8     274394 164899   453317\nlibrary(tidyr)\ndf <- pivot_longer(df, cols=-year, names_to=\"city\", values_to=\"pop\")\ndf #is tidy## # A tibble: 160 × 3\n##     year city         pop\n##    <int> <chr>      <int>\n##  1  1962 Angers    115273\n##  2  1962 Bordeaux  278403\n##  3  1962 Brest     136104\n##  4  1962 Dijon     135694\n##  5  1962 Grenoble  156707\n##  6  1962 LeHavre   187845\n##  7  1962 LeMans    132181\n##  8  1962 Lille     239955\n##  9  1962 Lyon      535746\n## 10  1962 Marseille 778071\n## # … with 150 more rows\n# is not tidy\npivot_wider(df, names_from=\"city\", values_from=\"pop\")## # A tibble: 8 × 21\n##    year Angers Bordeaux  Brest  Dijon Grenoble LeHavre LeMans  Lille   Lyon\n##   <int>  <int>    <int>  <int>  <int>    <int>   <int>  <int>  <int>  <int>\n## 1  1962 115273   278403 136104 135694   156707  187845 132181 239955 535746\n## 2  1968 128557   266662 154023 145357   161616  207150 143246 238554 527800\n## 3  1975 137591   223131 166826 151705   166037  217882 152285 219204 456716\n## 4  1982 136038   208159 156060 140942   156637  199388 147697 196705 413095\n## 5  1990 141404   210336 147956 146703   150758  195854 145502 198691 415487\n## 6  1999 151279   215363 149634 149867   153317  190905 146105 212597 445452\n## 7  2007 151108   235178 142722 151543   156793  179751 144164 225789 472330\n## 8  2012 149017   241287 139676 152071   158346  173142 143599 228652 496343\n## # … with 11 more variables: Marseille <int>, Montpellier <int>, Nantes <int>,\n## #   Nice <int>, Paris <int>, Reims <int>, Rennes <int>, Saint.Etienne <int>,\n## #   Strasbourg <int>, Toulon <int>, Toulouse <int>"},{"path":"data-frames.html","id":"tibbles","chapter":"6 Data frames","heading":"6.4.2 Tibbles","text":"tibble enhanced version data.frame provided tibble package (part tidyverse). main advantage tibble easier initialization nicer printing data.frame. Moreover, performance also enhanced reading files read_csv(), read_tsv(), read_table() read_delim() things read.xx() counterparts return tibble. Otherwise, handling basically .tibbles .Note initializing tibbles, construction iterative. means creating second column, one can refer first one created. ’t work data.frames.AttentionTibbles quite strict subsetting. [ always returns another tibble. Contrast data frame: sometimes [ returns data frame sometimes just returns vector:Unless want get tibble, recommend always using $ notation want get column vector avoid problems.Another interesting feature tibbles columns can contain vectors, like usual, also lists R objects like tibbles, nls() objects, etc. called “nesting”, can nest un-nest tibbles using explicit functions:","code":"\nlibrary(tidyverse)\ndata.frame(x=runif(1e3), y=cumsum(x))## Error in data.frame(x = runif(1000), y = cumsum(x)): object 'x' not found\ntib <- tibble(x=runif(1e3), y=cumsum(x))\ntib## # A tibble: 1,000 × 2\n##        x     y\n##    <dbl> <dbl>\n##  1 0.590 0.590\n##  2 0.929 1.52 \n##  3 0.462 1.98 \n##  4 0.395 2.38 \n##  5 0.449 2.83 \n##  6 0.553 3.38 \n##  7 0.188 3.57 \n##  8 0.488 4.06 \n##  9 0.686 4.74 \n## 10 0.817 5.56 \n## # … with 990 more rows\nhead(tib[[1]]) # is a vector## [1] 0.5902493 0.9292955 0.4618716 0.3951280 0.4486365 0.5533962\nhead(tib[,1])  # is a tibble## # A tibble: 6 × 1\n##       x\n##   <dbl>\n## 1 0.590\n## 2 0.929\n## 3 0.462\n## 4 0.395\n## 5 0.449\n## 6 0.553\ntib1 <- tibble(x=1:3, y=1:3)\ntib2 <- tibble(x=1:5, y=1:5)\ntib  <- tibble(number=1:2, data=list(tib1, tib2))\ntib## # A tibble: 2 × 2\n##   number data            \n##    <int> <list>          \n## 1      1 <tibble [3 × 2]>\n## 2      2 <tibble [5 × 2]>\ntib_unnested <- unnest(tib, data)\ntib_unnested## # A tibble: 8 × 3\n##   number     x     y\n##    <int> <int> <int>\n## 1      1     1     1\n## 2      1     2     2\n## 3      1     3     3\n## 4      2     1     1\n## 5      2     2     2\n## 6      2     3     3\n## 7      2     4     4\n## 8      2     5     5\ntib_unnested_renested <- nest(tib_unnested, data = c(number, y))\ntib_unnested_renested## # A tibble: 5 × 2\n##       x data            \n##   <int> <list>          \n## 1     1 <tibble [2 × 2]>\n## 2     2 <tibble [2 × 2]>\n## 3     3 <tibble [2 × 2]>\n## 4     4 <tibble [1 × 2]>\n## 5     5 <tibble [1 × 2]>\ntib_unnested_renested$data # The `data` column is a list## [[1]]\n## # A tibble: 2 × 2\n##   number     y\n##    <int> <int>\n## 1      1     1\n## 2      2     1\n## \n## [[2]]\n## # A tibble: 2 × 2\n##   number     y\n##    <int> <int>\n## 1      1     2\n## 2      2     2\n## \n## [[3]]\n## # A tibble: 2 × 2\n##   number     y\n##    <int> <int>\n## 1      1     3\n## 2      2     3\n## \n## [[4]]\n## # A tibble: 1 × 2\n##   number     y\n##    <int> <int>\n## 1      2     4\n## \n## [[5]]\n## # A tibble: 1 × 2\n##   number     y\n##    <int> <int>\n## 1      2     5"},{"path":"data-frames.html","id":"operations-in-the-tidyverse","chapter":"6 Data frames","heading":"6.5 Operations in the tidyverse","text":"end, base R tidyverse package provide many efficient functions perform tasks want perform recursively, thus allowing avoiding explicit loops.examples, find much . Take look cheatsheets tidyr dplyr, ’s really helpful.Let’s work tibble:","code":"\n# Let's create a random tibble\nlibrary(tidyverse)\nN <- 500\ndt <- tibble(x     = rep(runif(N,-1,1),3), \n             y     = runif(N*3,-1,1), \n             signx = ifelse(x>0,\"positive\",\"negative\"),\n             signy = ifelse(y>0,\"positive\",\"negative\")\n)\ndt## # A tibble: 1,500 × 4\n##         x       y signx    signy   \n##     <dbl>   <dbl> <chr>    <chr>   \n##  1 -0.430  0.785  negative positive\n##  2  0.417 -0.881  positive negative\n##  3  0.572 -0.0317 positive negative\n##  4 -0.730  0.897  negative positive\n##  5  0.715 -0.598  positive negative\n##  6  0.132  0.0621 positive positive\n##  7 -0.626  0.119  negative positive\n##  8 -0.828  0.728  negative positive\n##  9 -0.835  0.792  negative positive\n## 10  0.355  0.757  positive positive\n## # … with 1,490 more rows"},{"path":"data-frames.html","id":"the-pipe-operator","chapter":"6 Data frames","heading":"6.5.1 The pipe operator","text":"following, introduce pipe operator magrittr package: %>%.\noperator allows clear syntax successive operations, “left operator given first argument right”. thus good habit write operation separate line facilitate reading. particularly helpful performing multiple nested operations. example, summary(head(tail(dt),2)), hard read, translate :Note 4.1 version R introduced native pipe operator: |>. However, backward compatibility previous code still stick magrittr version %>%, ’s reason. Indeed, base R’s pipe, piped object can given first argument function right. also default behavior %>%, %>% allows retrieving piped object operator ..Silly example:","code":"\ndt %>% \n    tail() %>% \n    head(2) %>% \n    summary()\n\"Hello\" %>% gsub(\"o\", \"e\")## [1] \"e\"\n\"Hello\" %>% gsub(\"o\", \"e\", .)## [1] \"Helle\""},{"path":"data-frames.html","id":"sampling-data","chapter":"6 Data frames","heading":"6.5.2 Sampling data","text":"","code":"\ndt %>% slice(1:3)  # by index## # A tibble: 3 × 4\n##        x       y signx    signy   \n##    <dbl>   <dbl> <chr>    <chr>   \n## 1 -0.430  0.785  negative positive\n## 2  0.417 -0.881  positive negative\n## 3  0.572 -0.0317 positive negative\ndt %>% sample_n(3) # randomly## # A tibble: 3 × 4\n##        x        y signx    signy   \n##    <dbl>    <dbl> <chr>    <chr>   \n## 1 -0.430 -0.00247 negative negative\n## 2 -0.192 -0.799   negative negative\n## 3 -0.965 -0.377   negative negative"},{"path":"data-frames.html","id":"operations-on-groups-of-a-variable","chapter":"6 Data frames","heading":"6.5.3 Operations on groups of a variable","text":"group_by(column) groups similar values wanted column(s) performs next operations element group successively.","code":"\ndt %>% \n    group_by(signx) %>% \n    sample_n(3)## # A tibble: 6 × 4\n## # Groups:   signx [2]\n##        x       y signx    signy   \n##    <dbl>   <dbl> <chr>    <chr>   \n## 1 -0.402 -0.0811 negative negative\n## 2 -0.403  0.387  negative positive\n## 3 -0.760  0.434  negative positive\n## 4  0.316 -0.658  positive negative\n## 5  0.853  0.160  positive positive\n## 6  0.825 -0.285  positive negative\ndt %>% \n    group_by(signx, signy) %>% \n    sample_n(3)## # A tibble: 12 × 4\n## # Groups:   signx, signy [4]\n##          x      y signx    signy   \n##      <dbl>  <dbl> <chr>    <chr>   \n##  1 -0.514  -0.593 negative negative\n##  2 -0.752  -0.628 negative negative\n##  3 -0.788  -0.279 negative negative\n##  4 -0.717   0.689 negative positive\n##  5 -0.534   0.293 negative positive\n##  6 -0.775   0.876 negative positive\n##  7  0.566  -0.895 positive negative\n##  8  0.0665 -0.878 positive negative\n##  9  0.612  -0.483 positive negative\n## 10  0.0327  0.694 positive positive\n## 11  0.860   0.583 positive positive\n## 12  0.636   0.940 positive positive"},{"path":"data-frames.html","id":"summary-by-groups-of-a-variable","chapter":"6 Data frames","heading":"6.5.4 Summary by groups of a variable","text":"summarise() returns single value element groups.","code":"\ndt %>% \n    group_by(signx) %>% \n    summarise(count  = n(),\n              mean_x = mean(x), \n              sd_x   = sd(x))## # A tibble: 2 × 4\n##   signx    count mean_x  sd_x\n##   <chr>    <int>  <dbl> <dbl>\n## 1 negative   804 -0.498 0.292\n## 2 positive   696  0.538 0.287\ndt %>% \n    group_by(signx, signy) %>% \n    summarise(count  = n(),\n              mean_x = mean(x), \n              mean_y = mean(y))## # A tibble: 4 × 5\n## # Groups:   signx [2]\n##   signx    signy    count mean_x mean_y\n##   <chr>    <chr>    <int>  <dbl>  <dbl>\n## 1 negative negative   412 -0.498 -0.510\n## 2 negative positive   392 -0.497  0.497\n## 3 positive negative   340  0.530 -0.516\n## 4 positive positive   356  0.546  0.466"},{"path":"data-frames.html","id":"sorting","chapter":"6 Data frames","heading":"6.5.5 Sorting","text":"","code":"\ndt %>% arrange(x)## # A tibble: 1,500 × 4\n##         x       y signx    signy   \n##     <dbl>   <dbl> <chr>    <chr>   \n##  1 -0.999 -0.936  negative negative\n##  2 -0.999  0.251  negative positive\n##  3 -0.999 -0.779  negative negative\n##  4 -0.998 -0.921  negative negative\n##  5 -0.998 -0.0853 negative negative\n##  6 -0.998 -0.646  negative negative\n##  7 -0.991  0.0744 negative positive\n##  8 -0.991  0.805  negative positive\n##  9 -0.991  0.808  negative positive\n## 10 -0.988 -0.360  negative negative\n## # … with 1,490 more rows\ndt %>% arrange(x, desc(y))## # A tibble: 1,500 × 4\n##         x       y signx    signy   \n##     <dbl>   <dbl> <chr>    <chr>   \n##  1 -0.999  0.251  negative positive\n##  2 -0.999 -0.779  negative negative\n##  3 -0.999 -0.936  negative negative\n##  4 -0.998 -0.0853 negative negative\n##  5 -0.998 -0.646  negative negative\n##  6 -0.998 -0.921  negative negative\n##  7 -0.991  0.808  negative positive\n##  8 -0.991  0.805  negative positive\n##  9 -0.991  0.0744 negative positive\n## 10 -0.988  0.671  negative positive\n## # … with 1,490 more rows"},{"path":"data-frames.html","id":"merge-tables-column-wise","chapter":"6 Data frames","heading":"6.5.6 Merge tables column-wise","text":"least one column exact name must present table use xx_join() functions. possibilities inner_join() show , see help information.","code":"\ndt2 <- tibble(signx=c(\"positive\",\"positive\",\"negative\",\"negative\"), \n              signy=c(\"positive\",\"negative\",\"positive\",\"negative\"), \n              value=c(TRUE, FALSE, FALSE, TRUE))\ndt2## # A tibble: 4 × 3\n##   signx    signy    value\n##   <chr>    <chr>    <lgl>\n## 1 positive positive TRUE \n## 2 positive negative FALSE\n## 3 negative positive FALSE\n## 4 negative negative TRUE\ninner_join(dt, dt2)## # A tibble: 1,500 × 5\n##         x       y signx    signy    value\n##     <dbl>   <dbl> <chr>    <chr>    <lgl>\n##  1 -0.430  0.785  negative positive FALSE\n##  2  0.417 -0.881  positive negative FALSE\n##  3  0.572 -0.0317 positive negative FALSE\n##  4 -0.730  0.897  negative positive FALSE\n##  5  0.715 -0.598  positive negative FALSE\n##  6  0.132  0.0621 positive positive TRUE \n##  7 -0.626  0.119  negative positive FALSE\n##  8 -0.828  0.728  negative positive FALSE\n##  9 -0.835  0.792  negative positive FALSE\n## 10  0.355  0.757  positive positive TRUE \n## # … with 1,490 more rows"},{"path":"data-frames.html","id":"merge-tables-row-wise","chapter":"6 Data frames","heading":"6.5.7 Merge tables row-wise","text":"works even missing rows.","code":"\ndt3 <- tibble(a=1:3, b=3:5, c=6:8)\ndt4 <- tibble(a=3:1, c=3:5)\nbind_rows(dt3, dt4)## # A tibble: 6 × 3\n##       a     b     c\n##   <int> <int> <int>\n## 1     1     3     6\n## 2     2     4     7\n## 3     3     5     8\n## 4     3    NA     3\n## 5     2    NA     4\n## 6     1    NA     5"},{"path":"data-frames.html","id":"addmodify-a-column","chapter":"6 Data frames","heading":"6.5.8 Add/modify a column","text":"mutate(), like $, adds column doesn’t exist, modifies .","code":"\ndt %>% mutate(w=seq_along(x), z=sin(x))## # A tibble: 1,500 × 6\n##         x       y signx    signy        w      z\n##     <dbl>   <dbl> <chr>    <chr>    <int>  <dbl>\n##  1 -0.430  0.785  negative positive     1 -0.417\n##  2  0.417 -0.881  positive negative     2  0.405\n##  3  0.572 -0.0317 positive negative     3  0.541\n##  4 -0.730  0.897  negative positive     4 -0.667\n##  5  0.715 -0.598  positive negative     5  0.656\n##  6  0.132  0.0621 positive positive     6  0.132\n##  7 -0.626  0.119  negative positive     7 -0.586\n##  8 -0.828  0.728  negative positive     8 -0.737\n##  9 -0.835  0.792  negative positive     9 -0.741\n## 10  0.355  0.757  positive positive    10  0.348\n## # … with 1,490 more rows\ndt %>% mutate(x=seq_along(x))## # A tibble: 1,500 × 4\n##        x       y signx    signy   \n##    <int>   <dbl> <chr>    <chr>   \n##  1     1  0.785  negative positive\n##  2     2 -0.881  positive negative\n##  3     3 -0.0317 positive negative\n##  4     4  0.897  negative positive\n##  5     5 -0.598  positive negative\n##  6     6  0.0621 positive positive\n##  7     7  0.119  negative positive\n##  8     8  0.728  negative positive\n##  9     9  0.792  negative positive\n## 10    10  0.757  positive positive\n## # … with 1,490 more rows"},{"path":"data-frames.html","id":"selecting-columns","chapter":"6 Data frames","heading":"6.5.9 Selecting columns","text":"","code":"\ndt %>% select(x)  # only x## # A tibble: 1,500 × 1\n##         x\n##     <dbl>\n##  1 -0.430\n##  2  0.417\n##  3  0.572\n##  4 -0.730\n##  5  0.715\n##  6  0.132\n##  7 -0.626\n##  8 -0.828\n##  9 -0.835\n## 10  0.355\n## # … with 1,490 more rows\ndt %>% select(-x) # all but x## # A tibble: 1,500 × 3\n##          y signx    signy   \n##      <dbl> <chr>    <chr>   \n##  1  0.785  negative positive\n##  2 -0.881  positive negative\n##  3 -0.0317 positive negative\n##  4  0.897  negative positive\n##  5 -0.598  positive negative\n##  6  0.0621 positive positive\n##  7  0.119  negative positive\n##  8  0.728  negative positive\n##  9  0.792  negative positive\n## 10  0.757  positive positive\n## # … with 1,490 more rows\ndt %>% select(starts_with(\"sign\"))## # A tibble: 1,500 × 2\n##    signx    signy   \n##    <chr>    <chr>   \n##  1 negative positive\n##  2 positive negative\n##  3 positive negative\n##  4 negative positive\n##  5 positive negative\n##  6 positive positive\n##  7 negative positive\n##  8 negative positive\n##  9 negative positive\n## 10 positive positive\n## # … with 1,490 more rows\ndt %>% select(contains(\"x\"))## # A tibble: 1,500 × 2\n##         x signx   \n##     <dbl> <chr>   \n##  1 -0.430 negative\n##  2  0.417 positive\n##  3  0.572 positive\n##  4 -0.730 negative\n##  5  0.715 positive\n##  6  0.132 positive\n##  7 -0.626 negative\n##  8 -0.828 negative\n##  9 -0.835 negative\n## 10  0.355 positive\n## # … with 1,490 more rows"},{"path":"data-frames.html","id":"filtering-columns","chapter":"6 Data frames","heading":"6.5.10 Filtering columns","text":"","code":"\ndt %>% filter(signx==\"positive\")## # A tibble: 696 × 4\n##         x       y signx    signy   \n##     <dbl>   <dbl> <chr>    <chr>   \n##  1 0.417  -0.881  positive negative\n##  2 0.572  -0.0317 positive negative\n##  3 0.715  -0.598  positive negative\n##  4 0.132   0.0621 positive positive\n##  5 0.355   0.757  positive positive\n##  6 0.145   0.444  positive positive\n##  7 0.172   0.765  positive positive\n##  8 0.627  -0.0858 positive negative\n##  9 0.0242  0.643  positive positive\n## 10 0.271  -0.787  positive negative\n## # … with 686 more rows\ndt %>% filter(x<0, y>.1) # multiple filters can be applied at once## # A tibble: 345 × 4\n##         x     y signx    signy   \n##     <dbl> <dbl> <chr>    <chr>   \n##  1 -0.430 0.785 negative positive\n##  2 -0.730 0.897 negative positive\n##  3 -0.626 0.119 negative positive\n##  4 -0.828 0.728 negative positive\n##  5 -0.835 0.792 negative positive\n##  6 -0.825 0.742 negative positive\n##  7 -0.215 0.376 negative positive\n##  8 -0.713 0.925 negative positive\n##  9 -0.228 0.360 negative positive\n## 10 -0.717 0.689 negative positive\n## # … with 335 more rows"},{"path":"data-frames.html","id":"reorder-columns","chapter":"6 Data frames","heading":"6.5.11 Reorder columns","text":"","code":"\ndt %>% relocate(y, .after = signy)## # A tibble: 1,500 × 4\n##         x signx    signy          y\n##     <dbl> <chr>    <chr>      <dbl>\n##  1 -0.430 negative positive  0.785 \n##  2  0.417 positive negative -0.881 \n##  3  0.572 positive negative -0.0317\n##  4 -0.730 negative positive  0.897 \n##  5  0.715 positive negative -0.598 \n##  6  0.132 positive positive  0.0621\n##  7 -0.626 negative positive  0.119 \n##  8 -0.828 negative positive  0.728 \n##  9 -0.835 negative positive  0.792 \n## 10  0.355 positive positive  0.757 \n## # … with 1,490 more rows"},{"path":"data-frames.html","id":"separate-columns","chapter":"6 Data frames","heading":"6.5.12 Separate columns","text":"separation based standard separators “-”, “_”, “.”, \" \", etc. single separator can specified argument sep, otherwise separators used. One must provide resulting vector new column names: one value NA, column discarded. Examples:","code":"\ndt5 <- tibble(file=list.files(path=\"Exo/FTIR/Data/\", pattern=\".xls\"))\ndt5## # A tibble: 10 × 1\n##    file             \n##    <chr>            \n##  1 sample_0_25C.xls \n##  2 sample_0_300C.xls\n##  3 sample_1_25C.xls \n##  4 sample_1_300C.xls\n##  5 sample_2_25C.xls \n##  6 sample_2_300C.xls\n##  7 sample_3_25C.xls \n##  8 sample_3_300C.xls\n##  9 sample_4_25C.xls \n## 10 sample_4_300C.xls\ndt5 %>% separate(file, c(NA, \"sample\", \"temperature\", NA), convert = TRUE)## # A tibble: 10 × 2\n##    sample temperature\n##     <int> <chr>      \n##  1      0 25C        \n##  2      0 300C       \n##  3      1 25C        \n##  4      1 300C       \n##  5      2 25C        \n##  6      2 300C       \n##  7      3 25C        \n##  8      3 300C       \n##  9      4 25C        \n## 10      4 300C\ndt5 %>% separate(file, \n                 c(\"name\", \"extension\"), \n                 sep = \"\\\\.\"\n                 )## # A tibble: 10 × 2\n##    name          extension\n##    <chr>         <chr>    \n##  1 sample_0_25C  xls      \n##  2 sample_0_300C xls      \n##  3 sample_1_25C  xls      \n##  4 sample_1_300C xls      \n##  5 sample_2_25C  xls      \n##  6 sample_2_300C xls      \n##  7 sample_3_25C  xls      \n##  8 sample_3_300C xls      \n##  9 sample_4_25C  xls      \n## 10 sample_4_300C xls"},{"path":"data-frames.html","id":"apply-a-function-recursively-on-each-element-of-a-column","chapter":"6 Data frames","heading":"6.5.13 Apply a function recursively on each element of a column","text":"Take look cheatsheet purrr package options. show use purrr::map(vector, function) returns list. map(x, f) applies function f() element vector x, putting result separate element list: map(x, f) -> list(f(x1), f(x2), ... f(xn)). case f(xi) returns single value, might want use map_dbl() map_chr(), example, return vector doubles characters, respectively.course, case, ’s stupid use power map(). typical use case want read multiple files, example:(almost) equivalent :see can create function directly within call map using shortcut map(vector, ~ function(.)). useful provide arguments function – another solution write function call map() call function map().Note case need parameters, can use purrr::map2(vector1, vector2, ~function(.x, .y)), .x .y refer vector1 vector2, respectively (’s always .x .y whatever name vector1 vector2).","code":"\nx <- c(pi, pi/3, pi/2)\nmap(x, sin)     # returns a list## [[1]]\n## [1] 1.224647e-16\n## \n## [[2]]\n## [1] 0.8660254\n## \n## [[3]]\n## [1] 1\nx %>% map_dbl(sin) # returns a vector## [1] 1.224647e-16 8.660254e-01 1.000000e+00\ndt6 <- tibble(file=list.files(path=\"Exo/spectro/Data\", \n                              pattern = \".txt\", \n                              full.names = TRUE)) %>% \n    slice(1:5) %>% \n    mutate(data = map(file, read_table))\ndt6## # A tibble: 5 × 2\n##   file                          data                     \n##   <chr>                         <list>                   \n## 1 Exo/spectro/Data/rubis_01.txt <spec_tbl_df [1,014 × 2]>\n## 2 Exo/spectro/Data/rubis_02.txt <spec_tbl_df [1,014 × 2]>\n## 3 Exo/spectro/Data/rubis_03.txt <spec_tbl_df [1,014 × 2]>\n## 4 Exo/spectro/Data/rubis_04.txt <spec_tbl_df [1,014 × 2]>\n## 5 Exo/spectro/Data/rubis_05.txt <spec_tbl_df [1,014 × 2]>\ndt6 <- tibble(file=list.files(path=\"Exo/spectro/Data\", \n                              pattern = \".txt\", \n                              full.names = TRUE)) %>% \n    slice(1:5) %>%\n    mutate(data = map(file, ~ read_table(., col_names = c(\"w\", \"Int\"))))\ntibble(x=1:3, y=5:7) %>% \n    mutate(sum = map2_dbl(x, y, sum))## # A tibble: 3 × 3\n##       x     y   sum\n##   <int> <int> <dbl>\n## 1     1     5     6\n## 2     2     6     8\n## 3     3     7    10\ntibble(a=list(tibble(x=1:3, y=5:7), \n              tibble(x=0:3, y=4:7)), \n       b=list(tibble(x=10:13, y=15:18), \n              tibble(x=-1:2,  y=-14:-17))) %>% \n    mutate(sumx = map2_dbl(a, b, ~sum(.x$x, .y$x)),\n           sumy = map2_dbl(a, b, ~sum(.x$y, .y$y)))## # A tibble: 2 × 4\n##   a                b                 sumx  sumy\n##   <list>           <list>           <dbl> <dbl>\n## 1 <tibble [3 × 2]> <tibble [4 × 2]>    52    84\n## 2 <tibble [4 × 2]> <tibble [4 × 2]>     8   -40"},{"path":"data-frames.html","id":"nesting-and-un-nesting-data","chapter":"6 Data frames","heading":"6.5.14 Nesting and un-nesting data","text":"","code":"\ndt7 <- dt6 %>% \n    mutate(file = basename(file)) %>% \n    unnest(data)\ndt7## # A tibble: 5,075 × 3\n##    file             w   Int\n##    <chr>        <dbl> <dbl>\n##  1 rubis_01.txt 3064.  43.9\n##  2 rubis_01.txt 3064.  47.9\n##  3 rubis_01.txt 3064.  44.5\n##  4 rubis_01.txt 3065.  50.5\n##  5 rubis_01.txt 3065.  50.5\n##  6 rubis_01.txt 3065.  44.5\n##  7 rubis_01.txt 3065.  44.9\n##  8 rubis_01.txt 3066.  39.9\n##  9 rubis_01.txt 3066.  49.5\n## 10 rubis_01.txt 3066.  48.9\n## # … with 5,065 more rows\n# Nesting data per repeated values in a column (~equivalent to grouping)\ndt7 %>% nest(data=-file)## # A tibble: 5 × 2\n##   file         data                \n##   <chr>        <list>              \n## 1 rubis_01.txt <tibble [1,015 × 2]>\n## 2 rubis_02.txt <tibble [1,015 × 2]>\n## 3 rubis_03.txt <tibble [1,015 × 2]>\n## 4 rubis_04.txt <tibble [1,015 × 2]>\n## 5 rubis_05.txt <tibble [1,015 × 2]>"},{"path":"data-frames.html","id":"providing-data-to-ggplot","chapter":"6 Data frames","heading":"6.5.15 Providing data to ggplot","text":"","code":"\nlibrary(ggplot2)\ndt %>% filter(abs(y)> 0.1) %>% \n    ggplot(aes(x=x, y=y, color=signy))+\n        geom_point()"},{"path":"data-frames.html","id":"exo-df","chapter":"6 Data frames","heading":"6.6 Exercises","text":"Interactive exercises can found tutor package. , simply run:Create 3 column data.frame containing 10 random values, sinus, sum two first columns.Print 4 first lines tablePrint second columnPrint average third columnUsing plot(x,y) x y vectors, plot 2nd column function firstLook function write.table() write text file containing data.frameDo things tibbleDownload files:\nrubis_01.txt\npopulation.csv\nFTIR_rocks.xlsx\nrubis_01.txtpopulation.csvFTIR_rocks.xlsxLoad separate data.frames. Look options read.table(), read.csv(), readxl::read_excel(), get proper data fields.Add column names data.frame containing rubis_01.txt.Print dimensions.things tibbles.Download TGA data file ATG.txtLoad data.frame. Look options read.table() get proper data fields.tibbleDownload population.csv load tibble.names columns?data tidy? make table tidy neededCreate subset containing data Montpellier\nmax min population city?\naverage population time?\nmax min population city?average population time?total population 2012?total population per year?average population per city years?First, load tidyverse lubridate packageLoad people1.csv people2.csv pp1 pp2Create new tibble pp using pipe operator (%>%) successively:\njoining two tibbles one using inner_join()\nadding column age containing age years (use lubridate::time_length(x, 'years') x time difference days) using mutate()\njoining two tibbles one using inner_join()adding column age containing age years (use lubridate::time_length(x, 'years') x time difference days) using mutate()Display summary table using str()Using groupe_by() summarize():\nShow number males females table (use counter n())\nShow average age per gender\nShow average size per gender institution\nShow number people country, sorted descending population (arrange())\nShow number males females table (use counter n())Show average age per genderShow average size per gender institutionShow number people country, sorted descending population (arrange())Using select(), display:\nname age columns\nname column\nname age columnsall name columnUsing filter(), show data \nChinese people\ninstitution ECL UCBL\nPeople older 22\nPeople e name\nChinese peopleFrom institution ECL UCBLPeople older 22People e nameFor interesting exercises tidyverse, look :CO2 emissions: data wrangling ggplot2Religion babies: data handling, ggplot2 plotlyCOVID-19: data wrangling, ggplot2Nanoparticles statistics SEM images: data wrangling, ggplot2 fitting","code":"\nlibrary(tutor)\ntuto(\"dataframes\")\n# Create a 3 column `data.frame`{.R} containing 10 random values, their sinus, \n# and the sum of the two first columns.\nx <- runif(10)\ny <- sin(x)\nz <- x + y\ndf <- data.frame(x=x, y=y, z=z)\n# Print the 4 first lines of the table\nhead(df, 4)##            x          y          z\n## 1 0.03527932 0.03527201 0.07055133\n## 2 0.60510844 0.56885127 1.17395971\n## 3 0.02472849 0.02472597 0.04945446\n## 4 0.47338596 0.45590249 0.92928845\n# Print the second column\ndf[,2]##  [1] 0.03527201 0.56885127 0.02472597 0.45590249 0.26549129 0.44572934\n##  [7] 0.49928664 0.21686341 0.34470148 0.33159557\n# Print the average of the third column\nmean(df$z); mean(df[3]); mean(df[,3])## [1] 0.6488915## Warning in mean.default(df[3]): argument is not numeric or logical: returning NA## [1] NA## [1] 0.6488915\n# Using `plot(x,y)`{.R} where `x` and `y` are vectors, \n# plot the 2nd column as a function of the first\nplot(df[,1], df[,2])\nplot(df$x, df$y)\n# Look into the function `write.table()`{.R} to write a text file \n# containing this `data.frame`{.R}\nwrite.table(df, \"Data/some_data.dat\", quote = FALSE, row.names = FALSE)\n# # # # # # # # # # # # # # # # # \n# Tibble version\nlibrary(tidyverse)\ndf_tib <- tibble(a = runif(10), b = sin(a), c = a + b)\nhead(df_tib, 4)## # A tibble: 4 × 3\n##       a     b     c\n##   <dbl> <dbl> <dbl>\n## 1 0.207 0.205 0.412\n## 2 0.115 0.115 0.230\n## 3 0.426 0.413 0.839\n## 4 0.141 0.140 0.281\ndf_tib[,2]; df_tib[[2]];## # A tibble: 10 × 1\n##        b\n##    <dbl>\n##  1 0.205\n##  2 0.115\n##  3 0.413\n##  4 0.140\n##  5 0.506\n##  6 0.559\n##  7 0.716\n##  8 0.585\n##  9 0.373\n## 10 0.181##  [1] 0.2053041 0.1146277 0.4133594 0.1403453 0.5056044 0.5590776 0.7161695\n##  [8] 0.5845324 0.3727067 0.1813079\nmean(df_tib$c); mean(df_tib[3]); mean(df_tib[,3]); mean(df_tib[[3]])## [1] 0.7791838## Warning in mean.default(df_tib[3]): argument is not numeric or logical:\n## returning NA## [1] NA## Warning in mean.default(df_tib[, 3]): argument is not numeric or logical:\n## returning NA## [1] NA## [1] 0.7791838\nwrite.table(df_tib, \"Data/some_data.dat\", quote = FALSE, row.names = FALSE)\nplot(df_tib$a, df_tib$b)\nrubis_01   <- read.table(\"Data/rubis_01.txt\", col.names = c(\"w\", \"intensity\"))\npopulation <- read.csv(\"Data/population.csv\")\nFTIR_rocks <- readxl::read_excel(\"Data/FTIR_rocks.xlsx\")\ndim(rubis_01); names(rubis_01)## [1] 1015    2## [1] \"w\"         \"intensity\"\ndim(population); names(population)## [1]  8 21##  [1] \"year\"          \"Angers\"        \"Bordeaux\"      \"Brest\"        \n##  [5] \"Dijon\"         \"Grenoble\"      \"LeHavre\"       \"LeMans\"       \n##  [9] \"Lille\"         \"Lyon\"          \"Marseille\"     \"Montpellier\"  \n## [13] \"Nantes\"        \"Nice\"          \"Paris\"         \"Reims\"        \n## [17] \"Rennes\"        \"Saint.Etienne\" \"Strasbourg\"    \"Toulon\"       \n## [21] \"Toulouse\"\ndim(FTIR_rocks); names(FTIR_rocks)## [1] 4718    4## [1] \"wavenumber, cm-1\" \"rock 1\"           \"rock 2\"           \"rock 3\"\nlibrary(tidyverse)\nrubis_01 <- read_table(\"Data/rubis_01.txt\", col_names = c(\"w\", \"intensity\"))\npopulation <- read_csv(\"Data/population.csv\")\nd <- read.table(\"Data/ATG.txt\", \n                skip=12,\n                header=FALSE, \n                nrows=4088)\nnames(d) <- c(\"Index\", \"t\", \"Ts\", \"Tr\", \"Value\")\nhead(d)##   Index  t      Ts Tr   Value\n## 1     0  0 32.3769 25 32.9680\n## 2     3  3 32.4051 25 32.9655\n## 3     6  6 32.4332 25 32.9619\n## 4     9  9 32.4726 25 32.9582\n## 5    12 12 32.5066 25 32.9544\n## 6    15 15 32.5221 25 32.9504\nd <- read.table(\"Data/ATG.txt\", \n                skip=10,\n                comment.char=\"[\",\n                header=TRUE, \n                nrows=4088)\nhead(d)##   Index  t      Ts Tr   Value\n## 1     0  0 32.3769 25 32.9680\n## 2     3  3 32.4051 25 32.9655\n## 3     6  6 32.4332 25 32.9619\n## 4     9  9 32.4726 25 32.9582\n## 5    12 12 32.5066 25 32.9544\n## 6    15 15 32.5221 25 32.9504\nlibrary(tidyverse)\nd <- read_table(\"Data/ATG.txt\", \n                skip    = 10,\n                comment = \"[\") %>% \n        drop_na()## Warning: 122 parsing failures.\n##  row   col  expected    actual           file\n##   NA NA    5 columns 0 columns 'Data/ATG.txt'\n## 4090 Index a double  Results:  'Data/ATG.txt'\n## 4090 NA    5 columns 1 columns 'Data/ATG.txt'\n## 4091 Index a double  Content   'Data/ATG.txt'\n## 4091 Ts    a double  %         'Data/ATG.txt'\n## .... ..... ......... ......... ..............\n## See problems(...) for more details.\nd## # A tibble: 4,088 × 5\n##    Index     t    Ts    Tr Value\n##    <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1     0     0  32.4    25  33.0\n##  2     3     3  32.4    25  33.0\n##  3     6     6  32.4    25  33.0\n##  4     9     9  32.5    25  33.0\n##  5    12    12  32.5    25  33.0\n##  6    15    15  32.5    25  33.0\n##  7    18    18  32.6    25  32.9\n##  8    21    21  32.6    25  32.9\n##  9    24    24  32.6    25  32.9\n## 10    27    27  32.7    25  32.9\n## # … with 4,078 more rows\n# Download population.txt and load it into a `data.frame`{.R}.\nlibrary(tidyverse)\npopul <- read_csv(\"Data/population.csv\")\n# What are the names of the columns and the dimension of the table?\nnames(popul); dim(popul)##  [1] \"year\"          \"Angers\"        \"Bordeaux\"      \"Brest\"        \n##  [5] \"Dijon\"         \"Grenoble\"      \"LeHavre\"       \"LeMans\"       \n##  [9] \"Lille\"         \"Lyon\"          \"Marseille\"     \"Montpellier\"  \n## [13] \"Nantes\"        \"Nice\"          \"Paris\"         \"Reims\"        \n## [17] \"Rennes\"        \"Saint-Etienne\" \"Strasbourg\"    \"Toulon\"       \n## [21] \"Toulouse\"## [1]  8 21\n# Are the data tidy?\nhead(popul) # no## # A tibble: 6 × 21\n##    year Angers Bordeaux  Brest  Dijon Grenoble LeHavre LeMans  Lille   Lyon\n##   <dbl>  <dbl>    <dbl>  <dbl>  <dbl>    <dbl>   <dbl>  <dbl>  <dbl>  <dbl>\n## 1  1962 115273   278403 136104 135694   156707  187845 132181 239955 535746\n## 2  1968 128557   266662 154023 145357   161616  207150 143246 238554 527800\n## 3  1975 137591   223131 166826 151705   166037  217882 152285 219204 456716\n## 4  1982 136038   208159 156060 140942   156637  199388 147697 196705 413095\n## 5  1990 141404   210336 147956 146703   150758  195854 145502 198691 415487\n## 6  1999 151279   215363 149634 149867   153317  190905 146105 212597 445452\n## # … with 11 more variables: Marseille <dbl>, Montpellier <dbl>, Nantes <dbl>,\n## #   Nice <dbl>, Paris <dbl>, Reims <dbl>, Rennes <dbl>, `Saint-Etienne` <dbl>,\n## #   Strasbourg <dbl>, Toulon <dbl>, Toulouse <dbl>\npopul.tidy <- popul %>% \n    pivot_longer(cols=-year,\n                 names_to = \"city\",\n                 values_to = \"pop\"\n                )\npopul.tidy## # A tibble: 160 × 3\n##     year city         pop\n##    <dbl> <chr>      <dbl>\n##  1  1962 Angers    115273\n##  2  1962 Bordeaux  278403\n##  3  1962 Brest     136104\n##  4  1962 Dijon     135694\n##  5  1962 Grenoble  156707\n##  6  1962 LeHavre   187845\n##  7  1962 LeMans    132181\n##  8  1962 Lille     239955\n##  9  1962 Lyon      535746\n## 10  1962 Marseille 778071\n## # … with 150 more rows\n# Create a subset containing the data for Montpellier\nmtp <- subset(popul.tidy, city == \"Montpellier\")\n# I prefer the tidyverse version\nmtp <- popul.tidy %>% filter(city == \"Montpellier\")\n# What is the max and min of population in this city?\nmax(mtp$pop)## [1] 268456\nmin(mtp$pop)## [1] 118864\nrange(mtp$pop)## [1] 118864 268456\n# The average population over time?\nmean(mtp$pop)## [1] 203114.4\n# What is the total population in 2012?\nsum(popul.tidy[popul.tidy$year == 2012, \"pop\"])## [1] 7334805\npopul.tidy %>% \n    filter(year==2012) %>% \n    select(pop) %>% \n    sum()## [1] 7334805\n# What is the total population per year?\npopul.tidy %>% \n    group_by(year) %>% \n    summarise(pop_tot=sum(pop))## # A tibble: 8 × 2\n##    year pop_tot\n##   <dbl>   <dbl>\n## 1  1962 7349547\n## 2  1968 7550999\n## 3  1975 7298183\n## 4  1982 6933230\n## 5  1990 6857291\n## 6  1999 6965325\n## 7  2007 7235114\n## 8  2012 7334805\n# What is the average population per city over the years?\npopul.tidy %>% \n    group_by(city) %>% \n    summarise(pop_ave=mean(pop))## # A tibble: 20 × 2\n##    city           pop_ave\n##    <chr>            <dbl>\n##  1 Angers         138783.\n##  2 Bordeaux       234815.\n##  3 Brest          149125.\n##  4 Dijon          146735.\n##  5 Grenoble       157526.\n##  6 LeHavre        193990.\n##  7 LeMans         144347.\n##  8 Lille          220018.\n##  9 Lyon           470371.\n## 10 Marseille      844253.\n## 11 Montpellier    203114.\n## 12 Nantes         260925.\n## 13 Nice           334312.\n## 14 Paris         2321032.\n## 15 Reims          172278 \n## 16 Rennes         193425.\n## 17 Saint-Etienne  198135.\n## 18 Strasbourg     255429.\n## 19 Toulon         169683.\n## 20 Toulouse       382265.\n# First, load the `tidyverse` and `lubridate` package\nlibrary(tidyverse)\nlibrary(lubridate)\n# Load people1.csv and people2.csv\npp1  <- read_csv(\"Data/people1.csv\")\npp2  <- read_csv(\"Data/people2.csv\")\n# Create a new tibble `pp` by using the pipe operator (`%>%`)\n# and successively:\n# - joining the two tibbles into one using `inner_join()`\n# - adding a column `age` containing the age in years \n#   (use lubridate's `time_length(x, 'years')` with x a time\n#   difference in days) by using `mutate()`\npp <- pp1 %>% \n        inner_join(pp2) %>% \n        mutate(age=time_length(today()-dateofbirth,'years'))\n# Display a summary of the table using `str()`\nstr(pp)## tibble [20 × 7] (S3: tbl_df/tbl/data.frame)\n##  $ name       : chr [1:20] \"Salem\" \"Dilruwan-Shanaka-Perera\" \"Hanna\" \"Sabin\" ...\n##  $ gender     : chr [1:20] \"Male\" \"Male\" \"Female\" \"Male\" ...\n##  $ origin     : chr [1:20] \"Yemen\" \"Sri Lanka\" \"Ukraine\" \"India\" ...\n##  $ institution: chr [1:20] \"UCBL\" \"INSA\" \"ECL\" \"INSA\" ...\n##  $ dateofbirth: Date[1:20], format: \"1997-12-26\" \"1997-03-28\" ...\n##  $ size       : num [1:20] 161 172 165 186 176 ...\n##  $ age        : num [1:20] 24.3 25 24.3 26.7 27 ...\n# Using `groupe_by()` and `summarize()`:\n# - Show the number of males and females in the table \n#   (use the counter `n()`)\npp %>% group_by(gender) %>% summarize(count=n())## # A tibble: 2 × 2\n##   gender count\n##   <chr>  <int>\n## 1 Female     4\n## 2 Male      16\n# - Show the average age per gender\npp %>% group_by(gender) %>% summarize(age=mean(age))## # A tibble: 2 × 2\n##   gender   age\n##   <chr>  <dbl>\n## 1 Female  26.3\n## 2 Male    26.0\n# - Show the average size per gender and institution\npp %>% group_by(gender, institution) %>% summarize(size=mean(size))## # A tibble: 4 × 3\n## # Groups:   gender [2]\n##   gender institution  size\n##   <chr>  <chr>       <dbl>\n## 1 Female ECL          178.\n## 2 Male   ECL          168.\n## 3 Male   INSA         174.\n## 4 Male   UCBL         174.\n# - Show the number of people from each country, \n#   sorted by descending population\npp %>% group_by(origin) %>% \n        summarize(count=n()) %>% \n        arrange(desc(count))## # A tibble: 13 × 2\n##    origin      count\n##    <chr>       <int>\n##  1 China           4\n##  2 Ukraine         4\n##  3 USA             2\n##  4 Afghanistan     1\n##  5 Austria         1\n##  6 Brazil          1\n##  7 Colombia        1\n##  8 Cyprus          1\n##  9 India           1\n## 10 Iran            1\n## 11 Sri Lanka       1\n## 12 Tunisia         1\n## 13 Yemen           1\n# Using `select()`, display:\n# - only the name and age columns\npp %>% select(c(name, age))## # A tibble: 20 × 2\n##    name                      age\n##    <chr>                   <dbl>\n##  1 Salem                    24.3\n##  2 Dilruwan-Shanaka-Perera  25.0\n##  3 Hanna                    24.3\n##  4 Sabin                    26.7\n##  5 Benedikt                 27.0\n##  6 Jordyn                   25.1\n##  7 Jennifer                 26.9\n##  8 Yiran                    27.2\n##  9 Leran                    29.3\n## 10 Aymen                    32.1\n## 11 Pavlo                    25.0\n## 12 Saulo                    27.5\n## 13 Nicolas-Estevan          28.4\n## 14 Farzad                   25.3\n## 15 Roein                    22.7\n## 16 Paraskevas               22.8\n## 17 Ihor                     22.5\n## 18 Iryna                    29.1\n## 19 Peng                     25.3\n## 20 Mingyuan                 24.6\n# - all but the name column\npp %>% select(-name)## # A tibble: 20 × 6\n##    gender origin      institution dateofbirth  size   age\n##    <chr>  <chr>       <chr>       <date>      <dbl> <dbl>\n##  1 Male   Yemen       UCBL        1997-12-26   161.  24.3\n##  2 Male   Sri Lanka   INSA        1997-03-28   172.  25.0\n##  3 Female Ukraine     ECL         1997-12-30   165.  24.3\n##  4 Male   India       INSA        1995-08-04   186.  26.7\n##  5 Male   Austria     UCBL        1995-04-25   176.  27.0\n##  6 Female USA         ECL         1997-02-19   176.  25.1\n##  7 Female USA         ECL         1995-05-28   179   26.9\n##  8 Male   China       UCBL        1995-02-04   188.  27.2\n##  9 Male   China       UCBL        1992-12-30   186   29.3\n## 10 Male   Tunisia     INSA        1990-03-03   160.  32.1\n## 11 Male   Ukraine     ECL         1997-04-12   151.  25.0\n## 12 Male   Brazil      ECL         1994-09-24   184.  27.5\n## 13 Male   Colombia    INSA        1993-11-25   184.  28.4\n## 14 Male   Iran        INSA        1996-12-27   183   25.3\n## 15 Male   Afghanistan INSA        1999-07-11   155.  22.7\n## 16 Male   Cyprus      INSA        1999-06-25   176.  22.8\n## 17 Male   Ukraine     ECL         1999-10-03   170.  22.5\n## 18 Female Ukraine     ECL         1993-02-27   192   29.1\n## 19 Male   China       UCBL        1996-12-14   171   25.3\n## 20 Male   China       UCBL        1997-08-21   164.  24.6\n# Using `filter()`, show data only for\n# - Chinese people\npp %>% filter(origin=='China')## # A tibble: 4 × 7\n##   name     gender origin institution dateofbirth  size   age\n##   <chr>    <chr>  <chr>  <chr>       <date>      <dbl> <dbl>\n## 1 Yiran    Male   China  UCBL        1995-02-04   188.  27.2\n## 2 Leran    Male   China  UCBL        1992-12-30   186   29.3\n## 3 Peng     Male   China  UCBL        1996-12-14   171   25.3\n## 4 Mingyuan Male   China  UCBL        1997-08-21   164.  24.6\n# - From institution ECL and UCBL\npp %>% filter(institution %in% c('ECL', 'UCBL'))## # A tibble: 13 × 7\n##    name     gender origin  institution dateofbirth  size   age\n##    <chr>    <chr>  <chr>   <chr>       <date>      <dbl> <dbl>\n##  1 Salem    Male   Yemen   UCBL        1997-12-26   161.  24.3\n##  2 Hanna    Female Ukraine ECL         1997-12-30   165.  24.3\n##  3 Benedikt Male   Austria UCBL        1995-04-25   176.  27.0\n##  4 Jordyn   Female USA     ECL         1997-02-19   176.  25.1\n##  5 Jennifer Female USA     ECL         1995-05-28   179   26.9\n##  6 Yiran    Male   China   UCBL        1995-02-04   188.  27.2\n##  7 Leran    Male   China   UCBL        1992-12-30   186   29.3\n##  8 Pavlo    Male   Ukraine ECL         1997-04-12   151.  25.0\n##  9 Saulo    Male   Brazil  ECL         1994-09-24   184.  27.5\n## 10 Ihor     Male   Ukraine ECL         1999-10-03   170.  22.5\n## 11 Iryna    Female Ukraine ECL         1993-02-27   192   29.1\n## 12 Peng     Male   China   UCBL        1996-12-14   171   25.3\n## 13 Mingyuan Male   China   UCBL        1997-08-21   164.  24.6\n# - People older than 22 \npp %>% filter(age>22)## # A tibble: 20 × 7\n##    name                    gender origin     institution dateofbirth  size   age\n##    <chr>                   <chr>  <chr>      <chr>       <date>      <dbl> <dbl>\n##  1 Salem                   Male   Yemen      UCBL        1997-12-26   161.  24.3\n##  2 Dilruwan-Shanaka-Perera Male   Sri Lanka  INSA        1997-03-28   172.  25.0\n##  3 Hanna                   Female Ukraine    ECL         1997-12-30   165.  24.3\n##  4 Sabin                   Male   India      INSA        1995-08-04   186.  26.7\n##  5 Benedikt                Male   Austria    UCBL        1995-04-25   176.  27.0\n##  6 Jordyn                  Female USA        ECL         1997-02-19   176.  25.1\n##  7 Jennifer                Female USA        ECL         1995-05-28   179   26.9\n##  8 Yiran                   Male   China      UCBL        1995-02-04   188.  27.2\n##  9 Leran                   Male   China      UCBL        1992-12-30   186   29.3\n## 10 Aymen                   Male   Tunisia    INSA        1990-03-03   160.  32.1\n## 11 Pavlo                   Male   Ukraine    ECL         1997-04-12   151.  25.0\n## 12 Saulo                   Male   Brazil     ECL         1994-09-24   184.  27.5\n## 13 Nicolas-Estevan         Male   Colombia   INSA        1993-11-25   184.  28.4\n## 14 Farzad                  Male   Iran       INSA        1996-12-27   183   25.3\n## 15 Roein                   Male   Afghanist… INSA        1999-07-11   155.  22.7\n## 16 Paraskevas              Male   Cyprus     INSA        1999-06-25   176.  22.8\n## 17 Ihor                    Male   Ukraine    ECL         1999-10-03   170.  22.5\n## 18 Iryna                   Female Ukraine    ECL         1993-02-27   192   29.1\n## 19 Peng                    Male   China      UCBL        1996-12-14   171   25.3\n## 20 Mingyuan                Male   China      UCBL        1997-08-21   164.  24.6\n# - People with a `e` in their name\npp %>% filter(grepl('e',name))## # A tibble: 10 × 7\n##    name                    gender origin     institution dateofbirth  size   age\n##    <chr>                   <chr>  <chr>      <chr>       <date>      <dbl> <dbl>\n##  1 Salem                   Male   Yemen      UCBL        1997-12-26   161.  24.3\n##  2 Dilruwan-Shanaka-Perera Male   Sri Lanka  INSA        1997-03-28   172.  25.0\n##  3 Benedikt                Male   Austria    UCBL        1995-04-25   176.  27.0\n##  4 Jennifer                Female USA        ECL         1995-05-28   179   26.9\n##  5 Leran                   Male   China      UCBL        1992-12-30   186   29.3\n##  6 Aymen                   Male   Tunisia    INSA        1990-03-03   160.  32.1\n##  7 Nicolas-Estevan         Male   Colombia   INSA        1993-11-25   184.  28.4\n##  8 Roein                   Male   Afghanist… INSA        1999-07-11   155.  22.7\n##  9 Paraskevas              Male   Cyprus     INSA        1999-06-25   176.  22.8\n## 10 Peng                    Male   China      UCBL        1996-12-14   171   25.3"},{"path":"readingwriting-all-kinds-of-files.html","id":"readingwriting-all-kinds-of-files","chapter":"7 Reading/writing all kinds of files","heading":"7 Reading/writing all kinds of files","text":"","code":""},{"path":"readingwriting-all-kinds-of-files.html","id":"reading-files","chapter":"7 Reading/writing all kinds of files","heading":"7.1 Reading files","text":"Working data-based scientific field, encounter many different types files. ASCII text files usually predominant, may want read files coming Excel, Origin, etc.\nnon-exhaustive reminder help read kinds files often encounter R. invite visit RopenSci webpage packages, isn’t enough need, well, Google friend.","code":""},{"path":"readingwriting-all-kinds-of-files.html","id":"column-text-files","chapter":"7 Reading/writing all kinds of files","heading":"7.1.1 Column text files","text":"base R functions like read.csv() read.table() tidyverse counterpart, like read_csv() read_table(). usually prefer tidyverse version outputs tibble instead data.frame. functions can also directly provided url text file.data file “complicated” – sense contains lines columns skipped – look help reader function ?function_name.","code":""},{"path":"readingwriting-all-kinds-of-files.html","id":"comma-separated-values","chapter":"7 Reading/writing all kinds of files","heading":"7.1.1.1 Comma separated values","text":"Input file looks like :Since version 2.0 readr, read_csv() can also take vector argument, result reading files vector successively:","code":"## Country Name,Country Code,Year,Value\n## Arab World,ARB,1960,92490932\n## Arab World,ARB,1961,95044497\n## Arab World,ARB,1962,97682294\n## Arab World,ARB,1963,100411076\n## Arab World,ARB,1964,103239902\n## Arab World,ARB,1965,106174988\n## Arab World,ARB,1966,109230593\n## Arab World,ARB,1967,112406932\n## Arab World,ARB,1968,115680165\nlibrary(tidyverse)\nread_csv(\"Data/tot_population.csv\")## # A tibble: 14,885 × 4\n##    `Country Name` `Country Code`  Year     Value\n##    <chr>          <chr>          <dbl>     <dbl>\n##  1 Arab World     ARB             1960  92490932\n##  2 Arab World     ARB             1961  95044497\n##  3 Arab World     ARB             1962  97682294\n##  4 Arab World     ARB             1963 100411076\n##  5 Arab World     ARB             1964 103239902\n##  6 Arab World     ARB             1965 106174988\n##  7 Arab World     ARB             1966 109230593\n##  8 Arab World     ARB             1967 112406932\n##  9 Arab World     ARB             1968 115680165\n## 10 Arab World     ARB             1969 119016542\n## # … with 14,875 more rows\nread_csv(\"Data/tot_population.csv\", skip = 1)## # A tibble: 14,884 × 4\n##    `Arab World` ARB   `1960` `92490932`\n##    <chr>        <chr>  <dbl>      <dbl>\n##  1 Arab World   ARB     1961   95044497\n##  2 Arab World   ARB     1962   97682294\n##  3 Arab World   ARB     1963  100411076\n##  4 Arab World   ARB     1964  103239902\n##  5 Arab World   ARB     1965  106174988\n##  6 Arab World   ARB     1966  109230593\n##  7 Arab World   ARB     1967  112406932\n##  8 Arab World   ARB     1968  115680165\n##  9 Arab World   ARB     1969  119016542\n## 10 Arab World   ARB     1970  122398374\n## # … with 14,874 more rows\nread_csv(\"Data/tot_population.csv\", skip = 1, col_names = LETTERS[1:4])## # A tibble: 14,885 × 4\n##    A          B         C         D\n##    <chr>      <chr> <dbl>     <dbl>\n##  1 Arab World ARB    1960  92490932\n##  2 Arab World ARB    1961  95044497\n##  3 Arab World ARB    1962  97682294\n##  4 Arab World ARB    1963 100411076\n##  5 Arab World ARB    1964 103239902\n##  6 Arab World ARB    1965 106174988\n##  7 Arab World ARB    1966 109230593\n##  8 Arab World ARB    1967 112406932\n##  9 Arab World ARB    1968 115680165\n## 10 Arab World ARB    1969 119016542\n## # … with 14,875 more rows\nread_csv(c(\"Data/test1.csv\",\n           \"Data/test2.csv\"),\n         id = \"file\", show_col_types = FALSE)## # A tibble: 4 × 3\n##   file           name  value\n##   <chr>          <chr> <dbl>\n## 1 Data/test1.csv John      3\n## 2 Data/test1.csv Doe       2\n## 3 Data/test2.csv Colin     5\n## 4 Data/test2.csv Louis     8"},{"path":"readingwriting-all-kinds-of-files.html","id":"space-separated-values","chapter":"7 Reading/writing all kinds of files","heading":"7.1.1.2 Space separated values","text":"Input file looks like :","code":"## 3063.7136    43.916748\n## 3063.991 47.916748\n## 3064.2668    44.5\n## 3064.5442    50.5\n## 3064.8201    50.5\n## 3065.0972    44.5\n## 3065.373 44.916748\n## 3065.6504    39.916748\n## 3065.9263    49.5\n## 3066.2034    48.916748\nlibrary(tidyverse)\nread_table(\"Data/rubis_01.txt\")\nread_table(\"Data/rubis_01.txt\", col_names = c(\"w\",\"int\"))"},{"path":"readingwriting-all-kinds-of-files.html","id":"other-separators","chapter":"7 Reading/writing all kinds of files","heading":"7.1.1.3 Other separators","text":"tab-separated values, use read_tsv(). exotic separators, look read_delim().","code":""},{"path":"readingwriting-all-kinds-of-files.html","id":"excel-files","chapter":"7 Reading/writing all kinds of files","heading":"7.1.2 Excel files","text":", use readxl library function read_excel() returning tibble:case Excel file contains merged cells, read_excel() fill merged cells NA values. want avoid behavior, use openxlsx::read.xlsx() (returns data.frame):","code":"\nlibrary(readxl)\nread_excel(\"Data/test.xlsx\")## # A tibble: 10 × 2\n##        x      y\n##    <dbl>  <dbl>\n##  1     1  5.21 \n##  2     2  6.55 \n##  3     3  3.71 \n##  4     4  0.216\n##  5     5  0.205\n##  6     6  4.60 \n##  7     7 10.3  \n##  8     8 12.9  \n##  9     9 11.1  \n## 10    10  7.28\nread_excel(\"Data/test.xlsx\", sheet=2) # specify the sheet by its number or its name## # A tibble: 4 × 2\n##   hello  world   \n##   <chr>  <chr>   \n## 1 ac     th      \n## 2 asc    thh     \n## 3 ascsa  dthdh   \n## 4 ascacs dthtdhdh\nread_excel(\"Data/test.xlsx\", sheet=3)## # A tibble: 5 × 3\n##   a         b ...3 \n##   <chr> <dbl> <chr>\n## 1 <NA>     12 t    \n## 2 <NA>     13 h    \n## 3 <NA>     14 d    \n## 4 b        15 f    \n## 5 <NA>     16 g\nlibrary(openxlsx)\nread.xlsx(\"Data/test.xlsx\", fillMergedCells = TRUE, sheet = 3)##   a  b b\n## 1 a 12 t\n## 2 a 13 h\n## 3 a 14 d\n## 4 b 15 f\n## 5 b 16 g"},{"path":"readingwriting-all-kinds-of-files.html","id":"origin-files","chapter":"7 Reading/writing all kinds of files","heading":"7.1.3 Origin files","text":"moved R coming workflow used Origin, chances .opj files lying around still want able read. Lucky , Ropj library :","code":"\nlibrary(Ropj)\nread.opj(\"Data/opjfile.opj\")"},{"path":"readingwriting-all-kinds-of-files.html","id":"matlab-files","chapter":"7 Reading/writing all kinds of files","heading":"7.1.4 Matlab files","text":"read Matlab’s .mat format datasets, use R.matlab package readMat() function.","code":"\nlibrary(R.matlab)\ndf <- readMat(\"yourfile.mat\")"},{"path":"readingwriting-all-kinds-of-files.html","id":"images","chapter":"7 Reading/writing all kinds of files","heading":"7.1.5 Images","text":"can read image matrix. example:image processing (pictures videos), recommend imager package.","code":"\nlibrary(png)\nreadPNG(\"image.png\")\nlibrary(tiff)\nreadTIFF(\"image.tiff\")"},{"path":"readingwriting-all-kinds-of-files.html","id":"spectroscopic-files","chapter":"7 Reading/writing all kinds of files","heading":"7.1.6 Spectroscopic files","text":"case spectroscopic data wasn’t saved ASCII file spc another format, take look lightr package, example.Example reading function spc file:","code":"\nlibrary(tidyverse)\nlibrary(lightr)\nread_spc <- function(fname){\n    d <- lr_parse_spc(fname) # d is a list\n    tibble(w         = d[[1]]$wl, \n           intensity = d[[1]]$processed)\n}"},{"path":"readingwriting-all-kinds-of-files.html","id":"compressed-binary-data-files-hdf-netcdf","chapter":"7 Reading/writing all kinds of files","heading":"7.1.7 Compressed binary data files: HDF, netCDF","text":"HDF: Go vignette see read Hierarchical Data Files.netCDF: see .","code":""},{"path":"readingwriting-all-kinds-of-files.html","id":"reading-multiple-files-into-a-tidy-table","chapter":"7 Reading/writing all kinds of files","heading":"7.2 Reading multiple files into a tidy table","text":"often encounter situation need read multiple similar files tidy table.\n, can use loop: work un-R-ly, cases need perform operations loop.Let’s say store list file names vector file_list read files using function read_function():R-friendly way avoid using loop:case reading csv files, can use fact since version 2.0 readr, read_csv() takes vector first argument. ’ll also need use id argument get column list file names:","code":"\nlibrary(tidyverse)\ndf <- tibble() # empty initialization\nfor (file in file_list) {\n    df_temp <- read_function(file) %>% \n            mutate(name = file) # add the column `name` to make the tibble tidy\n    df <- bind_rows(df, def_temp)\n}\nlibrary(tidyverse)\ndf <- tibble(name = file_list) %>% \n    mutate(data = map(name, read_function)) %>% \n    unnest(data)\nlibrary(tidyverse)\ndf <- read_csv(file_list, id = \"name\")"},{"path":"readingwriting-all-kinds-of-files.html","id":"writing-files","chapter":"7 Reading/writing all kinds of files","heading":"7.3 Writing files","text":"","code":""},{"path":"readingwriting-all-kinds-of-files.html","id":"text-files","chapter":"7 Reading/writing all kinds of files","heading":"7.3.1 Text files","text":"Sometimes, want output data csv Excel file share others save data. Use write_csv() function write csv file (prefer tidyverse’s write_csv() base R write.csv() easy use):Note write_*() functions automatically compress outputs appropriate extension given. Three extensions currently supported: .gz gzip compression, .bz2 bzip2 compression .xz lzma compression. See examples help information.don’t want use csv files, look write_tsv() tab-separated values write_delim() delimiter. case want output fixed width files, look gdata’s write.fwf().","code":"\nlibrary(tidyverse)\nwrite_csv(df, \"your_file.csv\")"},{"path":"readingwriting-all-kinds-of-files.html","id":"excel-files-1","chapter":"7 Reading/writing all kinds of files","heading":"7.3.2 Excel files","text":"write Excel files, use library openxlsx function write.xlsx() (see help function options):","code":"\nlibrary(openxlsx)\nwrite.xlsx(df, \"your_file.xlsx\")"},{"path":"lists.html","id":"lists","chapter":"8 Lists","heading":"8 Lists","text":"","code":""},{"path":"lists.html","id":"definition-2","chapter":"8 Lists","heading":"8.1 Definition","text":"Lists allow store types objects types values: booleans, doubles, characters, vectors, lists, data.frame, etc","code":"\n# initialization\nL <- list(name = \"John\",\n          age  = 43,\n          kids = list(name=c(\"Kevin\", \"Pamela\"), # nested list\n                      age =c(4,5)\n                     )\n         )\nL## $name\n## [1] \"John\"\n## \n## $age\n## [1] 43\n## \n## $kids\n## $kids$name\n## [1] \"Kevin\"  \"Pamela\"\n## \n## $kids$age\n## [1] 4 5\n# names of entries (can be changed)\nnames(L)## [1] \"name\" \"age\"  \"kids\"\n# statistics\nsummary(L)##      Length Class  Mode     \n## name 1      -none- character\n## age  1      -none- numeric  \n## kids 2      -none- list\nstr(L)## List of 3\n##  $ name: chr \"John\"\n##  $ age : num 43\n##  $ kids:List of 2\n##   ..$ name: chr [1:2] \"Kevin\" \"Pamela\"\n##   ..$ age : num [1:2] 4 5"},{"path":"lists.html","id":"accessing-values-and-other-operations","chapter":"8 Lists","heading":"8.2 Accessing values and other operations","text":"","code":"\nL$name # is a vector## [1] \"John\"\nL[\"age\"];typeof(L[\"age\"])     # is a list## $age\n## [1] 43## [1] \"list\"\nL[[\"age\"]];typeof(L[[\"age\"]]) # is a vector## [1] 43## [1] \"double\"\nL[[3]]      # is a list (because 'kids' is a list)## $name\n## [1] \"Kevin\"  \"Pamela\"\n## \n## $age\n## [1] 4 5\nL[[3]]['name']   # is a list## $name\n## [1] \"Kevin\"  \"Pamela\"\nL[[3]][['name']] # is a vector## [1] \"Kevin\"  \"Pamela\"\n# empty initialization\nLL <- list(); LL # no specific size## list()\nLL <- vector(\"list\", length=3); LL # specific size## [[1]]\n## NULL\n## \n## [[2]]\n## NULL\n## \n## [[3]]\n## NULL\n# Concatenation\nL1 <- list(wife=\"Kim\", wife.age=38)\nL2 <- c(L, L1)\ntypeof(L2); L2## [1] \"list\"## $name\n## [1] \"John\"\n## \n## $age\n## [1] 43\n## \n## $kids\n## $kids$name\n## [1] \"Kevin\"  \"Pamela\"\n## \n## $kids$age\n## [1] 4 5\n## \n## \n## $wife\n## [1] \"Kim\"\n## \n## $wife.age\n## [1] 38"},{"path":"lists.html","id":"exo-lists","chapter":"8 Lists","heading":"8.3 Exercises","text":"Create list containing 2 strings, 2 numbers, 2 vectors, 1 list 2 logical values.Give names elements list.Access first second elements list.Add new item g4 = \"Hello\" list.Select second element nested list.Remove second element list.Create second list whatever wantMerge two lists one list.Print number objects merged list.Convert list(1,2,3,4) vector","code":"\n# Create a list containing 2 strings, 2 numbers, 2 vectors, 1 list and 2 logical values.\n# Give names to the elements in the list.\nfirst_list <- list(string1 = \"foo\",\n                   string2 = \"bar\",\n                   number1 = 42,\n                   number2 = pi,\n                   vec1    = seq(-10,10,1),\n                   vec2    = c(\"Hello\", \"world\"),\n                   list1   = list(a = 1:10, \n                                  b = 10:1),\n                   bool1   = TRUE,\n                   bool2   = FALSE\n                  )\nfirst_list## $string1\n## [1] \"foo\"\n## \n## $string2\n## [1] \"bar\"\n## \n## $number1\n## [1] 42\n## \n## $number2\n## [1] 3.141593\n## \n## $vec1\n##  [1] -10  -9  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7   8\n## [20]   9  10\n## \n## $vec2\n## [1] \"Hello\" \"world\"\n## \n## $list1\n## $list1$a\n##  [1]  1  2  3  4  5  6  7  8  9 10\n## \n## $list1$b\n##  [1] 10  9  8  7  6  5  4  3  2  1\n## \n## \n## $bool1\n## [1] TRUE\n## \n## $bool2\n## [1] FALSE\n# Access the first and second elements of the list.\nfirst_list[[1]]## [1] \"foo\"\nfirst_list[[\"string2\"]]## [1] \"bar\"\n# Add a new item `g4 = \"Hello\"` to the list.\nfirst_list$g4 <- \"Hello\"\nfirst_list## $string1\n## [1] \"foo\"\n## \n## $string2\n## [1] \"bar\"\n## \n## $number1\n## [1] 42\n## \n## $number2\n## [1] 3.141593\n## \n## $vec1\n##  [1] -10  -9  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7   8\n## [20]   9  10\n## \n## $vec2\n## [1] \"Hello\" \"world\"\n## \n## $list1\n## $list1$a\n##  [1]  1  2  3  4  5  6  7  8  9 10\n## \n## $list1$b\n##  [1] 10  9  8  7  6  5  4  3  2  1\n## \n## \n## $bool1\n## [1] TRUE\n## \n## $bool2\n## [1] FALSE\n## \n## $g4\n## [1] \"Hello\"\n# Select the second element of the nested list.\nfirst_list[[\"list1\"]][[2]]##  [1] 10  9  8  7  6  5  4  3  2  1\n# Remove the second element of the list.\nfirst_list[-2]## $string1\n## [1] \"foo\"\n## \n## $number1\n## [1] 42\n## \n## $number2\n## [1] 3.141593\n## \n## $vec1\n##  [1] -10  -9  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7   8\n## [20]   9  10\n## \n## $vec2\n## [1] \"Hello\" \"world\"\n## \n## $list1\n## $list1$a\n##  [1]  1  2  3  4  5  6  7  8  9 10\n## \n## $list1$b\n##  [1] 10  9  8  7  6  5  4  3  2  1\n## \n## \n## $bool1\n## [1] TRUE\n## \n## $bool2\n## [1] FALSE\n## \n## $g4\n## [1] \"Hello\"\n# Create a second list with whatever you want\nsecond_list <- list(a=1:10, b=1:10, c=\"hello\")\n# Merge the two lists into one list.\none_list <- c(first_list, second_list)\n# Print the number of objects in the merged list.\nlength(one_list)## [1] 13\n# Convert `list(1,2,3,4)` to a vector\nas.numeric(list(1,2,3,4))## [1] 1 2 3 4"},{"path":"functions.html","id":"functions","chapter":"9 Functions","heading":"9 Functions","text":"","code":""},{"path":"functions.html","id":"definition-3","chapter":"9 Functions","heading":"9.1 Definition","text":"get manual base function, type ?function_name.function returns last thing called . Thus function defined like return nothing:return want:result function can list, data.frame, vector… nothing. can attribute result function variable:One can add default values variables:pass arguments functions:even pass function argument:","code":"\ngeom_mean <- function(x, y){\n    a <- sqrt(x*y)\n}\ngeom_mean(1,2)\ngeom_mean <- function(x, y){\n    a <- sqrt(x*y)\n    a\n}\ngeom_mean(1,2) #returns a## [1] 1.414214\nperson <- function(name, age){\n    list(name=name, age=age)\n}\njoe <- person(name=\"Joe\", age=33)\njoe## $name\n## [1] \"Joe\"\n## \n## $age\n## [1] 33\ntestfunc <- function(x, y=1){\n    x*y\n}\ntestfunc(1)## [1] 1\ntestfunc(1, y=2)## [1] 2\ntestfunc(1:3, y=.1)## [1] 0.1 0.2 0.3\ntestfunc2 <- function(x, ...){\n    head(x, ...)\n}\ntestfunc2(1:100)## [1] 1 2 3 4 5 6\ntestfunc2(1:100,2)## [1] 1 2\ntestfunc3 <- function(FUN, ...){\n    FUN(...)\n}\ntestfunc3(sum, 1:10)## [1] 55\ntestfunc3(plot, 1:10, sin(1:10), type=\"l\")"},{"path":"functions.html","id":"interpolation-of-data","chapter":"9 Functions","heading":"9.2 Interpolation of data","text":"possible interpolate data approxfun() splinefun() functions: former uses linear interpolation, latter uses cubic splines (polynomials).","code":"\nxmin <- -2*pi; xmax <- 2*pi\nx  <- runif(30, min=xmin, max=xmax)\nxx <- seq(xmin, xmax, .1)\ny  <- sin(x)\n# Linear interpolation\nlin_interp <- approxfun(x,y)        #is a function\nlin_interp(0); lin_interp(pi)## [1] 0.000585687## [1] -0.0004503362\nyy_lin     <- approx(x, y, xout=xx) #is a list containing x and y\n\n# Cubic spline interpolation\nspl_interp <- splinefun(x,y)        #is a function\nyy_spl     <- spline(x, y, xout=xx) #is a list containing x and y\n\npar(family = \"Helvetica\", cex.lab=1.5, cex.axis=1.4, \n    mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1)\nplot(x, y, pch=16, cex=2, ylim=c(-1,1.6))\nlines(xx, lin_interp(xx), col=\"royalblue\") # equivalent to: lines(yy_lin, col=\"royalblue\")\nlines(xx, spl_interp(xx), col=\"red\", lty=2)# equivalent to: lines(yy_spl, col=\"red\")\nlegend(\"topright\",\n    cex=1.2,\n    lty=c(NA, 1, 2),\n    lwd=c(NA, 2, 2),\n    pch=c(16, NA, NA),\n    col=c(\"black\", \"royalblue\", \"red\"),\n    bty = \"n\",\n    legend=c(\"'Experimental' points\", \"Linear interpolation\", \"Spline interpolation\")\n    )"},{"path":"functions.html","id":"exo-functions","chapter":"9 Functions","heading":"9.3 Exercises","text":"Create sinus cardinal function, \\(f(x)=\\sin(x)/x\\) \\(x\\neq0\\) \\(f(0)=1\\).Write function returning normalized Gaussian function\nTest indeed normalized numerically computing integral\nTest indeed normalized numerically computing integralWrite new function returning sum arbitrary number Gaussian functionsWrite function returning tibble (created supplied, incremented supplied) containing name, age, gender country origin people class. Print . Play around obtained tibble make statistics class population.","code":"\nsinc <- function(x, tol = sqrt(.Machine$double.eps) ){\n    # sinus cardinal\n    y <- rep(1,length(x))\n    b <- which(abs(x)>tol)\n    y[b] <- sin(x[b])/x[b]\n    y\n}\nsinc(seq(-pi,pi,pi/4))## [1] 3.898172e-17 3.001054e-01 6.366198e-01 9.003163e-01 1.000000e+00\n## [6] 9.003163e-01 6.366198e-01 3.001054e-01 3.898172e-17\nx <- seq(-8*pi,8*pi,.1)\nplot(x, sinc(x), type=\"l\", lwd=3);abline(h=0,v=0)\n# Write a function returning a normalized Gaussian function\n# look also at the dnorm() base function\nGaussian <- function(x,x0,FWHM,A=1){\n    2.*A*sqrt(2*log(2))/sqrt(2*pi)/FWHM*exp(-(x-x0)^2*4*log(2)/FWHM^2)\n}\n# Test that it is indeed normalized by numerically computing its integral\ndx <- .01\nx  <- seq(-10,10,dx)\ny  <- Gaussian(x,0,1)\nsum(y*dx)\nsum(dnorm(x,mean=0,sd=1)*dx)\n# Write a new function returning the sum of an arbitrary number of Gaussian functions\nsumGaussian1 <- function(x,x0,FWHM,A=1){\n    y <- y0\n    for (i in 1:length(x0)) {\n      y <- y + Gaussian(x,x0[i],FWHM[i],A=A[i])\n    }\n    y\n}\n# handling bad entries and being more efficient\nsumGaussian2 <- function(x,x0,FWHM,A=1){\n    if(length(x0)!=length(FWHM)) FWHM <- rep(FWHM, length.out=length(x0))\n    if(length(x0)!=length(A))    A    <- rep(A,    length.out=length(x0))\n    rowSums(sapply(1:length(x0), function(i) {\n          Gaussian(x,x0[i],FWHM[i],A=A[i])\n        }))\n}\npeople <- function(ppl=tibble::tibble(), name=NA, age=NA, gender=NA, origin=NA){\n    library(tibble)\n    library(dplyr)\n    bind_rows(ppl, tibble(name=name, age=age, gender=gender, origin=origin))\n}\nppl <- people(name=\"Colin\", age=33, gender=\"Male\", origin=\"France\")\nppl <- people(ppl=ppl, name=\"Vincent\", age=39, gender=\"Male\", origin=\"France\")\nppl## # A tibble: 2 × 4\n##   name      age gender origin\n##   <chr>   <dbl> <chr>  <chr> \n## 1 Colin      33 Male   France\n## 2 Vincent    39 Male   France"},{"path":"conditional-actions-and-loops.html","id":"conditional-actions-and-loops","chapter":"10 Conditional actions and loops","heading":"10 Conditional actions and loops","text":"","code":""},{"path":"conditional-actions-and-loops.html","id":"conditional-actions","chapter":"10 Conditional actions and loops","heading":"10.1 Conditional actions","text":"Conditional actions R can determined usual else statements:Sometimes, ’s usefull able one line using ifesle(test, yes, ):","code":"\nx <- 1; y <- 2\nif(x>y){\n    print(\"x is larger than y\")\n}else if(x<y){\n    print(\"x is smaller than y\")\n}else{\n    print(\"x is equal to y\")\n}## [1] \"x is smaller than y\"\nx <- 3:7\nifelse(x>5, \"larger than 5\", \"lower than 5\") ## [1] \"lower than 5\"  \"lower than 5\"  \"lower than 5\"  \"larger than 5\"\n## [5] \"larger than 5\""},{"path":"conditional-actions-and-loops.html","id":"loops","chapter":"10 Conditional actions and loops","heading":"10.2 Loops…","text":"Loops R provided usual keywords:","code":"\n# For loop\nfor(i in 1:100){\n    # pass to next index directly\n    if(i %in% c(3,8,5)) next \n    # break loop\n    if(i==10) break\n    print(i)\n}## [1] 1\n## [1] 2\n## [1] 4\n## [1] 6\n## [1] 7\n## [1] 9\nphrase <- c(\"hello\", \"world\")\nfor(word in phrase){\n    print(word)\n}## [1] \"hello\"\n## [1] \"world\"\n# While loop\ni <- 1\nwhile(i<8){\n    print(i)\n    i <- i+2\n}## [1] 1\n## [1] 3\n## [1] 5\n## [1] 7"},{"path":"conditional-actions-and-loops.html","id":"and-how-to-avoid-them","chapter":"10 Conditional actions and loops","heading":"10.3 … and how to avoid them","text":"However, since R vectorized language, means loops avoided possible inefficient:Avoiding loops therefore sought possible. R helps us way base functions apply(), sapply() lapply(). Operations tidyverse also good way avoiding loops.Take look help functions, summary apply(df, direction, function) applies function wanted direction (1 rows, 2 columns) given data.frame (vector). Example:lapply() (equivalently, sapply()) basically thing applied lists returns list (vector):","code":"\ntest_time <- function(FUN,...) {\n    start_time <- Sys.time()\n    FUN(...)\n    elapsed_time <- Sys.time()-start_time\n    print(paste(\"Elapsed time :\", elapsed_time, \"s - \",\n                as.character(substitute(FUN)))\n         )\n}\nforloop <- function(x){\n    for(i in seq_along(x)){\n        x[i] <- 2*x[i]\n    }\n    x\n}\nnoforloop <- function(x){\n    2*x\n}\nx <- runif(1e8)\ntest_time(forloop, x); test_time(noforloop, x)## [1] \"Elapsed time : 6.36099100112915 s -  forloop\"## [1] \"Elapsed time : 0.424988031387329 s -  noforloop\"\nlibrary(tibble)\ndt <- tibble(x=1:5, y=x^2, z=x^3);dt## # A tibble: 5 × 3\n##       x     y     z\n##   <int> <dbl> <dbl>\n## 1     1     1     1\n## 2     2     4     8\n## 3     3     9    27\n## 4     4    16    64\n## 5     5    25   125\napply(dt, 1, mean) # mean of the rows## [1]  1.000000  4.666667 13.000000 28.000000 51.666667\napply(dt, 2, mean) # mean of the columns##  x  y  z \n##  3 11 45\n# row/column means\nrowMeans(dt)## [1]  1.000000  4.666667 13.000000 28.000000 51.666667\ncolMeans(dt)##  x  y  z \n##  3 11 45\nmy_list <- list(dt/3, dt/5);my_list## [[1]]\n##           x         y          z\n## 1 0.3333333 0.3333333  0.3333333\n## 2 0.6666667 1.3333333  2.6666667\n## 3 1.0000000 3.0000000  9.0000000\n## 4 1.3333333 5.3333333 21.3333333\n## 5 1.6666667 8.3333333 41.6666667\n## \n## [[2]]\n##     x   y    z\n## 1 0.2 0.2  0.2\n## 2 0.4 0.8  1.6\n## 3 0.6 1.8  5.4\n## 4 0.8 3.2 12.8\n## 5 1.0 5.0 25.0\nlapply(my_list, \"[\", 1, )  # print first row## [[1]]\n##           x         y         z\n## 1 0.3333333 0.3333333 0.3333333\n## \n## [[2]]\n##     x   y   z\n## 1 0.2 0.2 0.2\nsapply(my_list, rowSums)   # sum on rows##           [,1] [,2]\n## [1,]  1.000000  0.6\n## [2,]  4.666667  2.8\n## [3,] 13.000000  7.8\n## [4,] 28.000000 16.8\n## [5,] 51.666667 31.0\nlapply(my_list, round, 1)  # round to first decimal## [[1]]\n##     x   y    z\n## 1 0.3 0.3  0.3\n## 2 0.7 1.3  2.7\n## 3 1.0 3.0  9.0\n## 4 1.3 5.3 21.3\n## 5 1.7 8.3 41.7\n## \n## [[2]]\n##     x   y    z\n## 1 0.2 0.2  0.2\n## 2 0.4 0.8  1.6\n## 3 0.6 1.8  5.4\n## 4 0.8 3.2 12.8\n## 5 1.0 5.0 25.0\n# For more complex operations, use it this way:\nsapply(1:nrow(dt), function(i){\n    dt$x[i] + dt$y[(i+2)%%nrow(dt)+1] - dt$z[(i+4)%%nrow(dt)+1]\n})## [1]   16   19  -23  -56 -111"},{"path":"conditional-actions-and-loops.html","id":"exo-loops","chapter":"10 Conditional actions and loops","heading":"10.4 Exercises","text":"Given x <- runif(1e3, min=-1, max=1), create tibble like one:Given:Print sum element LL list, vector.Download population.csv load data.frameWhat total population years?mean population city?","code":"## # A tibble: 1,000 × 2\n##          x y    \n##      <dbl> <chr>\n##  1  0.0681 x>0  \n##  2 -0.346  x<=0 \n##  3  0.387  x>0  \n##  4 -0.971  x<=0 \n##  5 -0.245  x<=0 \n##  6 -0.491  x<=0 \n##  7  0.345  x>0  \n##  8  0.797  x>0  \n##  9  0.258  x>0  \n## 10  0.228  x>0  \n## # … with 990 more rows\nLL <- list(A = runif(1e2),\n           B = rnorm(1e3),\n           C = data.frame(x=runif(1e2), y=runif(1e2))\n           )\nLL <- list(A = runif(1e2),\n           B = rnorm(1e3),\n           C = data.frame(x=runif(1e2), y=runif(1e2))\n           )\nlapply(LL, sum)## $A\n## [1] 51.42577\n## \n## $B\n## [1] -11.4057\n## \n## $C\n## [1] 96.59506\nunlist(lapply(LL, sum)); sapply(LL, sum)##         A         B         C \n##  51.42577 -11.40570  96.59506##         A         B         C \n##  51.42577 -11.40570  96.59506\n# Download population.csv and load it into a `data.frame`\ndf <- read.csv(\"Data/population.csv\")\n# What is the total population over the years?\ndata.frame(year=df[,\"year\"],\n           pop =rowSums(df[,-1]),     # a first way\n           pop2=apply(df[,-1], 1, sum)# another way\n          )##   year     pop    pop2\n## 1 1962 7349547 7349547\n## 2 1968 7550999 7550999\n## 3 1975 7298183 7298183\n## 4 1982 6933230 6933230\n## 5 1990 6857291 6857291\n## 6 1999 6965325 6965325\n## 7 2007 7235114 7235114\n## 8 2012 7334805 7334805\n# A tidy-compatible version \nlibrary(tidyverse)\npopul <- pivot_longer(df, cols=-year, names_to=\"city\", values_to=\"pop\")\npopul %>%\n  group_by(year) %>%\n  summarise(totpop = sum(pop))## # A tibble: 8 × 2\n##    year  totpop\n##   <int>   <int>\n## 1  1962 7349547\n## 2  1968 7550999\n## 3  1975 7298183\n## 4  1982 6933230\n## 5  1990 6857291\n## 6  1999 6965325\n## 7  2007 7235114\n## 8  2012 7334805\n# or equivalently\nsummarise(group_by(popul, year), totpop = sum(pop))## # A tibble: 8 × 2\n##    year  totpop\n##   <int>   <int>\n## 1  1962 7349547\n## 2  1968 7550999\n## 3  1975 7298183\n## 4  1982 6933230\n## 5  1990 6857291\n## 6  1999 6965325\n## 7  2007 7235114\n## 8  2012 7334805\n# What is the mean population for each city?\napply(df[,-1], 2, mean)##        Angers      Bordeaux         Brest         Dijon      Grenoble \n##      138783.4      234814.9      149125.1      146735.2      157526.4 \n##       LeHavre        LeMans         Lille          Lyon     Marseille \n##      193989.6      144347.4      220018.4      470371.1      844253.4 \n##   Montpellier        Nantes          Nice         Paris         Reims \n##      203114.4      260924.9      334311.6     2321031.9      172278.0 \n##        Rennes Saint.Etienne    Strasbourg        Toulon      Toulouse \n##      193424.9      198134.6      255429.1      169682.6      382264.9\npopul %>%\n  group_by(city) %>%\n  summarise(avepop = mean(pop))## # A tibble: 20 × 2\n##    city            avepop\n##    <chr>            <dbl>\n##  1 Angers         138783.\n##  2 Bordeaux       234815.\n##  3 Brest          149125.\n##  4 Dijon          146735.\n##  5 Grenoble       157526.\n##  6 LeHavre        193990.\n##  7 LeMans         144347.\n##  8 Lille          220018.\n##  9 Lyon           470371.\n## 10 Marseille      844253.\n## 11 Montpellier    203114.\n## 12 Nantes         260925.\n## 13 Nice           334312.\n## 14 Paris         2321032.\n## 15 Reims          172278 \n## 16 Rennes         193425.\n## 17 Saint.Etienne  198135.\n## 18 Strasbourg     255429.\n## 19 Toulon         169683.\n## 20 Toulouse       382265."},{"path":"plotting.html","id":"plotting","chapter":"11 Plotting","heading":"11 Plotting","text":"Now seen basics, let’s start fun stuff !two main ways plot data R:Using base graphics, native R plotting deviceUsing package ggplot2 tidy data framesggplot2 extremely powerful people advise even teaching base graphics beginners. find times ’s just quicker/easier base graphics, still present , although full details.","code":""},{"path":"plotting.html","id":"base-graphics","chapter":"11 Plotting","heading":"11.1 Base graphics","text":"","code":""},{"path":"plotting.html","id":"basic-plotting","chapter":"11 Plotting","heading":"11.1.1 Basic plotting","text":"","code":"\nx  <- seq(-3*pi,3*pi,length=50)\ny  <- sin(x)\nz  <- sin(x)^2\ndf <- data.frame(x=x, y=y)\nplot(x,y) # plot providing x and y data\nplot(df)  # plot providing a two-columns data.frame\nplot(df, type=\"l\")\nplot(df, type=\"b\")\ndf <- data.frame(x=x, y=y, z=z, w=z*y)\nplot(df)  # plot providing a multi-columns data.frame"},{"path":"plotting.html","id":"adding-some-style","chapter":"11 Plotting","heading":"11.1.2 Adding some style","text":"OK, easy. Now let’s tuning , ’s tad ugly…\nType command see .needs covered simple plot can adapted.Go Rstudio Preferences, Code, Edit code snippets, add following lines:Lets create plot different panels (bit ugly without styling, need tweak margins text distance plot par(mar(), mgp()) plot):Try reproducing plots:","code":"\n# create some fake data\nx  <- seq(-3*pi,3*pi,length=100)\ndf <- data.frame(x=x, y=sin(x), z=sin(x)^2)\n# add some styling parameters\npar(family = \"Helvetica\", cex.lab=1.5, cex.axis=1.4, \n    mgp = c(2.4, .5, 0), tck=0.02, mar=c(4, 4, 2, .5), lwd=2, las=1)\nplot(df$x,df$y,\n     type = \"l\",     # \"l\" for lines, \"p\" for points\n     xlab = \"X values\",\n     ylab = \"Intensity\",\n     axes = FALSE,\n     main = \"Some Plot\",\n     ylim = c(-1,2)\n    )\n# vertical line in 0\nabline(v=0,lty=2,lwd=2)\n# horizontal line in 0\nabline(h=0,lty=3,lwd=2)\n# line with coefficients a (intercept) and b (slope)\nabline(a=0,b=.1,lty=4,lwd=1)\n# add a line\nlines(df$x,df$z,type = \"l\",col=\"red\",lwd=3)\n# add points\npoints(df$x,df$z*df$y,col=\"royalblue\",pch=16,cex=1)\n# add custom axis. \n# Default with axis(1);axis(2);axis(3, labels=FALSE);axis(4, labels=FALSE);\n# Bottom\naxis(1,at=seq(-10,10,2),labels=TRUE,tck=0.02)\naxis(1,at=seq(-10,10,1),labels=FALSE,tck=0.01); # small inter-ticks\n# Top\naxis(3,at=seq(-10,10,2),labels=FALSE)\naxis(3,at=seq(-10,10,1),labels=FALSE,tck=0.01); # small inter-ticks\n# Left\naxis(2,at=seq(-1,2,.5),labels=TRUE)\naxis(2,at=seq(-1,2,.25),labels=FALSE,tck=0.01); # small inter-ticks\n# Right\naxis(4,at=seq(-1,2,.5),labels=FALSE)\naxis(4,at=seq(-1,2,.25),labels=FALSE,tck=0.01); # small inter-ticks\n# Draw a box\nbox()\n# Print legend\nlegend(\"topleft\",\n    cex=1.4, #size of text\n    lty=c(1,1,NA),   # type of line (1 is full, 2 is dashed...)\n    lwd=c(1,3,NA),   # line width\n    pch=c(NA,NA,16), # type of points\n    col=c(\"black\",\"red\",\"royalblue\"), # color\n    bty = \"n\", # no box around legend\n    legend=c(\"sin(x)\",expression(\"sin(x)\"^2),expression(\"sin(x)\"^3))\n    )snippet plot\n    #pdf(\"xxx.pdf\", height=6, width=8)\n    par(cex.lab=1.7, cex.axis=1.7, mgp = c(3, 0.9, 0), \n        tck=0.02, mar=c(4.5, 4.5, 1, 1), lwd = 3, las=1)\n    plot(${1:x},${2:y},\n        type=\"l\",      # plot with a line\n        ylim=c( , ),\n        xlim=c( , ),\n        lwd=2,         # width of the line\n        lty=1,         # type of line\n        axes=FALSE,    # do not show axes\n        xlab=\"${1:x}\", # x label\n        ylab=\"${2:y}\", # y label\n        main=\"\")       # Title\n    legend(\"topright\",\n        cex=1.5,       # size of the text\n        pch=c(),       # list of point types\n        lty=c(),       # list of line types\n        lwd=c(),       # list of line widths\n        col=c(),       # list of line colors\n        bty=\"n\",       # no box around the legend\n        legend=c()     # list of legend labels\n        )\n    # Draw axes with minor ticks\n    axis(1, at=seq(0,1,.2), labels=TRUE)\n    axis(1, at=seq(0,1,.1), labels=FALSE, tck=0.01)\n    axis(3, at=seq(0,1,.2), labels=FALSE)\n    axis(3, at=seq(0,1,.1), labels=FALSE, tck=0.01)\n    par(mgp = c(2.5, 0.2, 0))\n    axis(2, at=seq(0,10,1), labels=TRUE)\n    axis(2, at=seq(0,10,.5), labels=FALSE, tck=0.01)\n    axis(4, at=seq(0,10,1), labels=FALSE)\n    axis(4, at=seq(0,10,.5), labels=FALSE, tck=0.01)\n    box() # drow box around plot\n    #dev.off()\n\nsnippet ggplot\n    library(ggplot2)\n    ggplot(data=${1:df}, aes(x=${2:x}, y=${3:y}, color=${4:z}, size=${5:w})) +\n        geom_point() +\n        geom_smooth() +\n        theme_bw()\n# some fake data\nx  <- seq(-10,10,1)\nd1 <- data.frame(x=x, y=sin(x))\nd2 <- data.frame(x=x, y=cos(x))\nd3 <- data.frame(x=x, y=exp(-x^2)*sin(x)^2)\n# on a simple grid, use:\n# par(mfrow=c(nrows, ncols))\npar(mfrow=c(1, 3), mar=c(4,4,1,1))\nplot(d1,type=\"l\")\nplot(d2,type=\"p\")\nplot(d3,type=\"b\")\n# creating the layout and styling\nM  <- matrix(c(c(1,1),c(2,3)), byrow=TRUE, ncol=2); M##      [,1] [,2]\n## [1,]    1    1\n## [2,]    2    3\nnf <- layout(M, heights=c(1), widths=c(1))\n# first plot\nplot(d1,type=\"l\")\n# second plot\nplot(d2,type=\"p\")\n# third plot\nplot(d3,type=\"b\")\n# creating the layout and styling\nM  <- matrix(c(c(1,1),c(2,3)), byrow=FALSE, ncol=2); M##      [,1] [,2]\n## [1,]    1    2\n## [2,]    1    3\nnf <- layout(M, heights=c(1), widths=c(1))\n# first plot\nplot(d1,type=\"l\")\n# second plot\nplot(d2,type=\"p\")\n# third plot\nplot(d3,type=\"b\")\nx <- rnorm(1e4, mean = 0, sd = 1)\n# Barplot\nhist(x)\n# Density\ny  <- density(x, bw=0.1) # small kernel bandwidth\ny2 <- density(x, bw=0.5) # larger kernel bandwidth\nplot(y, lwd=2, main=\"\", xlab=\"X values\", xlim=c(-4,4))\nlines(y2,col=\"red\",lwd=2)\npoints(x, jitter(rep(.01,length(x)), amount=.01), \n        cex=1,pch=16, col=adjustcolor(\"royalblue\", alpha=.01))"},{"path":"plotting.html","id":"panel-plots","chapter":"11 Plotting","heading":"11.1.2.1 Panel plots","text":"Lets create plot different panels (bit ugly without styling, need tweak margins text distance plot par(mar(), mgp()) plot):","code":"\n# some fake data\nx  <- seq(-10,10,1)\nd1 <- data.frame(x=x, y=sin(x))\nd2 <- data.frame(x=x, y=cos(x))\nd3 <- data.frame(x=x, y=exp(-x^2)*sin(x)^2)\n# on a simple grid, use:\n# par(mfrow=c(nrows, ncols))\npar(mfrow=c(1, 3), mar=c(4,4,1,1))\nplot(d1,type=\"l\")\nplot(d2,type=\"p\")\nplot(d3,type=\"b\")\n# creating the layout and styling\nM  <- matrix(c(c(1,1),c(2,3)), byrow=TRUE, ncol=2); M##      [,1] [,2]\n## [1,]    1    1\n## [2,]    2    3\nnf <- layout(M, heights=c(1), widths=c(1))\n# first plot\nplot(d1,type=\"l\")\n# second plot\nplot(d2,type=\"p\")\n# third plot\nplot(d3,type=\"b\")\n# creating the layout and styling\nM  <- matrix(c(c(1,1),c(2,3)), byrow=FALSE, ncol=2); M##      [,1] [,2]\n## [1,]    1    2\n## [2,]    1    3\nnf <- layout(M, heights=c(1), widths=c(1))\n# first plot\nplot(d1,type=\"l\")\n# second plot\nplot(d2,type=\"p\")\n# third plot\nplot(d3,type=\"b\")"},{"path":"plotting.html","id":"barplots-and-densities","chapter":"11 Plotting","heading":"11.1.2.2 Barplots and densities","text":"Try reproducing plots:","code":"\nx <- rnorm(1e4, mean = 0, sd = 1)\n# Barplot\nhist(x)\n# Density\ny  <- density(x, bw=0.1) # small kernel bandwidth\ny2 <- density(x, bw=0.5) # larger kernel bandwidth\nplot(y, lwd=2, main=\"\", xlab=\"X values\", xlim=c(-4,4))\nlines(y2,col=\"red\",lwd=2)\npoints(x, jitter(rep(.01,length(x)), amount=.01), \n        cex=1,pch=16, col=adjustcolor(\"royalblue\", alpha=.01))"},{"path":"plotting.html","id":"advanced-plotting-using-ggplot2","chapter":"11 Plotting","heading":"11.2 Advanced plotting using ggplot2","text":"reading cheatsheet example.ggplot2 package (now even available python) completely changes methodology plotting data. ggplot2, data gathered tidy data.frame, column can used parameter tweak colors, point size, etc.First things first, load library :Actually, ggplot2 attached tidyverse simple library(tidyverse) enough.","code":"\nlibrary(ggplot2)\nlibrary(tidyverse) # for easier data manipulation"},{"path":"plotting.html","id":"the-grammar-of-graphics","chapter":"11 Plotting","heading":"11.2.1 The grammar of graphics","text":"ggplot2 introduced notion “grammar graphics” function ggplot(). means plots built independent blocks can combined create wanted graphical display.\nconstruct plot, need provide building blocks :data gathered tidy data.framean aesthetics mapping: column x, y, color, size, etc…geometric object: point, line, bar, histogram, tile…statistical transformations neededscales: color_manual, x_continuous, …coordinate systemfaceting: wrap, gridtheme: theme_bw(), theme_light()…typical call ggplot() thus (arguments <> specify):Since figure worth thousand words, let’s get . use dataset diamonds built-ggplot2 package. Let’s look:diamonds contains 53940 lines 10 columns tibble. ggplot2 can easily handle large dataset.Let’s say want see whether correlation price weight (carat) diamonds:OK, ’re onto something, can probably add information plot. first cut data 3 carats relevant, add transparency points see statistical information.Let’s now see whether clarity plays role coloring points according diamonds cut:looks like price dispersion homogeneous, can make sure adding spline smoothing:slope evolution shows general, better cut, higher price. discrepancies may explained another manner:often easier grasp multi-variable problem plotting data facet plot using facet_wrap(~variable1) want one variable changing plot:… facet_grid(variable1~variable2) want see one variable function another:adding another graphical parameter size points:OK, maybe graph gets clogged, can lighten sampling data:","code":"ggplot(data=<data>, aes(x=<x>, y=<y>, color=<z>, size=<w>))+\n    geom_<geometry>()+\n    scale_<scales>()+\n    facet_<facets>()+\n    <theme>\ndiamonds## # A tibble: 53,940 × 10\n##    carat cut       color clarity depth table price     x     y     z\n##    <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n##  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n##  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n##  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n##  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n##  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n##  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n##  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n##  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n##  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n## 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n## # … with 53,930 more rows\np <- ggplot(data = diamonds, aes(x = carat,y = price))\np + geom_point()\np <- diamonds %>% filter(carat<=3) %>% \n        ggplot(aes(x = carat, y = price))\np + geom_point(alpha=0.5)\np <- diamonds %>% filter(carat<=3) %>% \n        ggplot(aes(x = carat, y = price, color = cut))\np + geom_point(alpha=0.5)\np + geom_point(alpha=0.5) + geom_smooth()\np <- diamonds %>% filter(carat<=3) %>% \n        ggplot(aes(x = carat, y = price, color = clarity))\np + geom_point(alpha=0.5) + geom_smooth()\ncolors <- rainbow(length(unique(diamonds$clarity)))\np <- ggplot(diamonds, aes(x = price, y = carat)) + \n        geom_point(aes(color = clarity), alpha = 0.5, size = 1) + \n        geom_smooth(color = \"black\") + \n        scale_colour_manual(values = colors, name = \"Clarity\") +\n        facet_wrap(~cut) \np\np <- ggplot(diamonds, aes(x = price, y = carat)) + \n        geom_point(aes(color = color), alpha = 0.8, size = 1) + \n        geom_smooth(method=\"lm\", color = \"black\") + \n        scale_colour_brewer(palette = \"Spectral\", name = \"Color\") +\n        facet_grid(clarity~cut) \np\np <- ggplot(diamonds, aes(x = price, y = carat, size = cut)) + \n        geom_point(aes(color = clarity), alpha = 0.5) + \n        scale_colour_manual(values = colors, name = \"Clarity\")\np\np <- ggplot(diamonds %>% sample_n(500), \n            aes(x = carat, y = price, size = cut)) + \n        geom_point(aes(color = clarity), alpha = 0.5) + \n        scale_colour_manual(values = colors, name = \"Clarity\")\np"},{"path":"plotting.html","id":"theming","chapter":"11 Plotting","heading":"11.2.2 Theming","text":"easy keep theme graphs thanks theme() function.\ncollection pre-defined themes, like:can define parameters want, like (hit ?theme like usual see parameters):","code":"\nmy_theme <- theme_bw()+\n            theme(text = element_text(size = 18, family = \"Times\", face = \"bold\"),\n                  axis.ticks = element_line(size = 1),\n                  legend.text = element_text(size = 14, family = \"Times\"),\n                  panel.border = element_rect(size = 2),\n                  panel.grid.major = element_blank(), \n                  panel.grid.minor = element_blank()\n                  )\np + my_theme"},{"path":"plotting.html","id":"making-interactive-plots-with-ggplot2-and-plotly","chapter":"11 Plotting","heading":"11.2.3 Making interactive plots with ggplot2 and plotly","text":"Thanks plotly package, really easy transform ggplot plot interactive plot:","code":"\n# load plotly\nlibrary(plotly)\np <- ggplot(diamonds %>% sample_n(100), \n        aes(x = carat, y = price)) + \n        geom_point(aes(color = clarity), alpha = 0.5, size = 2) + \n        my_theme\nggplotly(p, dynamicTicks = TRUE)"},{"path":"plotting.html","id":"gathering-plots-on-a-grid","chapter":"11 Plotting","heading":"11.2.4 Gathering plots on a grid","text":"several plot want gather grid can’t use facet_wrap() (come different data sets), can use library patchwork:","code":"\nlibrary(patchwork)\nlibrary(ggplot2)\ntheme_set(theme_bw())\nx  <- seq(-2*pi,2*pi,.1)\np1 <- qplot(x,sin(x), geom = \"line\")\np2 <- qplot(x,cos(x), geom = \"line\")\np3 <- qplot(x,atan(x), geom = \"line\")\np4 <- qplot(x,dnorm(x), geom = \"line\")\np1 + p2\np1 + p2 / p3 + p4 + \n    plot_annotation(tag_levels = 'a', tag_suffix=\")\")\n(p1 + p2 + plot_layout(widths = c(1,3))) /\np3/p4 + \n    plot_layout(heights = c(6, 2, 1))"},{"path":"plotting.html","id":"plots-with-insets","chapter":"11 Plotting","heading":"11.2.5 Plots with insets","text":"want make inset plot, first make plots, add plot within using patchwork::inset_element(), specifying x y positions 4 corners inset plot using relative values:","code":"\nlibrary(ggplot2)\np4 + inset_element(p3, left   = 0.01, right = .4, \n                       bottom = .45,    top = .99)"},{"path":"plotting.html","id":"exporting-a-plot-to-pdf-or-png","chapter":"11 Plotting","heading":"11.3 Exporting a plot to pdf or png","text":"","code":""},{"path":"plotting.html","id":"a-single-plot","chapter":"11 Plotting","heading":"11.3.1 A single plot","text":"plot can exported surrounded XXX dev.(), XXX can pdf(\"xxx.pdf\",height=6, width=8), png(\"xxx.png\",height=600, width=800)… Examples:can also export graph .tex file using tikz(), allows use \\(\\LaTeX\\) mathematical expressions (don’t forget escape \\ character):","code":"\nP <- ggplot(df, aes(x,y)) + geom_point()\npdf(\"plot.pdf\",height=6, width=8)\nP\ndev.off()\npdf(\"plot.png\",height=600, width=800)\nplot(x,y,\n     type=\"l\",\n     xlab=\"x\"\n     )\ndev.off()\nlibrary(tikzDevice)\ntikz(\"plot.tex\",height=6, width=8, pointsize = 10, standAlone=TRUE)\nplot(x,y,\n     type=\"l\",\n     xlab=\"$\\\\omega_i$\"\n     )\ndev.off()\ntools::texi2pdf(\"plot.tex\") # compile the tex fileto pdf\nsystem(\"open -a Skim plot.pdf\") # on Mac: open the resulting pdf with Skim"},{"path":"plotting.html","id":"multiple-plots","chapter":"11 Plotting","heading":"11.3.2 Multiple plots","text":"case want output multiple plots loop, two options:Ouptut separate file plotFor pdf output : ouptut single file plot different pageIn cases, plot ggplot (always recommend), need explicitly print() plot loop, like :Output separate file plot:Output single file page plot:","code":"\nfor(i in 1:4){\n    plot_name = paste0(\"plot_\",i,\".pdf\")\n    P <- ggplot(my_data[[i]], aes(x, y)) + geom_point()\n    pdf(plot_name, height = 6, width = 8)\n    print(P)\n    dev.off()\n}\npdf(\"plots.pdf\", height = 6, width = 8)\nfor(i in 1:4){\n    P <- ggplot(my_data[[i]], aes(x, y)) + geom_point()\n    print(P)\n}\ndev.off()"},{"path":"plotting.html","id":"exo-plots","chapter":"11 Plotting","heading":"11.4 Exercises","text":"Interactive exercises can found tutor package. , simply run:Download two sample Raman spectra: PPC60_G_01.txt PPC60_G_30.txtLoad two separate tibbleGather two data.frame another single tidy one: three columns, w, Intensity file_nameCreate function norm01() , given vector, returns vector normalized [0,1]Using group_by() mutate(), add column norm_int normalized intensity filePlot two normalized spectra graph using lines different colorsPlay theme parameters reproduce following plot:Download rubis_01.txt, rubis_02.txt, rubis_03.txt rubis_04.txt load tidy tibble.Normalize data [0,1] 4th columnPlot 4 spectra top vertical shift 1, different color spectrum\n, check factor() function:\n, check factor() function:Annotate base line name file. , use annotate(\"text\", x, y, label)look like :Download dataG.zipMake plot similar one (don’t bother fit), plotting evolution Raman spectrum function pressure:Bonus:Looking data increasing pressures\nPlot data using interactive slider (see frame option )\nPlot data using 3D color map. Since data regular grid, need interpolate data regular grid akima package interp() function. See chapter 12 3D plotting help.\nPlot data using interactive slider (see frame option )Plot data using 3D color map. Since data regular grid, need interpolate data regular grid akima package interp() function. See chapter 12 3D plotting help.Download population.csv load data.frameIs tidy data.frame?\nwant tidy data.frame?\n?\nAct accordingly\nwant tidy data.frame??Act accordinglyPlot population vs. year color city\npoints\nlines\nblack white theme\nMake interactive\npointsWith linesWith black white themeMake interactiveTry reproducing following plots (Google friend) (look function reorder() help use facets):","code":"\nlibrary(tutor)\ntuto(\"plots\")\n# Load them in two separate `tibbles`\nlibrary(tidyverse)\n# Using read.table (who returns a data.frame)\ndf1 <- read.table(\"Data/PPC60_G_01.txt\", col.names=c(\"w\",\"Intensity\"))\ndf2 <- read.table(\"Data/PPC60_G_30.txt\", col.names=c(\"w\",\"Intensity\"))\ndf1 <- tibble(df1) # make a tibble from a data.frame\ndf2 <- tibble(df2)\n# Direct version using tidyverse (read_table returns a tibble)\ndf1 <- read_table(\"Data/PPC60_G_01.txt\", col_names=c(\"w\",\"Intensity\"))\ndf2 <- read_table(\"Data/PPC60_G_30.txt\", col_names=c(\"w\",\"Intensity\"))\n# Gather the two `tibbles` in another single tidy one: \n# it should have three columns, `w`, `Intensity` and `file_name`\ndf1$file_name <- \"PPC60_G_01\" # add the \"file_name\" column\ndf2$file_name <- \"PPC60_G_30\"\ndf_tidy <- bind_rows(df1,df2) # stack the two tibbles\n# Create a function `norm01` that, given a vector, returns the same vector normalized to [0,1]\nnorm01 <- function(x) {\n    (x-min(x))/(max(x)-min(x))\n}\n# Using `group_by` and `mutate`, add a column `norm_int` in df_tidy of normalized intensity for each file\ndf_tidy <- df_tidy %>% \n    group_by(file_name) %>% \n    mutate(norm_int=norm01(Intensity))\n# Plot the two normalized spectra on the same graph using lines of different colors\nlibrary(ggplot2)\ndf_tidy %>% \n    ggplot(aes(x=w, y=norm_int, color=file_name))+\n        geom_line()+\n        theme_bw()\n# Play with the theme and parameters to reproduce the following plot:\ndf_tidy %>% \n    ggplot(aes(x=w, y=norm_int, color=file_name)) +\n        geom_line()+\n        scale_color_manual(values=c(\"red\",\"royalblue\"), name=\"\") +\n        labs(x=\"Raman Shift [1/cm]\", y=\"Intensity [arb. unit]\") +\n        theme_bw() +\n        theme(legend.position = \"top\",\n              text = element_text(size = 14,family = \"Times\"),\n              panel.grid.major = element_blank(), \n              panel.grid.minor = element_blank())\nx <- c(\"a\",\"a\",\"b\",\"c\",\"a\")\nfactor(x)## [1] a a b c a\n## Levels: a b c\nas.numeric(factor(x))## [1] 1 1 2 3 1\nlibrary(tidyverse)\nlibrary(ggplot2)\ndf <- tibble()\nnorm01 <- function(x) {\n    (x-min(x))/(max(x)-min(x))\n}\nfor (i in 1:4) {\n    d  <- read_table(paste0(\"Data/rubis_0\",i,\".txt\"), col_names=c(\"w\", \"Int\"))\n    d$Int_n <- norm01(d$Int)\n    d$name  <- paste0(\"rubis_0\",i)\n    df      <- bind_rows(df, d)\n}\nfnames <- unique(df$name)\nggplot(data=df, aes(x=w, \n                    y=Int_n+as.numeric(factor(name))-1, \n                    color=name))+\n    geom_line(size=1)+\n    annotate(\"text\", x=3080, y=1:length(fnames)-.85, label=fnames, size=5)+\n    labs(x=\"Raman Shift [1/cm]\", y=\"Intensity [arb. units]\")+\n    theme_bw()+\n    theme(legend.position = \"none\",\n          text            = element_text(size = 14),\n          axis.text.y     = element_blank(),\n          axis.text       = element_text(size = 14))\n# get the list of files for the ramps up and down and out of cell\nfiles_up   <- list.files(\"Data/dataG/\", pattern=\"up\")\nfiles_down <- list.files(\"Data/dataG/\", pattern=\"down\")\nout_cell   <- list.files(\"Data/dataG/\", pattern=\"out\")\n# store all file names in the correct order\nallfiles <- c(out_cell, files_up, files_down)\n# load the wanted package\nlibrary(tidyverse)\nlibrary(ggplot2)\n# create the norm01 function\nnorm01 <- function(x) { (x-min(x))/(max(x)-min(x)) }\n# initialize an empty tibble to store all data\nalldata <- tibble()\nfor (file in allfiles) {#file <- allfiles[1]\n    # read the data and stor it in d\n    d <- read_table(paste0(\"Data/dataG/\",file), col_names=TRUE)\n    # normalize data\n    d$Int_n <- norm01(d$Int)\n    # store file name\n    d$name <- file\n    # store run number for the stacking\n    d$run_number <- which(file==allfiles)\n    # store all data in a single tidy tibble\n    alldata <- bind_rows(alldata, d)\n}\n# plot all data\nalldata %>% \n    filter(w<=1750, w>=1500) %>% # zoom on the interesting part\n    ggplot(aes(x=w, \n               y=Int_n + run_number - 1))+ # to stack the plots\n        geom_point(color=\"gray\", alpha=.5, size=.2)+ #plot data with points\n        xlim(c(1500,1800))+ #add some white space on the right to write the pressure\n        geom_vline(xintercept=1592, lty=2, size=1)+#show a vertical line\n        annotate(geom  = \"text\", size=5, #show the pressure values\n                 x = 1760, y=seq_along(allfiles)-1, hjust = 0,\n                 label  = paste(unique(alldata$P),\"GPa\"),\n                 family = \"Times\")+\n        labs(x=\"Raman Shift [1/cm]\", #have the good axis labels\n             y=\"Intensity [arb. units]\")+\n        theme_bw()+#black and white theme\n        theme(legend.position = \"none\",#no legend\n              text            = element_text(size = 14, family = \"Times\"),#text in font Times\n              axis.text.y     = element_blank(),# no y axis values\n              axis.text       = element_text(size = 14),\n              panel.grid.major = element_blank(), # no grid\n              panel.grid.minor = element_blank())\n# Looking at data for increasing pressures, plot the data using an interactive slider\nlibrary(plotly)\nP <- alldata %>% \n    filter(grepl(\"up\",name)) %>% # only increasing pressures\n    filter(w<=1850, w>=1500) %>% # zoom on the interesting part\n    ggplot(aes(x=w, \n               y=Int_n,\n               frame=P))+ # each pressure in a new frame\n        geom_point(color=\"gray\", alpha=.5, size=1)+ #plot data with points\n        labs(x=\"Raman Shift [1/cm]\", #have the good axis labels\n             y=\"Intensity [arb. units]\")+\n        theme_bw()+#black and white theme\n        theme(legend.position = \"none\",#no legend\n              text            = element_text(size = 14, family = \"Times\"),\n              axis.text       = element_text(size = 14),\n              panel.grid.major = element_blank(), # no grid\n              panel.grid.minor = element_blank())\nggplotly(P, dynamicTicks = TRUE)\n# Plot the data using a 3D color map. Since the data are not on a regular grid, \n# you will need to interpolate the data on a regular grid \n# with the `akima` package and its `interp()` function\nlibrary(akima)\ntoplot <- alldata %>% \n            filter(grepl(\"up\",name)) %>%\n            filter(w<=1850, w>=1500)\ntoplot.interp <- with(toplot, \n                    interp(x = w, y = P, z = Int_n, \n                           duplicate=\"median\",\n                           xo=seq(min(toplot$w), max(toplot$w), length = 100),\n                           yo=seq(min(toplot$P), max(toplot$P), length = 100),\n                           extrap=FALSE, linear=FALSE)\n                   )\n# toplot.interp is a list of 2 vectors and a matrix\nstr(toplot.interp)## List of 3\n##  $ x: num [1:100] 1500 1504 1507 1511 1514 ...\n##  $ y: num [1:100] 2.12 2.35 2.59 2.82 3.06 ...\n##  $ z: num [1:100, 1:100] NA NA NA 0.0287 0.0291 ...\n# Regrouping this list to a 3-columns data.frame\nmelt_x <- rep(toplot.interp$x, times=length(toplot.interp$y))\nmelt_y <- rep(toplot.interp$y, each=length(toplot.interp$x))\nmelt_z <- as.vector(toplot.interp$z)\ntoplot.smooth <- na.omit(data.frame(w=melt_x, Pressure=melt_y, Intensity=melt_z))\n# Plotting\ncolors <- colorRampPalette(c(\"white\",\"royalblue\",\"seagreen\",\"orange\",\"red\",\"brown\"))(500)\nP <- ggplot(data=toplot.smooth, aes(x=w, y=Pressure, fill=Intensity)) + \n      geom_raster() + \n      scale_fill_gradientn(colors=colors, name=\"Normalized\\nIntensity\\n[arb. units]\") +\n      labs(x = \"Raman Shift [1/cm]\",y=\"Pressure [GPa]\") +\n      theme_bw()+\n      theme(text            = element_text(size = 14, family = \"Times\"),\n            axis.text       = element_text(size = 14),\n            panel.grid.major = element_blank(), # no grid\n            panel.grid.minor = element_blank())\nggplotly(P, dynamicTicks = TRUE)\n# Load and tidy population data.frame\nlibrary(tidyverse)\ndf <- read.csv(\"Data/population.csv\")\ndf <- pivot_longer(df, \n                   cols=-year, #year should stay a column\n                   names_to=\"City\", #column names should go to the column `city`\n                   values_to=\"Population\" #values should go to the column `population`\n                   )\ndf$City <- gsub(\"\\\\.\", \" \", df$City) # replace dots by spaces in city names\n# Plot the population vs. year with a different color for each city\np <- ggplot(data=df, aes(x=year, y=Population, color=City))\n# With points\np + geom_point()\n# With lines\np + geom_line()\n# With a black and white theme\n# Change the axis labels to \"year\" and \"Population\"\np <- p + geom_line() + theme_bw(); p\n# Make it interactive\nlibrary(plotly)\nggplotly(p, dynamicTicks = TRUE)\n# Reproduce the plots\nmy_theme <- theme_bw()+\n            theme(axis.text = element_text(size = 14,family = \"Helvetica\",colour=\"black\"),\n                  text = element_text(size = 14,family = \"Helvetica\"),\n                  axis.ticks = element_line(colour = \"black\"),\n                  legend.text = element_text(size = 10,family = \"Helvetica\",colour=\"black\"),\n                  panel.border = element_rect(colour = \"black\", fill=NA, size=1)\n                  )\ncolors <- c(\"royalblue\",\"red\")\np1 <- df %>% filter(City%in%c(\"Montpellier\",\"Nantes\")) %>% \n        ggplot(aes(x=year, y=Population, size=Population, color=City)) +\n            geom_point() + \n            geom_smooth(method=\"lm\", aes(fill=City), \n                        alpha=0.1, show.legend = FALSE) + \n            scale_color_manual(values=colors)+\n            scale_fill_manual(values=colors)+\n            ggtitle(\"Population in Montpellier and Nantes\")+\n            labs(x=\"Year\", y=\"Population\")+\n            my_theme \np1\np2 <- df %>% filter(year==2012) %>% \n        ggplot(aes(x=reorder(City,-Population), \n                   y=Population/1e6, \n                   fill=Population/1e6)) +\n            geom_bar(stat=\"identity\", position=\"dodge\") + \n            ggtitle(\"Population in 2012 (in millions)\")+\n            labs(x=\"\", y=\"Population (in millions)\")+\n            scale_fill_gradientn(colors=colors, \n                                 name=\"Population\\n(in millions)\") +\n            my_theme + \n            theme(axis.text.x = element_text(angle = 45, hjust=1))\np2"},{"path":"colorplots.html","id":"colorplots","chapter":"12 3D color plots","heading":"12 3D color plots","text":"may want plot data color map, like evolution Raman spectrum function temperature, pressure position. cases ’ll 3-columns data.frame x, y, z values (e.g. intensity peak function position sample), cases can list spectra evolving given parameter.","code":""},{"path":"colorplots.html","id":"the-ggplot2-solution","chapter":"12 3D color plots","heading":"12.1 The ggplot2 solution","text":"Let’s create dummy set spectra gather tidy tibble.OK, now fake experimental data stored tidy tibble called fake_data. want plot color map order grasp evolution spectra. can done use geom_contour() geom_contour_filled() functions providing z aesthetics, using geom_raster() geom_tile() functions fill aesthetics. methods can combined, shown :Another option make “ridge plot”, stacking plots:","code":"\nlibrary(tidyverse)\nNspec <- 40                           # Amount of spectra\nN     <- 500                          # Size of the x vector\n# Create a fake data tibble\nfake_data <- tibble(T = round(seq(273, 500, length=Nspec), 1)) %>% \n    mutate(spec = map(T, ~tibble(w = seq(0, 100, length = N),\n                         Intensity = 50*dnorm(w, mean = (./T[1])*20 + 25, \n                                                  sd  = 10+runif(1,max=5)))))\nfake_data## # A tibble: 40 × 2\n##        T spec              \n##    <dbl> <list>            \n##  1  273  <tibble [500 × 2]>\n##  2  279. <tibble [500 × 2]>\n##  3  285. <tibble [500 × 2]>\n##  4  290. <tibble [500 × 2]>\n##  5  296. <tibble [500 × 2]>\n##  6  302. <tibble [500 × 2]>\n##  7  308. <tibble [500 × 2]>\n##  8  314. <tibble [500 × 2]>\n##  9  320. <tibble [500 × 2]>\n## 10  325. <tibble [500 × 2]>\n## # … with 30 more rows\nfake_data <- fake_data %>% unnest(spec)\nfake_data## # A tibble: 20,000 × 3\n##        T     w Intensity\n##    <dbl> <dbl>     <dbl>\n##  1   273 0       0.00385\n##  2   273 0.200   0.00406\n##  3   273 0.401   0.00428\n##  4   273 0.601   0.00451\n##  5   273 0.802   0.00475\n##  6   273 1.00    0.00501\n##  7   273 1.20    0.00528\n##  8   273 1.40    0.00556\n##  9   273 1.60    0.00585\n## 10   273 1.80    0.00616\n## # … with 19,990 more rows\n# Plotting\ncolors <- colorRampPalette(c(\"white\",\"royalblue\",\"seagreen\",\n                             \"orange\",\"red\",\"brown\"))\nNbins <- 10\nggplot(data=fake_data, aes(x=w, y=T, z=Intensity)) + \n      geom_contour_filled(bins = Nbins) + \n      ggtitle(\"Some fake data\") + \n      scale_fill_manual(values = colors(Nbins),\n                        name = \"Intensity\\n[arb. units]\") +\n      labs(x = \"Fake Raman Shift [1/cm]\",\n           y = \"Fake Temperature [K]\") +\n      theme_bw()\nggplot(data=fake_data, aes(x = w, y = T)) + \n      geom_raster(aes(fill = Intensity)) + #geom_tile would work\n      geom_contour(aes(z = Intensity), color = \"black\", bins = 5)+\n      ggtitle(\"Some fake data\") + \n      scale_fill_gradientn(colors = colors(10), \n                           name = \"Intensity\\n[arb. units]\") +\n      labs(x = \"Fake Raman Shift [1/cm]\",\n           y = \"Fake Temperature [K]\") +\n      theme_bw()\ncolors <- colorRampPalette(c(\"royalblue\",\"seagreen\",\"orange\",\n                             \"red\",\"brown\"))(length(unique(fake_data$T)))\nggplot(data = fake_data, \n       aes(x = w, \n           y = Intensity + as.numeric(factor(T))-1,\n           color = factor(T))\n       ) + \n    geom_line() + \n    labs(x = \"Fake Raman Shift [1/cm]\", \n         y = \"Fake Intensity [arb. units]\") +\n    coord_cartesian(xlim = c(25,75)) +\n    scale_color_manual(values=colors,name=\"Fake\\nTemperature [K]\") +\n    theme_bw()\nggplot(data=fake_data, \n       aes(x = w, \n           y = Intensity + as.numeric(factor(T))-1, \n           color = T, \n           group = T)\n       )+\n    geom_line() + \n    labs(x=\"Fake Raman Shift [1/cm]\", y=\"Fake Intensity [arb. units]\") +\n    scale_color_gradientn(colors=colors,name=\"Fake\\nTemperature [K]\") +\n    coord_cartesian(xlim = c(25,75)) +\n    theme_bw()"},{"path":"colorplots.html","id":"the-base-graphics-solution","chapter":"12 3D color plots","heading":"12.2 The base graphics solution","text":"cases end matrix z, two vectors x y. easy plot using base image() function. sake example, let’s just pivot 3-columns data.frame matrix using pivot_wider():can add legend using image.plot function:","code":"\nx <- sort(unique(fake_data$w))\ny <- sort(unique(fake_data$T))\nz <- as.matrix(fake_data %>% \n                pivot_wider(values_from = Intensity, names_from = T) %>% \n                select(-w)\n               )\ncolors <- colorRampPalette(c(\"white\",\"royalblue\",\"seagreen\",\"orange\",\"red\",\"brown\"))(50)\npar(mar = c(4, 4, .5, 4), lwd = 2)\nimage(x, y, z, col = colors)\nlibrary(fields)\npar(mar=c(4, 4, .5, 4), lwd=2)\nimage.plot(x,y,z, col = colors)"},{"path":"colorplots.html","id":"the-plotly-solution","chapter":"12 3D color plots","heading":"12.3 The plotly solution","text":"finally, want make interactive plot, can use plot_ly():, cool, interactive surface plot:","code":"\nlibrary(plotly)\naX <- list(title = \"Raman Shift [1/cm]\")\naY <- list(title = \"Temperature [K]\")\n# Weird but you need to use t(z) here:\nz <- t(z)\n# Color plot\nplot_ly(x = x, y = y, z = z, type = \"heatmap\", colors = colors) %>% \n   layout(xaxis = aX, yaxis = aY)\nplot_ly(x=x, y=y, z=z, type = \"surface\", colors=colors) %>%\n   layout(scene = list(xaxis = aX, yaxis = aY, dragmode=\"turntable\"))"},{"path":"colorplots.html","id":"the-case-of-non-regular-data","chapter":"12 3D color plots","heading":"12.4 The case of non-regular data","text":"case set non-regular data, plotting color map can get tricky: tell plotting device color place data point?solution use spline (linear, spline looks usually nicer) interpolation 2D data. , can use akima package interp() function, like :","code":"\n# let's make our data irregular and see the plot is now not working:\nirreg.df <- fake_data[sample(nrow(fake_data), nrow(fake_data)/3),]\n# let's plot these irregular data\ncolors <- colorRampPalette(c(\"white\",\"royalblue\",\"seagreen\",\n                             \"orange\",\"red\",\"brown\"))(500)\nggplot(data=irreg.df, aes(x=w, y=T, fill=Intensity)) + \n      geom_raster() + #geom_tile would work\n      ggtitle(\"Some irregular and ugly fake data\") + \n      scale_fill_gradientn(colors=colors,name=\"Intensity\\n[arb. units]\") +\n      labs(x = \"Fake Raman Shift [1/cm]\",\n           y = \"Fake Temperature [K]\") +\n      theme_bw()\n# now let's interpolate the data on a 100x100 regular grid\n# linear = FALSE -> cubic interpolation\nlibrary(akima)\nirreg.df.interp <- with(irreg.df, \n    interp(x=w, y=T, z=Intensity, nx = 100, ny = 100,\n           duplicate = \"median\", extrap = FALSE, linear = FALSE)\n    )\n# irreg.df.interp is a list of 2 vectors and a matrix\nstr(irreg.df.interp)## List of 3\n##  $ x: num [1:100] 0 1.01 2.02 3.03 4.04 ...\n##  $ y: num [1:100] 273 275 278 280 282 ...\n##  $ z: num [1:100, 1:100] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...\n# Regrouping this list to a 3-columns data.frame\nirreg.df.smooth <- expand.grid(w = irreg.df.interp$x, \n                               T = irreg.df.interp$y) %>% \n                        tibble() %>% \n                        mutate(Intensity = as.vector(irreg.df.interp$z)) %>% \n                        na.omit()\n# Plotting\nirreg.df.smooth %>% \n    ggplot(aes(x=w, y=T, fill=Intensity)) + \n        geom_raster() + \n        ggtitle(\"Some irregular fake data that have been cubic-interpolated\") + \n        scale_fill_gradientn(colors=colors, name=\"Intensity\\n[arb. units]\") +\n        labs(x = \"Fake Raman Shift [1/cm]\", \n             y = \"Fake Temperature [K]\") +\n        theme_bw()"},{"path":"colorplots.html","id":"d-density-of-points","chapter":"12 3D color plots","heading":"12.5 2D density of points","text":"case want plot density points, variety solutions:base smoothScatter() function trick:","code":"\ndf <- tibble(x=rnorm(1e3, mean=c(1,5)),\n             y=rnorm(1e3, mean=c(5,1)))\np1 <- ggplot(data=df, aes(x=x,y=y))+ geom_density2d() + ggtitle('geom_density2d()')\np2 <- ggplot(data=df, aes(x=x,y=y))+ geom_hex() + ggtitle('geom_hex()')\np3 <- ggplot(data=df, aes(x=x,y=y))+ geom_bin2d() + ggtitle('geom_bin2d()')\np4 <- ggplot(data=df, aes(x=x,y=y))+ ggtitle('stat_density2d()') +\n        stat_density2d(aes(fill = ..density..), geom = \"tile\", contour = FALSE, n = 200) +\n        scale_fill_continuous(low = \"white\", high = \"dodgerblue4\")\nlibrary(cowplot)\nplot_grid(p1,p2,p3,p4)\nsmoothScatter(df)"},{"path":"fitting.html","id":"fitting","chapter":"13 Fitting","heading":"13 Fitting","text":"","code":""},{"path":"fitting.html","id":"linear-fitting-with-lm","chapter":"13 Fitting","heading":"13.1 Linear fitting with lm()","text":"","code":""},{"path":"fitting.html","id":"single-variable","chapter":"13 Fitting","heading":"13.1.1 Single variable","text":"Let’s learn simple linear fits R’s lm() plot results. Let’s start creating fake data:see data shows linear evolution, might want extract slope (0.22) intercept (1.5). simply done applying lm() function, like :Now see fit results, can just display fit, call summary(fit)actually retrieve store fit parameters, call coef(fit)get properly stored tibble, see broom package describe later chapter:get standard error fitted parameters R2:finally, plot result fit:function geom_smooth() fit data display fitted line, retrieve actual coefficients still need run lm().Finally, may want impose intercept 0 given value. , need add +0 formula, like :","code":"\n# Create some fake data\nd <- tibble(x = 1:10,\n            y = 1.5 + 0.22*x + .5*runif(10))\nggplot(d, aes(x = x, y = y)) +\n    geom_point() +\n    expand_limits(x = 0, y = 0)\n# Fit with a linear model:\n# 3 equivalent ways of calling it\nfit <- lm(data = d, y ~ x)\nfit <- lm(d$y ~ d$x)\nfit <- d %>% lm(data=., y ~ x)\n# Summary of the fit\nfit## \n## Call:\n## lm(formula = y ~ x, data = .)\n## \n## Coefficients:\n## (Intercept)            x  \n##       1.819        0.210\nsummary(fit)## \n## Call:\n## lm(formula = y ~ x, data = .)\n## \n## Residuals:\n##       Min        1Q    Median        3Q       Max \n## -0.124342 -0.095042  0.009266  0.052357  0.209865 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  1.81928    0.07531   24.16 9.19e-09 ***\n## x            0.20999    0.01214   17.30 1.27e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1102 on 8 degrees of freedom\n## Multiple R-squared:  0.974,  Adjusted R-squared:  0.9707 \n## F-statistic: 299.4 on 1 and 8 DF,  p-value: 1.268e-07\n# Retrieve the coefficients and errors\ncoef(fit)## (Intercept)           x \n##   1.8192834   0.2099929\ncoef(fit)[1]## (Intercept) \n##    1.819283\ncoef(fit)['(Intercept)']## (Intercept) \n##    1.819283\n# Summary of the fit\nbroom::tidy(fit)## # A tibble: 2 × 5\n##   term        estimate std.error statistic       p.value\n##   <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n## 1 (Intercept)    1.82     0.0753      24.2 0.00000000919\n## 2 x              0.210    0.0121      17.3 0.000000127\nsummary(fit)$coefficients##              Estimate Std. Error  t value     Pr(>|t|)\n## (Intercept) 1.8192834 0.07530712 24.15819 9.192109e-09\n## x           0.2099929 0.01213684 17.30210 1.268192e-07\nsummary(fit)$coefficients[\"x\", \"Std. Error\"]## [1] 0.01213684\nsummary(fit)$r.squared## [1] 0.9739721\n# Get the fitted paramters and make a string with it to be printed\nto_print <- paste(\"y = \", round(coef(fit)[1],2),\" + x*\",\n                    round(coef(fit)[2],2), sep=\"\")\n# Base plot\nplot(d, pch = 16, main = \"With base plot\", sub = to_print)\nabline(coef(fit), col=\"red\")\n# GGplot versions\nggplot(data=d, aes(x,y)) + \n    geom_point(cex=3) +\n    geom_abline(slope = coef(fit)[2], intercept = coef(fit)[1], col=\"red\") +\n    labs(title = \"With ggplot and the parameters you get from the external call to lm()\",\n         subtitle = to_print)\nggplot(data=d, aes(x,y)) + \n    geom_point(cex=3) +\n    geom_smooth(method=\"lm\") + # does the fit but does not allow saving the parameters\n    labs(title = \"With ggplot and the geom_smooth() function\",\n         subtitle = to_print)\nfit0 <- lm(data = d, y ~ x + 0) # intercept will be fixed in 0\nfit1.5 <- lm(data = d, y - 1.5 ~ x + 0) # intercept will be fixed in 1.5\nd %>% ggplot(aes(x,y)) + \n    geom_point(cex=3) +\n    geom_abline(slope = coef(fit0)[1], intercept = 0, col=\"red\")+\n    geom_abline(slope = coef(fit1.5)[1], intercept = 1.5, col=\"royalblue\")+\n    expand_limits(x = 0, y = 0)"},{"path":"fitting.html","id":"nonlinear-least-squares-fitting","chapter":"13 Fitting","heading":"13.2 Nonlinear Least Squares fitting","text":"","code":""},{"path":"fitting.html","id":"the-nls-workhorse","chapter":"13 Fitting","heading":"13.2.1 The nls() workhorse","text":"can fit data functions constraints using nls(). Example data may want fit, stored tibble called df:first need define function fit data. see contains two peaks look Gaussian, let’s go sum two Gaussian functions:plot data result fit, use predict(fit) retrieve fitted y values:","code":"\ndf## # A tibble: 121 × 2\n##        x        y\n##    <dbl>    <dbl>\n##  1  -5   -0.0295 \n##  2  -4.9 -0.0252 \n##  3  -4.8  0.00365\n##  4  -4.7 -0.0407 \n##  5  -4.6  0.00857\n##  6  -4.5 -0.0310 \n##  7  -4.4  0.0116 \n##  8  -4.3 -0.0414 \n##  9  -4.2 -0.0395 \n## 10  -4.1  0.0454 \n## # … with 111 more rows\nggplot(data=df, aes(x,y))+\n    geom_point()+\n    ggtitle(\"Some fake data we want to fit with 2 Gaussians\")\n# Create a function to fit the data\nmyfunc <- function(x, y0, x1, x2, A1, A2, sd1, sd2) {\n    y0 + A1 * dnorm(x, mean=x1, sd = sd1) + A2 * dnorm(x, mean = x2, sd = sd2)\n}\n# Fit the data using a user function\nfit_nls <- nls(data=df,\n               y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2),\n               start=list(y0=0, x1=0, x2=1.5, sd1=.2, sd2=.2, A1=1, A2=1) # provide starting point\n               )\nsummary(fit_nls)## \n## Formula: y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2)\n## \n## Parameters:\n##      Estimate Std. Error t value Pr(>|t|)    \n## y0  -0.006957   0.003562  -1.953   0.0533 .  \n## x1  -0.010613   0.011893  -0.892   0.3740    \n## x2   2.015637   0.039536  50.983   <2e-16 ***\n## sd1  0.499322   0.011562  43.187   <2e-16 ***\n## sd2  1.007636   0.041787  24.114   <2e-16 ***\n## A1   0.987647   0.030939  31.922   <2e-16 ***\n## A2   1.033973   0.040559  25.493   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.02802 on 114 degrees of freedom\n## \n## Number of iterations to convergence: 9 \n## Achieved convergence tolerance: 1.02e-06\n# With base R\nplot(x, y, pch=16)\nlines(x, predict(fit_nls), col=\"red\", lwd=2)\n# With ggplot2\nggplot(data=df, aes(x,y))+\n    geom_point(size=2, alpha=.5) +\n    geom_line(aes(y = predict(fit_nls)), color=\"red\", size=1)"},{"path":"fitting.html","id":"using-constraints","chapter":"13 Fitting","heading":"13.2.2 Using constraints","text":"nls() even possible constraint fitting adding lower upper boundaries. boundaries useful want give physical meaning parameters, example, like forcing width amplitude positive certain minimum value. However, careful provide stupid ones, e.g.:","code":"\n# Constraining the upper and lower values of the fitting parameters\nfit_constr <- nls(data = df,\n                  y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2),\n                  start = list(y0=0, x1=0, x2=3, sd1=.2, sd2=.2, A1=1, A2=1),\n                  upper = list(y0=Inf, x1=Inf, x2=Inf, sd1=Inf, sd2=Inf, A1=2, A2=2),\n                  lower = list(y0=-Inf, x1=-Inf, x2=2.9, sd1=0, sd2=0, A1=0, A2=0),\n                  algorithm = \"port\"\n                 )\n# Plotting the resulting function in blue\nggplot(data=df, aes(x,y))+\n    ggtitle(\"Beware of bad constraints!\")+\n    geom_point(size=2, alpha=.5) +\n    geom_line(aes(y = predict(fit_constr)), color=\"royalblue\", size=1)"},{"path":"fitting.html","id":"a-more-robust-version-of-nls","chapter":"13 Fitting","heading":"13.2.3 A more robust version of nls","text":"Sometimes, nls() struggle converge towards solution, especially provide initial guesses far expected values.case, may want use robust nls() function nlsLM() minpack.lm package.Also, nlsLM() won’t fail fit exact, whereas nls() :","code":"\nfit3 <- nls(data = df,\n            y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2),\n            start = list(y0 = 0, x1 = 1, x2 = 5, sd1 = .2, sd2 = .2, A1 = 10, A2 = 10)\n            )## Error in nls(data = df, y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2), start = list(y0 = 0, : singular gradient\nlibrary(minpack.lm)\nfit_nlsLM <- nlsLM(data = df,\n                   y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2),\n                   start = list(y0 = 0, x1 = 1, x2 = 5, sd1 = .2, sd2 = .2, A1 = 10, A2 = 10)\n                   )\nsummary(fit_nls);## \n## Formula: y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2)\n## \n## Parameters:\n##      Estimate Std. Error t value Pr(>|t|)    \n## y0  -0.006957   0.003562  -1.953   0.0533 .  \n## x1  -0.010613   0.011893  -0.892   0.3740    \n## x2   2.015637   0.039536  50.983   <2e-16 ***\n## sd1  0.499322   0.011562  43.187   <2e-16 ***\n## sd2  1.007636   0.041787  24.114   <2e-16 ***\n## A1   0.987647   0.030939  31.922   <2e-16 ***\n## A2   1.033973   0.040559  25.493   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.02802 on 114 degrees of freedom\n## \n## Number of iterations to convergence: 9 \n## Achieved convergence tolerance: 1.02e-06\nsummary(fit_nlsLM);## \n## Formula: y ~ myfunc(x, y0, x1, x2, A1, A2, sd1, sd2)\n## \n## Parameters:\n##      Estimate Std. Error t value Pr(>|t|)    \n## y0  -0.006957   0.003562  -1.953   0.0533 .  \n## x1  -0.010613   0.011893  -0.892   0.3741    \n## x2   2.015639   0.039536  50.983   <2e-16 ***\n## sd1  0.499323   0.011562  43.187   <2e-16 ***\n## sd2  1.007634   0.041787  24.114   <2e-16 ***\n## A1   0.987649   0.030939  31.923   <2e-16 ***\n## A2   1.033971   0.040559  25.493   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.02802 on 114 degrees of freedom\n## \n## Number of iterations to convergence: 15 \n## Achieved convergence tolerance: 1.49e-08\ntestdf <- tibble(x = seq(-10,10),\n                 y = dnorm(x))\nnls(data = testdf,\n    y ~ A*dnorm(x, sd=B, mean=x0) + y0,\n    start = list(y0=0, x0=0, A=1, B=1)\n    )## Error in nls(data = testdf, y ~ A * dnorm(x, sd = B, mean = x0) + y0, : number of iterations exceeded maximum of 50\nnlsLM(data = testdf,\n    y ~ A*dnorm(x, sd=B, mean=x0) + y0,\n    start = list(y0=0, x0=0, A=1, B=1)\n    )## Nonlinear regression model\n##   model: y ~ A * dnorm(x, sd = B, mean = x0) + y0\n##    data: testdf\n## y0 x0  A  B \n##  0  0  1  1 \n##  residual sum-of-squares: 0\n## \n## Number of iterations to convergence: 1 \n## Achieved convergence tolerance: 1.49e-08"},{"path":"fitting.html","id":"the-broom-library","chapter":"13 Fitting","heading":"13.3 The broom library","text":"Thanks broom library, easy retrieve fit parameters tibble:easy make recursive fit data without using loop, like :case want provide fit parameters vary depending group looking , use notation .$column_name, like done .can see results data :","code":"\nlibrary(broom)\n# Get all parameters and their error\ntidy(fit_nls)## # A tibble: 7 × 5\n##   term  estimate std.error statistic  p.value\n##   <chr>    <dbl>     <dbl>     <dbl>    <dbl>\n## 1 y0    -0.00696   0.00356    -1.95  5.33e- 2\n## 2 x1    -0.0106    0.0119     -0.892 3.74e- 1\n## 3 x2     2.02      0.0395     51.0   2.61e-80\n## 4 sd1    0.499     0.0116     43.2   1.70e-72\n## 5 sd2    1.01      0.0418     24.1   1.40e-46\n## 6 A1     0.988     0.0309     31.9   1.11e-58\n## 7 A2     1.03      0.0406     25.5   6.57e-49\n# Get the fitted curve and residuals next to the original data\naugment(fit_nls)## # A tibble: 121 × 4\n##        x        y  .fitted  .resid\n##    <dbl>    <dbl>    <dbl>   <dbl>\n##  1  -5   -0.0295  -0.00696 -0.0225\n##  2  -4.9 -0.0252  -0.00696 -0.0183\n##  3  -4.8  0.00365 -0.00696  0.0106\n##  4  -4.7 -0.0407  -0.00696 -0.0338\n##  5  -4.6  0.00857 -0.00696  0.0155\n##  6  -4.5 -0.0310  -0.00696 -0.0241\n##  7  -4.4  0.0116  -0.00696  0.0185\n##  8  -4.3 -0.0414  -0.00696 -0.0344\n##  9  -4.2 -0.0395  -0.00696 -0.0326\n## 10  -4.1  0.0454  -0.00696  0.0523\n## # … with 111 more rows\nlibrary(broom)\nlibrary(tidyverse)\nlibrary(ggplot2)\ntheme_set(theme_bw())\n# Create fake data\na <- seq(-10,10,.1)\ncenters <- c(-2*pi,pi,pi/6)\nwidths  <- runif(3, min=0.5, max=1)\namp     <- runif(3, min=2, max=10)\nnoise   <- .3*runif(length(a))-.15\nd <- tibble(x=rep(a,3),\n            y=c(amp[1]*dnorm(a,mean=centers[1],sd=widths[1]) + sample(noise),\n                amp[2]*dnorm(a,mean=centers[2],sd=widths[2]) + sample(noise),\n                amp[3]*dnorm(a,mean=centers[3],sd=widths[3]) + sample(noise)),\n            T=rep(1:3, each=length(a))\n            )\n# Plot the data\nd %>% ggplot(aes(x=x, y=y, color=factor(T))) + \n    geom_line()\n# Fit all data\nd_fitted <- d %>% \n    nest(data = -T) %>%\n    mutate(fit = purrr::map(data, ~ nls(data = .,\n                                y ~ y0 + A*dnorm(x, mean=x0, sd=FW), \n                                start=list(A  = max(.$y),\n                                           y0 = .01, \n                                           x0 = .$x[which.max(.$y)], \n                                           FW = .7)\n                                )),\n           tidied = purrr::map(fit, tidy),\n           augmented = purrr::map(fit, augment)\n          )\nd_fitted## # A tibble: 3 × 5\n##       T data               fit    tidied           augmented         \n##   <int> <list>             <list> <list>           <list>            \n## 1     1 <tibble [201 × 2]> <nls>  <tibble [4 × 5]> <tibble [201 × 4]>\n## 2     2 <tibble [201 × 2]> <nls>  <tibble [4 × 5]> <tibble [201 × 4]>\n## 3     3 <tibble [201 × 2]> <nls>  <tibble [4 × 5]> <tibble [201 × 4]>\n# data and fit resulting curve\nd_fitted %>% \n  unnest(augmented)## # A tibble: 603 × 8\n##        T data               fit    tidied       x       y .fitted  .resid\n##    <int> <list>             <list> <list>   <dbl>   <dbl>   <dbl>   <dbl>\n##  1     1 <tibble [201 × 2]> <nls>  <tibble> -10    0.104  0.00182  0.102 \n##  2     1 <tibble [201 × 2]> <nls>  <tibble>  -9.9 -0.0644 0.00182 -0.0662\n##  3     1 <tibble [201 × 2]> <nls>  <tibble>  -9.8 -0.137  0.00182 -0.138 \n##  4     1 <tibble [201 × 2]> <nls>  <tibble>  -9.7  0.0274 0.00182  0.0256\n##  5     1 <tibble [201 × 2]> <nls>  <tibble>  -9.6  0.149  0.00182  0.148 \n##  6     1 <tibble [201 × 2]> <nls>  <tibble>  -9.5 -0.0357 0.00183 -0.0375\n##  7     1 <tibble [201 × 2]> <nls>  <tibble>  -9.4 -0.124  0.00183 -0.125 \n##  8     1 <tibble [201 × 2]> <nls>  <tibble>  -9.3 -0.0262 0.00184 -0.0280\n##  9     1 <tibble [201 × 2]> <nls>  <tibble>  -9.2 -0.0562 0.00186 -0.0580\n## 10     1 <tibble [201 × 2]> <nls>  <tibble>  -9.1  0.100  0.00190  0.0981\n## # … with 593 more rows\n# fit parameters\nd_fitted %>% \n  unnest(tidied)## # A tibble: 12 × 9\n##        T data     fit    term   estimate std.error statistic   p.value augmented\n##    <int> <list>   <list> <chr>     <dbl>     <dbl>     <dbl>     <dbl> <list>   \n##  1     1 <tibble> <nls>  A      5.31       0.0544     97.6   9.06e-169 <tibble> \n##  2     1 <tibble> <nls>  y0     0.00182    0.00673     0.271 7.87e-  1 <tibble> \n##  3     1 <tibble> <nls>  x0    -6.27       0.00662  -947.    0         <tibble> \n##  4     1 <tibble> <nls>  FW     0.611      0.00683    89.5   1.66e-161 <tibble> \n##  5     2 <tibble> <nls>  A      6.32       0.0746     84.7   6.39e-157 <tibble> \n##  6     2 <tibble> <nls>  y0     0.000841   0.00723     0.116 9.08e-  1 <tibble> \n##  7     2 <tibble> <nls>  x0     3.15       0.0117    270.    4.47e-255 <tibble> \n##  8     2 <tibble> <nls>  FW     0.996      0.0123     80.8   5.42e-153 <tibble> \n##  9     3 <tibble> <nls>  A      7.48       0.0723    103.    1.23e-173 <tibble> \n## 10     3 <tibble> <nls>  y0     0.00162    0.00717     0.226 8.21e-  1 <tibble> \n## 11     3 <tibble> <nls>  x0     0.532      0.00919    57.9   1.27e-125 <tibble> \n## 12     3 <tibble> <nls>  FW     0.952      0.00969    98.2   2.82e-169 <tibble>\n# fit parameters as a wide table\nd_fitted %>% \n  unnest(tidied) %>% \n  select(T, term, estimate, std.error) %>% \n  pivot_wider(names_from = term, \n              values_from = c(estimate,std.error))## # A tibble: 3 × 9\n##       T estimate_A estimate_y0 estimate_x0 estimate_FW std.error_A std.error_y0\n##   <int>      <dbl>       <dbl>       <dbl>       <dbl>       <dbl>        <dbl>\n## 1     1       5.31    0.00182       -6.27        0.611      0.0544      0.00673\n## 2     2       6.32    0.000841       3.15        0.996      0.0746      0.00723\n## 3     3       7.48    0.00162        0.532       0.952      0.0723      0.00717\n## # … with 2 more variables: std.error_x0 <dbl>, std.error_FW <dbl>\n# plot fit result\nd_fitted %>% \n    unnest(augmented) %>% \n    ggplot(aes(x=x, color=factor(T)))+\n        geom_point(aes(y=y), alpha=0.5, size=3) + \n        geom_line(aes(y=.fitted))\n# plot fit parameters\nd_fitted %>% \n  unnest(tidied) %>% \n  ggplot(aes(x=T, y=estimate, color=term))+\n    geom_point()+\n    geom_errorbar(aes(ymin=estimate-std.error,\n                      ymax=estimate+std.error),\n                  width=.1)+\n    facet_wrap(~term, scales=\"free_y\")+\n    theme(legend.position = \"none\")"},{"path":"fitting.html","id":"exo-fits","chapter":"13 Fitting","heading":"13.4 Exercises","text":"Interactive exercises can found tutor package. , simply run:Load exo_fit.txt tibble.Using lm() nls() fit column function x display “experimental” data fit graph.\nTip: Take look function dnorm() define Gaussian\nTip: Take look function dnorm() define GaussianLoad tidyverse library.Define function norm01(x), , given vector x, returns vector normalized [0,1].Load Raman spectrum rubis_01.txt, normalize [0,1] plot itDefine normalized Lorentzian function Lorentzian(x, x0, FWHM), defined \\(L(x, x_0, FWHM)=\\frac{FWHM}{2\\pi}\\frac{1}{(FWHM/2)^2 + (x-x_0)^2}\\)Guess grossly initial parameters plot resulting curve blue dashed lineFit data sum 2 Lorentzians using nls()Add result plot red lineAdd 2 Lorentzian components area-filled curves alpha=0.2 two different colorsCreate Exercise_fit folder, create Rstudio project linked folderDownload corresponding data files unzip folder called Data.Create new .R file write code save .Like previous exercise, fit ruby Raman spectra, many files . First, using list.files(), save flist list ruby files Data folder.Define Lorentzian(x, x0, FWHM) functionDefine norm01(x) function returning vector x normalized [0,1]Create read_ruby(filename) function , given file name filename, reads file tibble, gives proper column names, normalizes intensity [0,1], returns tibble.Create fitfunc(tib) function , given tibble tib, fits tibble’s y values function x values using sum two Lorentzians, returns nls() fit result. Make sure provide “clever” starting parameters, especially positions two peaks. example, one peak spectrum maximum , one always energy roughly 30 cm-1 lower.Using pipe operations purrr::map(), recursively:\nCreate tibble one column called file, contains list file names flist.\nCreate column data containing list read files, obtained mapping read_ruby() onto flist.\nCreate column fit containing list nls() objects, obtained mapping fitfunc() onto list (column) data\nCreate column tidied containing list tidied nls() tibbles, obtained mapping bbroom::tidy() onto list (column) fit\nCreate column augmented containing list augmented nls() tibbles, obtained mapping bbroom::augment() onto list (column) fit\nTurn file column run contain run number (.e. number file name) numeric value. Use function separate() .\nCreate tibble one column called file, contains list file names flist.Create column data containing list read files, obtained mapping read_ruby() onto flist.Create column fit containing list nls() objects, obtained mapping fitfunc() onto list (column) dataCreate column tidied containing list tidied nls() tibbles, obtained mapping bbroom::tidy() onto list (column) fitCreate column augmented containing list augmented nls() tibbles, obtained mapping bbroom::augment() onto list (column) fitTurn file column run contain run number (.e. number file name) numeric value. Use function separate() .Plot experimental data fit black points red lines faceted plot. Play various ways plotting , like ridge slider plot.Plot evolution fitting parameters function run number.Plot evolution position higher energy peak function file name.Fit linearly evolution higher intensity peaks respect run number. Display fitted parameters R2. Plot fit red line. Make sure use proper weighing fit.","code":"\nlibrary(tutor)\ntuto(\"fits\")\n# Load the `tidyverse` library.\nlibrary(tidyverse)\n# Define a function `norm01(x)`, that, given a vector `x`, returns this vector normalized to [0,1].\nnorm01 <- function(x) {(x-min(x))/(max(x)-min(x))}\n# Load rubis_1.txt, normalize it to [0,1] and plot it\nd <- read_table(\"Data/rubis_01.txt\", col_names=c(\"w\", \"Int\")) %>% \n    mutate(Int_n = norm01(Int))\nP <- d %>%\n    ggplot(aes(x=w, y=Int_n))+\n        geom_point(alpha=0.5)\nP\n# Define the Lorentzian function\nLorentzian <- function(x, x0=0, FWHM=1){\n    FWHM / (2*pi) / ((FWHM/2)^2 + (x - x0)^2)\n}\n# Guess grossly the initial parameters and plot the resulting curve as a blue dashed line\nP+geom_line(aes(y = 0.03 + \n                    3*Lorentzian(w, x0=3160, FWHM=10) +\n                    7*Lorentzian(w, x0=3210, FWHM=10)),\n            col=\"blue\", lty=2)\n# Fit the data by a sum of 2 Lorentzians using `nls`\nfit <- nls(data=d, \n           Int_n ~ y0 + A1*Lorentzian(w,x1,FWHM1) + A2*Lorentzian(w,x2,FWHM2), \n           start=list(y0=0.03,\n                      x1=3160, FWHM1=10, A1=3,\n                      x2=3200, FWHM2=10, A2=7))\nsummary(fit)## \n## Formula: Int_n ~ y0 + A1 * Lorentzian(w, x1, FWHM1) + A2 * Lorentzian(w, \n##     x2, FWHM2)\n## \n## Parameters:\n##        Estimate Std. Error   t value Pr(>|t|)    \n## y0    9.825e-03  6.165e-04     15.94   <2e-16 ***\n## x1    3.173e+03  3.503e-02  90576.82   <2e-16 ***\n## FWHM1 1.076e+01  1.087e-01     98.96   <2e-16 ***\n## A1    1.039e+01  8.028e-02    129.38   <2e-16 ***\n## x2    3.203e+03  2.709e-02 118214.68   <2e-16 ***\n## FWHM2 1.453e+01  8.600e-02    169.00   <2e-16 ***\n## A2    2.112e+01  9.680e-02    218.19   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.01568 on 1008 degrees of freedom\n## \n## Number of iterations to convergence: 10 \n## Achieved convergence tolerance: 7.651e-06\n# Add the result on the plot as a red line\nP + geom_line(aes(y=.03 + \n                    3*Lorentzian(w, x0=3160, FWHM=10) +\n                    7*Lorentzian(w, x0=3210, FWHM=10)),\n            col=\"blue\", lty=2)+\n    geom_line(aes(y=predict(fit)), col=\"red\")\n# Add the 2 Lorentzian components as area-filled curves with `alpha=0.2` and two different colors\ny0  <- coef(fit)['y0']\nA1  <- coef(fit)['A1'];   A2   <- coef(fit)['A2']\nx1  <- coef(fit)['x1'];   x2   <- coef(fit)['x2']\nFW1 <- coef(fit)['FWHM1']; FW2 <- coef(fit)['FWHM2']\nP + geom_line(aes(y=.03 + \n                    3*Lorentzian(w, x0=3160, FWHM=10) +\n                    7*Lorentzian(w, x0=3210, FWHM=10)),\n            col=\"blue\", lty=2)+\n    geom_line(aes(y = predict(fit)), col=\"red\")+\n    geom_area(aes(y = A1*Lorentzian(w, x0=x1, FWHM=FW1)), \n                fill=\"royalblue\", alpha=.2)+\n    geom_area(aes(y = A2*Lorentzian(w, x0=x2, FWHM=FW2)), \n                fill=\"orange\", alpha=.2)\n# - Using `list.files()`, save in `flist` the list of ruby files in the `Data` folder.\nflist <- list.files(path = \"Data\", pattern = \"rubis\", full.names = TRUE)\n# - Define the `Lorentzian(x, x0, FWHM)` function\nLorentzian <- function(x, x0 = 0, FWHM = 1) {\n    2 / (pi * FWHM) / (1 + ((x - x0) / (FWHM / 2))^2)\n}\n# - Define the `norm01(x)` function returning the vector x normalized to [0,1]\nnorm01 <- function(x) {\n    (x - min(x)) / (max(x) - min(x))\n}\n# - Create a `read_ruby(filename)` function that, given a file name `filename`, \n# reads the file into a tibble, gives the proper column names, normalizes the \n# intensity to [0,1], and returns the tibble.\nread_ruby <- function(filename){\n    read_table(filename, col_names = c(\"w\", \"Int\")) %>% \n        mutate(Int = norm01(Int))\n}\n# - Create a `fitfunc(tib)` function that, given a tibble `tib`, fits this \n# tibble's *y* values as a function of the *x* values using the sum of two Lorentzians, \n# and returns the `nls()` fit result. Make sure to provide \"clever\" starting parameters, \n# especially for the positions of the two peaks. For example, one peak is where \n# the spectrum maximum is, and the other one is always at an energy roughly 30 cm^-1^ lower.\nfitfunc <- function(tib){\n    nls(data=tib,\n        Int ~ y0 + A1*Lorentzian(w,x1,FWHM1)+\n                   A2*Lorentzian(w,x2,FWHM2), \n           start=list(y0=0.03,\n                      x1=tib$w[which.max(tib$Int)] - 30, \n                      FWHM1=10, \n                      A1=max(tib$Int)*10,\n                      x2=tib$w[which.max(tib$Int)], \n                      FWHM2=10, \n                      A2=max(tib$Int)*10)\n        )\n}\n# Test it:\n# df <- read_ruby(flist[1])\n# fitfunc(df)\n# \n# - Using pipe operations and `purrr::map()`, recursively:\n#     - Create a tibble with only one column called `file`, which contains the \n#       list of file names `flist`.\n#     - Create a column `data` containing a list of all read files, \n#       obtained by mapping `read_ruby()` onto `flist`.\n#     - Create a column `fit` containing a list of `nls()` objects, \n#       obtained by mapping `fitfunc()` onto the list (column) `data`\n#     - Create a column `tidied` containing a list of tidied `nls()` tibbles, \n#       obtained by mapping `bbroom::tidy()` onto the list (column) `fit`\n#     - Create a column `augmented` containing a list of augmented `nls()` tibbles, \n#       obtained by mapping `bbroom::augment()` onto the list (column) `fit`\n#     - Turn the `file` column into `run` that will contain the run number \n#       (*i.e.* the number in the file name) as a numeric value. \n#       Use the function `separate()`{.R} to do so.\ndata <- tibble(file=flist) %>% \n    mutate(data = map(file, read_ruby),\n           fit = map(data, fitfunc),\n           tidied = map(fit, tidy),\n           augmented = map(fit, augment)\n           ) %>% \n    separate(file, c(NA, NA, \"run\", NA), convert = TRUE)\n# - Plot all the experimental data and the fit with black points and red lines \n# into a faceted plot. Play with various ways of plotting this, \n# like a ridge or slider plot.\ndata %>% \n    unnest(augmented) %>% \n    ggplot(aes(x = w, y = Int)) +\n       geom_point(alpha=0.5)+\n       geom_line(aes(y=.fitted), col=\"red\")+\n       facet_wrap(~run)\ndata %>% \n    unnest(augmented) %>% \n    ggplot(aes(x = w, y = Int + as.numeric(factor(run)), group=run)) +\n       geom_point(alpha=0.5)+\n       geom_line(aes(y = .fitted + as.numeric(factor(run))), col = \"red\")\nP <- data %>%\n    unnest(augmented) %>%\n    ggplot(aes(x = w, y = Int, frame=run)) +\n        geom_point(alpha = 0.5) +\n        geom_line(aes(y = .fitted), col = \"red\")\nlibrary(plotly)\nggplotly(P, dynamicTicks = TRUE) %>% \n    animation_opts(5)%>%\n    layout(xaxis = list(autorange=FALSE, range = c(3050, 3550)))\n# - Plot the evolution of all fitting parameters as a function of the run number.\ndata %>%\n    unnest(tidied) %>% \n    ggplot(aes(x = run, y = estimate)) +\n        geom_point()+\n        facet_wrap(~term, scales = \"free\")+\n        geom_errorbar(aes(ymin = estimate - std.error,\n                          ymax = estimate + std.error),\n                      width=0.5)\n# - Plot the evolution of the position of the higher intensity peaks.\ndata %>%\n    unnest(tidied) %>% \n    filter(term == \"x1\") %>% \n    ggplot(aes(x = run, y = estimate)) +\n        geom_point()+\n        geom_errorbar(aes(ymin = estimate - std.error,\n                          ymax = estimate + std.error),\n                      width=0.5)\n# - Fit linearly the evolution of the higher intensity peaks with respect to the \n#   run number. Display the fitted parameters and R^2^.Plot the fit as a red line. \n#   Make sure to use proper weighing for the fit.\nlmfit <- data %>%\n    unnest(tidied) %>%\n    filter(term == \"x1\") %>% \n    lm(data=., \n       estimate ~ run, \n       weights = 1/std.error^2)\ntidy(lmfit)## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  3169.      0.557     5686.  6.39e-49\n## 2 run             6.99    0.0756      92.6 4.23e-22\nglance(lmfit)## # A tibble: 1 × 12\n##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1     0.998         0.998  57.6     8566. 4.23e-22     1  -36.0  78.1  80.6\n## # … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\ndata %>%\n    unnest(tidied) %>% \n    filter(term == \"x1\") %>% \n    ggplot(aes(x = run, y = estimate)) +\n        geom_point()+\n        geom_errorbar(aes(ymin = estimate - std.error,\n                          ymax = estimate + std.error),\n                      width=0.5)+\n        geom_line(aes(y = predict(lmfit)), col=\"red\")"},{"path":"writing-documents-with-rmarkdown.html","id":"writing-documents-with-rmarkdown","chapter":"14 Writing documents with Rmarkdown","heading":"14 Writing documents with Rmarkdown","text":"","code":""},{"path":"writing-documents-with-rmarkdown.html","id":"what-is-markdown","chapter":"14 Writing documents with Rmarkdown","heading":"14.1 What is markdown?","text":"Markdown simplified language can used produce variety rich documents: single .md file can compiled outputted .docx, .odt, .html, .rtf, .pdf .tex. output format well various options (font size, template, table contents, numbered sections…) specified YAML header, .e. text two lines like --- (’ll see example later).markdown can embedded \\(\\LaTeX\\) code displaying math expressions, html tags complicated html stuff, rest formatting given easy commands:can also add -line code writing text back-ticks:render : Text -line codeFor commands, can example get digested cheat-sheet tutorial .","code":"# Title\n## sub-title\n### sub-sub-title\n...\n###### sub_6-title\n**bold**\n*italic*\n[link](http://google.com/)\n![image caption](image.png)\n\nTable:\n|   |   |\n|---|---|\n|   |   |\n\nUnordered list:\n- bla\n- bla bla\n\nOrdered list:\n1. bla\n1. bla bla\n\nLaTeX code: $\\int_{-\\infty}^{\\infty} e^{-x^2}=\\sqrt{\\pi}$\n\nHTML code: <a href=\"some_link\">text<\/a>Text with `in-line code`"},{"path":"writing-documents-with-rmarkdown.html","id":"and-rmarkdown","chapter":"14 Writing documents with Rmarkdown","heading":"14.2 … and Rmarkdown?","text":"Rmarkdown basically thing markdown (extension: .Rmd instead .md), difference code chunks specify language accolades computed result displayed.-line code can computed rendered:render : -line code 3.webpage fully written Rmarkdown (see “View book source” bottom left sidebar).Rmarkdown supports number languages:python R code chunks can communicate thanks reticulate package.… starting see power tool…?Basically, can use best language task combine single Rmd file display text images computed compilation Rmd file: can fully automatize data treatment reporting.Example:chunk 1: bash, call program creates fileschunk 2: python, call program big computation fileschunk 3: R, data treatment, plot data","code":"```r\n# Not computed\n1+1\n``````{r}\n# Computed\n1+1\n```## [1] 2In-line code `r 1+2`\nnames(knitr::knit_engines$get())##  [1] \"awk\"         \"bash\"        \"coffee\"      \"gawk\"        \"groovy\"     \n##  [6] \"haskell\"     \"lein\"        \"mysql\"       \"node\"        \"octave\"     \n## [11] \"perl\"        \"psql\"        \"Rscript\"     \"ruby\"        \"sas\"        \n## [16] \"scala\"       \"sed\"         \"sh\"          \"stata\"       \"zsh\"        \n## [21] \"asis\"        \"asy\"         \"block\"       \"block2\"      \"bslib\"      \n## [26] \"c\"           \"cat\"         \"cc\"          \"comment\"     \"css\"        \n## [31] \"dot\"         \"embed\"       \"fortran\"     \"fortran95\"   \"go\"         \n## [36] \"highlight\"   \"js\"          \"julia\"       \"python\"      \"R\"          \n## [41] \"Rcpp\"        \"sass\"        \"scss\"        \"sql\"         \"stan\"       \n## [46] \"targets\"     \"tikz\"        \"verbatim\"    \"theorem\"     \"lemma\"      \n## [51] \"corollary\"   \"proposition\" \"conjecture\"  \"definition\"  \"example\"    \n## [56] \"exercise\"    \"hypothesis\"  \"proof\"       \"remark\"      \"solution\"   \n## [61] \"glue\"        \"glue_sql\"    \"gluesql\""},{"path":"writing-documents-with-rmarkdown.html","id":"further-reading-2","chapter":"14 Writing documents with Rmarkdown","heading":"14.3 Further reading","text":"see Rmarkdown combining languages single document:code chunkslanguagesRmarkdown cheatsheetRmarkdown cookbook","code":""},{"path":"writing-documents-with-rmarkdown.html","id":"example-Rmd","chapter":"14 Writing documents with Rmarkdown","heading":"14.4 Example","text":"Download biblio.bib nature.csl put root project.Create example.Rmd file following YAML header (indentation important):understand header:---: surrounds YAML header. body comes .title, author date: easy. date can automatically set current one setting :output: tells pandoc output format want. compiling, case multiple entries, compiler look first one. Click links see options.\ncase, output html document floating table contents, unnumbered sections code chunks hidden button allow showing .\noutput formats allowed:\nword_document\npdf_document\nrtf_document\nbeamer_presentation\n…\n\nUseful options:\nWord document: can supply reference style (template) use. Just write dummy .docx file edit style, save word-template.docx (example), set option reference_docx: word-template.docx.\nLaTeX: keep_tex: pandoc compiles markdown file PDF, goes intermediate step creating .tex file. can decide keep tweaking style PDF output, like normally .tex file.\nfig_caption: allows figure caption.\ntoc: creates table contents.\nnumber_sections: allows section numbering.\nhighlight: syntax highlighting theme code chunks.\n\ncase, output html document floating table contents, unnumbered sections code chunks hidden button allow showing .output formats allowed:\nword_document\npdf_document\nrtf_document\nbeamer_presentation\n…\nword_documentpdf_documentrtf_documentbeamer_presentation…Useful options:\nWord document: can supply reference style (template) use. Just write dummy .docx file edit style, save word-template.docx (example), set option reference_docx: word-template.docx.\nLaTeX: keep_tex: pandoc compiles markdown file PDF, goes intermediate step creating .tex file. can decide keep tweaking style PDF output, like normally .tex file.\nfig_caption: allows figure caption.\ntoc: creates table contents.\nnumber_sections: allows section numbering.\nhighlight: syntax highlighting theme code chunks.\nWord document: can supply reference style (template) use. Just write dummy .docx file edit style, save word-template.docx (example), set option reference_docx: word-template.docx.LaTeX: keep_tex: pandoc compiles markdown file PDF, goes intermediate step creating .tex file. can decide keep tweaking style PDF output, like normally .tex file.fig_caption: allows figure caption.toc: creates table contents.number_sections: allows section numbering.highlight: syntax highlighting theme code chunks.bibliography: path .bib file. create bibliography, add # References header end document.csl: path bibliography style output – example, nature.csl. Find style edit .many options, ’ll fulfill needs.Now can start adding content, like:Note choose output html format, can’t use PDF images: use .svg (pdf2svg) non vectorial images.’s nice html output, ’s can include interactive figures plotly like saw previous sections. course, won’t work static documents like PDF Word…cross referencing figures tables, use output: bookdown::html_document2 instead output: html_document (requires package bookdown), see details.","code":"---\ntitle  : Your Title\nauthor : John Doe\ndate   : `r format(Sys.time(), '%d/%m/%Y')`\noutput :\n    html_document:\n        toc            : true\n        toc_float      : true\n        highlight      : tango\n        number_sections: false\n        code_folding   : hide    \nbibliography: \"biblio.bib\"\ncsl         : \"nature.csl\"\n---`r format(Sys.time(), '%d/%m/%Y')`---\ntitle: \"The title\"\noutput: \n    bookdown::html_document2: #instead of html_document, for referencing images\n        toc            : true\n        toc_float      : true\n        highlight      : tango\n        number_sections: true\n        code_folding   : show\n        code_download  : true\n    # bookdown::pdf_document2 #instead of pdf_document, for referencing images\nbibliography: \"biblio.bib\"\ncsl         : \"nature.csl\"\n---\n\n# First section\n## First subsection\nI am writing _italic_ and __bold__ stuff.\n\n- This is an item\n- Another one with citations [@bevan_statistical_2013;@rcoreteam_language_2017]\n\n# Second section\n## First subsection that I want to refer to {#subsectionID}\n\nThis is a text with a footnote[^1].\n\nNow I can refer to my subsection using `\\@ref(subsectionID)` like so:\nsection \\@ref(subsectionID).\n\nThis is an image with a caption:\n\n```{r CHUNKname, echo=FALSE, fig.cap=\"This is a very nice caption\", out.width=\"50%\", fig.align='center'}\nknitr::include_graphics(\"https://cdn.foliovision.com/images/2017/03/i-love-markdown.png\")\n```\n\nAnd I can refer to this figure using `\\@ref(fig:CHUNKname)`. \nExample : Figure \\@ref(fig:CHUNKname).\n\nHere is a code chunk in R in Fig. \\@ref(fig:Rfigure):\n```{r Rfigure, fig.cap=\"Test figure in R\", fig.align='center'}\nx <- seq(0,10,.1)\nplot(x, sin(x), main=\"R plot\")\n```\n\nAnd one in python in Fig. \\@ref(fig:Pythonfigure):\n```{python Pythonfigure, fig.cap=\"Test figure in python\", fig.align='center'}\n# Load some libraries\nimport numpy as np\n# Matplotlib non interactive plots\nimport matplotlib.pyplot as plt\nN = 100\nx = np.linspace(0,10,N)\nplt.plot(x, np.sin(x))\nplt.title(\"Matplotlib Plot\")\nplt.ylabel(\"Y values\")\nplt.xlabel(\"X values\")\nplt.show()\n```\n\n# References\n\n[^1]: This is a footnote."},{"path":"writing-documents-with-rmarkdown.html","id":"code-chunks-options","chapter":"14 Writing documents with Rmarkdown","heading":"14.5 Code chunks options","text":"can add options code chunk, like:echo=FALSE: hide code, show outputinclude=FALSE: hide code outputwarnings=FALSE: hide warning messageserror=TRUE: compute code chunk despite errorscache=TRUE: cache result chunk faster re-compilationfig.asp: figure aspect ratiofig.caption: figure caption…","code":""},{"path":"writing-documents-with-rmarkdown.html","id":"compilation","chapter":"14 Writing documents with Rmarkdown","heading":"14.6 Compilation","text":"knit Rmd file desired output, Rstudio, click little triangle next “Knit” button, like :corresponding output file created folder.","code":""},{"path":"writing-documents-with-rmarkdown.html","id":"going-further-parameters","chapter":"14 Writing documents with Rmarkdown","heading":"14.7 Going further: parameters","text":"can even provide list parameters Rmarkdown file can retrieve code chunks params$param_name. information , short example: try compiling directly using “Knit” button, try compiling using “Knit parameters”. Alternatively, can popup interactive window rendering command rmarkdown::render(\"MyDocument.Rmd\", params = \"ask\").“Knit parameters” launches Shiny user interface allowing interactively choosing parameters. options listed .","code":"---\ntitle: \"Test\"\noutput: html_document\nparams:\n  city:\n    label: \"City:\"\n    value: Angers\n    input: select\n    multiple: TRUE\n    choices: [Angers, Paris, Montpellier, Nantes, Marseille]\n  printcode:\n    label: \"Display Code\"\n    value: TRUE\n  data:\n    label: \"Input dataset:\"\n    value: \"Data/population.txt\"\n    input: file\n---\n\n```{r, setup, include=FALSE}\n# set this option in the first code chunk in the document\nknitr::opts_chunk$set(echo = params$printcode)\n```\n\nPlotting `r paste(params$data)`:\n\n```{r, message=FALSE}\nlibrary(ggplot2)\nlibrary(plotly)\ndf <- read.table(params$data, header=TRUE)\np <- ggplot(data=subset(df, city %in% params$city), \n            aes(x=year, y=pop, size=pop, color=city)) +\n        geom_point() + \n        geom_smooth(method=\"lm\", aes(fill=city), alpha=0.1, show.legend = FALSE) + \n        ggtitle(paste(\"Population in \",paste(params$city, collapse=\", \"),sep=\"\"))+\n        labs(x=\"Year\", y=\"Population\")+\n        theme_light()\nggplotly(p)\n```"},{"path":"writing-documents-with-rmarkdown.html","id":"and-what-about-jupyter-notebooks","chapter":"14 Writing documents with Rmarkdown","heading":"14.8 And what about JuPyteR notebooks?","text":"JuPyteR notebooks basically web-based interactive version Rmarkdown documents working Julia, Python R.installation tad complicated non initiate, , well, just like Rmarkdown less easy use share, opinion. mostly work python, get used since Rmarkdown better suited R.","code":""},{"path":"writing-documents-with-rmarkdown.html","id":"further-readings-and-ressources","chapter":"14 Writing documents with Rmarkdown","heading":"14.9 Further readings and ressources","text":"numerous ressources help Rmarkdown journey.Rmarkdown website gallery: help chose formats templates, example codesThe Rmarkdown cookbook: just go question Rmarkdown.Rmarkdown definitive guide: just go question Rmarkdown.flexdashboard: package make dashboardsrticles: package collection pdf templates scientific articlesrmdformats: package collection html templatesstevetemplates: collection pdf templates Steve MillerRexams: help define exams included solutionThesisdown: package write thesis RmarkdownI also provide collection examples github repo class:\n- HTML outputs:\n- Simple page\n- Dashboard\n- Gitbook\n- BS4 book (like class)\n- Book\n- ioslide\n- PDF outputs:\n- Document template\n- Beamer presentation\n- Book\n- Exercises hidden solution\n- Microsoft Office outputs:\n- PowerPoint\n- Word (template)","code":""},{"path":"writing-documents-with-rmarkdown.html","id":"exo-rmd","chapter":"14 Writing documents with Rmarkdown","heading":"14.10 Exercise","text":"Create new R Markdown file (.Rmd) RStudio.Insert YAML Header title, author date choice top .Rmd script. Make output html document.Display summary “cars” dataset report.Make plot “cars” dataset summary just created.Create small experimental dataframe display report.Hide code last code chunk (HINT: Use echo.)Hide code code chunks possibility show (HINT: use code_folding).Load package “knitr” .Rmd file. hide code chunk. HINT: Use include.Hide warning message appeared report. HINT: Use warning.Set fig.width fig.height plot 5.Output report pdf.Create html experimental logbook data treatment example previous section.Create html experimental logbook data treatment example previous section single experimental file provide parameter YAML header. file path must given interactive file input selection.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"graphical-interfaces-with-shiny","chapter":"15 Graphical interfaces with Shiny","heading":"15 Graphical interfaces with Shiny","text":"preview shiny interface previous section interactive parameter input Rmarkdown file.Using shiny package, can actually easily build interactive graphical user interface (GUI) able set parameters (values, files…), visualize outputs (plots, images, tables…), write files output. useful always repeat task varying input parameter, example.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"stand-alone-shiny-application","chapter":"15 Graphical interfaces with Shiny","heading":"15.1 Stand-alone shiny application","text":"shiny application app.R file (must named like ) containing 3 elements:ui: definition interface layout (buttons, text input, plot output, etc.) input parametersserver: definition various actions perform input parametersshinyApp(ui, server): launches shiny app defined parametersIn Rstudio, create new “Shiny web app”. create app.R file containing :Run clicking “Run App”: window opens can pan slider see resulting output.case want clean code, can separate app.R ui.R server.R. need add shinyApp(ui = ui, server = server) line case.user-defined functions variable definitions can defined global.R file sourced default launching app.","code":"\nlibrary(shiny)\n# Define UI for application that draws a histogram\nui <- fluidPage(\n    # Application title\n    titlePanel(\"Old Faithful Geyser Data\"),\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"bins\",\n                        \"Number of bins:\",\n                        min = 1,\n                        max = 50,\n                        value = 30)\n        ),\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"distPlot\")\n        )\n    )\n)\n# Define server logic required to draw a histogram\nserver <- function(input, output, session) {\n    output$distPlot <- renderPlot({\n        # generate bins based on input$bins from ui.R\n        x    <- faithful[, 2]\n        bins <- seq(min(x), max(x), length.out = input$bins + 1)\n\n        # draw the histogram with the specified number of bins\n        hist(x, breaks = bins, col = 'darkgray', border = 'white')\n    })\n}\n# Run the application \nshinyApp(ui = ui, server = server)"},{"path":"graphical-interfaces-with-shiny.html","id":"the-layout","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.1 The layout","text":"ui <- fluidPage(...) item, define layout application. example:titlePanel(\"Title\") creates titlesidebarLayout() separates layout short one left (sidebarPanel()) main one right (mainPanel())sliderInput(\"name_of_slider\", \"text display\", min=min_value, max=max_value, value=current_value, step=step_value) creates slider input value. value retrieved input$name_of_slider server() function.plotOutput(\"name_of_plot\") plots result output$name_of_plot defined server() function.See guide application layout layout options. also recommend taking look packages shinydashboard shinymaterial.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"the-server","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.2 The server","text":"server <- function(input, output){...} function, define various actions outputs reaction input change.example, define output$distPlot renderPlot() function whose results depends input$bins. plot rendered ui plotOutput(\"distPlot\").","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"various-useful-functions","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3 Various useful functions","text":"Input\nButtons\nCheckbox\nText/numeric\nSlider\nFile\nDropdown menu\nButtonsCheckboxText/numericSliderFileDropdown menuOutput\nDisplay plot\nDisplay text\nDisplay table\nReactive events\nWriting file\nDisplay plotDisplay textDisplay tableReactive eventsWriting file","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"input","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1 Input","text":"","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"buttons","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1.1 Buttons","text":"","code":"\n# # # # # # # # # \n# In ui:\nactionButton(\"button_name\", \"Text to display\")\n# # # # # # # # # \n# In server:\nobserveEvent(input$button_name, {\n    # do something\n})\n# or\nsome_function <- eventReactive(input$button_name, {\n                               # do something\n                               })"},{"path":"graphical-interfaces-with-shiny.html","id":"checkbox","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1.2 Checkbox","text":"","code":"\n# # # # # # # # # \n# In ui:\ncheckboxInput(\"checkbox_name\", \"Text to display\", value=FALSE)\n# # # # # # # # # \n# In server:\ninput$checkbox_name #TRUE or FALSE"},{"path":"graphical-interfaces-with-shiny.html","id":"textnumeric","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1.3 Text/numeric","text":"","code":"\n# # # # # # # # # \n# In ui:\ntextInput(\"text_name\", \n            label = \"Text to display\", \n            value = \"initial value\", \n            width = '100%')\n\ntextAreaInput(\"text_name\", \n            label=\"Text to display\", \n            value = \"initial_value\", \n            rows = 5) %>%\n            shiny::tagAppendAttributes(style = 'width: 100%;')\n\nnumericInput(\"value_name\", 'Text to display', value=0)\n# # # # # # # # # \n# In server, retrieve it as:\ninput$text_name\ninput$value_name"},{"path":"graphical-interfaces-with-shiny.html","id":"slider","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1.4 Slider","text":"","code":"\n# # # # # # # # # \n# In ui:\nsliderInput(\"slider_name\", \"Text to display\",\n            min = 1,\n            max = 50,\n            step= 1,\n            value = 30)\n# # # # # # # # # \n# In server, retrieve it as:\ninput$slider_name"},{"path":"graphical-interfaces-with-shiny.html","id":"file","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1.5 File","text":"","code":"\n# # # # # # # # # \n# In ui:\nfileInput(\"file_in\", \n          \"Choose input file:\", accept = c(\".txt\") \n          )\n# # # # # # # # # \n# In server, retrieve it as:\ninput$file_in$datapath\n# For example, read it as a data.frame with myData():\nmyData <- reactive({\n        inFile <- input$file_in\n        if (is.null(inFile)) {\n            return(NULL)\n        } else {\n            return(read.table(inFile$datapath, header=TRUE))\n        }\n    })"},{"path":"graphical-interfaces-with-shiny.html","id":"dropdown-menu","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.1.6 Dropdown menu","text":"","code":"\n# # # # # # # # # \n# In ui:\nselectInput(\"menu_name\", \"Text to display\", \n            choices=c(\"choice 1\", \"choice 2\"), \n            multiple = FALSE # multiple selection possible\n            )\n# # # # # # # # # \n# In server, retrieve it as:\ninput$menu_name"},{"path":"graphical-interfaces-with-shiny.html","id":"output","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.2 Output","text":"","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"display-a-plot","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.2.1 Display a plot","text":"want interactive plot, use plotlyOutput() renderPlotly() instead.","code":"\n# # # # # # # # # \n# In ui:\nplotOutput(\"plot_name\", height = 600,\n           click = \"plot_click\", # to retrieve the click position\n           dblclick = \"plot_dblclick\", # to retrieve the double click position\n           hover = \"plot_hover\", # to retrieve the mouse position\n           brush = \"plot_brush\" # to retrieve the rectangle coordinates\n           )\n# # # # # # # # # \n# In server:\noutput$plot_name <- renderPlot({\n        # do plot:\n        plot(...)\n        # or\n        ggplot(...)\n    })"},{"path":"graphical-interfaces-with-shiny.html","id":"display-text","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.2.2 Display text","text":"","code":"\n# # # # # # # # # \n# In ui:\ntextOutput(\"text_to_display\")\n# Verbatim text (fixed width characters):\nverbatimTextOutput(\"text_to_display\")\n# # # # # # # # # \n# In server:\noutput$text_to_display <- renderText({ \"some text\" })\noutput$text_to_display <- renderPrint({ \"some text\" })"},{"path":"graphical-interfaces-with-shiny.html","id":"display-a-table","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.2.3 Display a table","text":"case want interactive tables, use package datatable:","code":"\n# # # # # # # # # \n# In ui:\ntableOutput(\"table_to_display\")\n# # # # # # # # # \n# In server:\noutput$table_to_display <- renderTable({ df })\nlibrary(DT)\n# # # # # # # # # \n# In ui:\ndataTableOutput(\"table_to_display\")\n# # # # # # # # # \n# In server:\noutput$table_to_display <- renderDataTable({ df })"},{"path":"graphical-interfaces-with-shiny.html","id":"reactive-events","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.2.4 Reactive events","text":"case want plots text display react change input value, can wrap corresponding code reactive() function server side:various input default values can updated using following functions server side:","code":"# # # # # # # # # \n# In ui:\nfileInput(\"file_in\", \n          \"Choose input file:\", accept = c(\".txt\") \n          ),\ncheckboxInput(\"header\", \"Header?\", value=TRUE),\nselectInput(\"menu\", \"Columns to display\", \n            choices=1, selected = 1, multiple = TRUE),\ntableOutput(\"table\")\n# # # # # # # # # \n# In server:\nmyData <- reactive({\n        inFile <- input$file_in\n        if (is.null(inFile)) {\n            return(NULL)\n        } else {\n            df <- read.table(inFile$datapath, header=input$header)\n            updateSelectInput(session, \"menu\", choices=1:ncol(df), selected=input$menu)\n            return(df)\n        }\n    })\noutput$table <- renderTable( myData()[,sort(as.numeric(input$menu))] )\n# Dropdown menu\nupdateSelectInput(session, \"menu_name\", choices=new_choices)\n# Text\nupdateTextInput(session, \"text_name\", value = new_value)\n# Numeric\nupdateNumericInput(session, \"value_name\", value = new_value)"},{"path":"graphical-interfaces-with-shiny.html","id":"writing-a-file","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.3.2.5 Writing a file","text":"function shiny, may want write text file. comes data.frame, can use function write.table():forms printing, look write() function:can example write Rmd file render (pdf, etc…) using render():","code":"\ndf <- data.frame(x=1:10,y=sin(1:10))\nwrite.table(df, \"test.dat\", quote=FALSE, row.names=FALSE)\ntoprint <- paste(\"hello\", \"world\")\noutfile <- file(\"file_name.txt\", encoding=\"UTF-8\")\nwrite(toprint, file=outfile)\nclose(outfile)\nrmarkdown::render(\"file_name.Rmd\")"},{"path":"graphical-interfaces-with-shiny.html","id":"example-shiny","chapter":"15 Graphical interfaces with Shiny","heading":"15.1.4 Example","text":"Create new shiny app following code, play around . input file tidy population.txt.render like .","code":"\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(DT)\n\nui <- fluidPage(\n    titlePanel(\"City population in France\"),\n    sidebarLayout(\n        sidebarPanel(\n            fileInput(\"file_in\", \"Choose input file:\",\n                      accept = c(\".txt\") ),\n            selectInput(\"sel_city\", \"City:\", choices = \"\", multiple = TRUE)\n        ),\n        mainPanel(\n            tabsetPanel(\n                tabPanel(\"Plot\", plotlyOutput(\"cityplot\", height = \"400px\")),\n                tabPanel(\"Table\", dataTableOutput(\"table\"))\n            )\n        )\n    )\n)\n\nserver <- function(input, output, session) {\n\n    # myData() returns the data if a file is provided\n    myData <- reactive({\n        inFile <- input$file_in\n        if (is.null(inFile)) {\n            return(NULL)\n        } else {\n            df <- read.table(inFile$datapath, header=TRUE)\n            # in case something changes,\n            # update the city input selection list\n            updateSelectInput(session, \"sel_city\",\n                              choices = unique(df$city),\n                              selected = unique(df$city)[1])\n            return(df)\n        }\n    })\n\n    # plot the pop vs year for the selected cities\n    output$cityplot <- renderPlotly({\n        df <- myData()\n        if(is.null(df)) return(NULL)\n        p <- df %>% \n            filter(city %in% input$sel_city) %>%\n            ggplot(aes(x=year, y=pop, size=pop, color=city)) +\n                geom_point() +\n                geom_smooth(method=\"lm\", alpha=0.1,\n                            show.legend = FALSE,\n                            aes(fill=city)) +\n                ggtitle(paste0(\"Population in \",\n                               paste(input$sel_city, collapse = \", \")\n                               ))+\n                labs(x=\"Year\", y=\"Population\")+\n                theme_light()\n        ggplotly(p, dynamicTicks = TRUE)\n    })\n\n    # show data as a table\n    output$table <- renderDataTable({\n        df <- myData() %>% filter(city %in% input$sel_city)\n        if(is.null(df)) return(NULL)\n        df <- pivot_wider(df, names_from=year, values_from=pop)\n        datatable(df, rownames = FALSE)\n    })\n\n}\n\nshinyApp(ui = ui, server = server)"},{"path":"graphical-interfaces-with-shiny.html","id":"rmarkdown-embedded-shiny-application","chapter":"15 Graphical interfaces with Shiny","heading":"15.2 Rmarkdown-embedded shiny application","text":"shiny application can even embedded inside Rmarkdown document providing runtime: shiny YAML header. short example , try compile :“problem” solution html file produced run shiny app , open Rmd file Rstudio hit “Run Document”.Another solution consists deploying app shinyapps.io embedding page document :","code":"---\ntitle: \"Test\"\noutput: html_document\nruntime: shiny\n---\n\nThis is a test Rmarkdown document.\n\n```{r, echo=FALSE, message=FALSE}\nlibrary(ggplot2)\nlibrary(plotly)\ndf <- read.table(\"Data/population.txt\", header=TRUE)\n\n\nshinyApp(\n  ui = fluidPage(\n    selectInput(\"city\", \"City:\", choices = unique(df$city)),\n    plotlyOutput(\"cityplot\", height = 600)\n  ),\n\n  server = function(input, output) {\n    output$cityplot = renderPlotly({\n      p <- ggplot(data=subset(df,city==input$city), \n                aes(x=year, y=pop, size=pop)) +\n            geom_point() + \n            geom_smooth(method=\"lm\", alpha=0.1, show.legend = FALSE) + \n            ggtitle(paste(\"Population in \",input$city,sep=\"\"))+\n            labs(x=\"Year\", y=\"Population\")+\n            theme_light()\n      ggplotly(p)\n    })\n  }\n)\n``````{r, echo=FALSE}\nknitr::include_app(\"https://cbousige.shinyapps.io/shiny_example/\", \n                    height = \"800px\")\n```"},{"path":"graphical-interfaces-with-shiny.html","id":"deploying-your-shiny-app","chapter":"15 Graphical interfaces with Shiny","heading":"15.3 Deploying your shiny app","text":"4 ways deploy app: passing app.R file users, deploying shinyapps.io, deploying server, building executable Electron.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"passing-the-app.r-file-to-your-users","chapter":"15 Graphical interfaces with Shiny","heading":"15.3.1 Passing the app.R file to your users","text":"option certainly easy: just send app.R file (Rmd file shiny embedded app) well files needed (e.g. global.R) users, explain run , voilà.However, needs little bit know-users: need install R Rstudio, install needed packages, run app.good option remove “package-installing” step define function check.package() check package installed, install needed, load :","code":"\ncheck.packages <- function(pkg){\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg)) \n        install.packages(new.pkg, dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n# Usage:\ncheck.packages(\"ggplot2\")"},{"path":"graphical-interfaces-with-shiny.html","id":"deploying-to-shinyapps.io","chapter":"15 Graphical interfaces with Shiny","heading":"15.3.2 Deploying to shinyapps.io","text":"Applications deployed shinyapps.io accessible anywhere weblink. See example application determine pressure ruby Raman spectrum expected Raman shift given pressure laser wavelength. application however public limitations number online applications time use (don’t pay fee, see various plans).First, create account shinyapps.ioFollow steps described :\nConfigure RSconnect: shinyapps.io dashboard, click name, Tokens, create token new app. Copy text popup window.\nDeploy app Rstudio window clicking “Publish” button top right corner interface. Follow steps along shinyapps.io way.\nConfigure RSconnect: shinyapps.io dashboard, click name, Tokens, create token new app. Copy text popup window.Deploy app Rstudio window clicking “Publish” button top right corner interface. Follow steps along shinyapps.io way.Note case, install.package() command code. packages supported shinyapps.io.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"deploying-on-your-own-linux-server","chapter":"15 Graphical interfaces with Shiny","heading":"15.3.3 Deploying on your own Linux server","text":"option advanced ’m going details , number tutorials online. See e.g. , .might consider option work company want handle privately data (sounds plausible) pay shinyapps.io fee password protect app. case, just work department get running.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"building-an-executable","chapter":"15 Graphical interfaces with Shiny","heading":"15.3.4 Building an executable","text":"Windows, possibility looks nice never tried don’t Windows: RInno.platform: possibility described corresponding github page. option actually awesome quite recent possibility. However, since produced application contain R needed packages, executable file quite heavy.","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"further-reading-3","chapter":"15 Graphical interfaces with Shiny","heading":"15.4 Further reading","text":"Shiny cheatsheetHelp deploying shiny appGuide application layoutThe Shiny Gallery: find want adapt needsThe official Shiny video tutorial","code":""},{"path":"graphical-interfaces-with-shiny.html","id":"exo-shiny","chapter":"15 Graphical interfaces with Shiny","heading":"15.5 Exercises","text":"Create new empty app blank user-interface run .Add title, left panel main panelAdd input numerical value defaulting 1 step 0.05, name “bw”Add slider input 0 1e3 steps 1e2 defaulting 5e2, name “N_val”Add plot density rnorm(N_val) bandwidth bwMake sure bw>0, otherwise don’t produce plotCreate shiny application :read input (file dialog) Raman spectrum ruby (XPdata.zip)fit data two Lorentziansplot data interactivelyask laser wavelength input give 568.189 nm defaultwrite corresponding pressure page using Pruby() function defined myfunc.R found XPdata.zip.insert button , pressed, render pdf report displaying laser wavelength, plot, fit pressure found:\nwrite separate Rmd file proper parameters\nrender Rmd file pdf (see render() function help)\nwrite separate Rmd file proper parametersrender Rmd file pdf (see render() function help)","code":"\nlibrary(shiny)\n\nui <- fluidPage(\n    titlePanel(\"Some title\"),\n    sidebarLayout(\n        sidebarPanel(\n            numericInput(\"bw\", \"Enter bandwidth:\", 1, step=0.05),\n            sliderInput(\"N_val\", \"Number of points:\", \n                        min = 0, max = 1e4, step= 1e2, value = 5e2)\n        ),\n        mainPanel(\n            plotOutput(\"plot\", height = 600)\n        )\n    )\n)\n\nserver <- function(input, output, session) {\n    output$plot <- renderPlot({\n                        if(input$bw==0) return(NULL)\n                        plot(density(rnorm(input$N_val), bw=abs(input$bw)))\n                    })\n}\n\nshinyApp(ui = ui, server = server)"},{"path":"working-with-units-and-experimental-errors.html","id":"working-with-units-and-experimental-errors","chapter":"16 Working with units and experimental errors","heading":"16 Working with units and experimental errors","text":"","code":""},{"path":"working-with-units-and-experimental-errors.html","id":"working-with-units","chapter":"16 Working with units and experimental errors","heading":"16.1 Working with units","text":"easy work units R thanks package units (see vignette).Working units package can prove good idea avoid conversion errors data treatment…gist :possible, automatic units conversion performed. Also, possible attribute units columns tibbles data.frames:can moreover convert units systems using set_units(vector, \"unit\") units(vector) <- \"unit\":Sometimes, may define unit outside set_units() call want retrieve , use unit another variable new variable. , use mode=\"standard\" option:can give units table columns:can plot using units easily convert units plotting:","code":"\n# Load the 'units' library\nlibrary(units)\nt <- seq(0.1,1,length=3)\n# attribute a unit, here 'seconds':\nt <- set_units(t, \"s\") \nt## Units: [s]\n## [1] 0.10 0.55 1.00\nd1    <- set_units(seq(1,2,length=3), \"m\")\n(tib1 <- tibble(t=t, d=d1, speed=d1/t))## # A tibble: 3 × 3\n##      t   d speed\n##    [s] [m] [m/s]\n## 1 0.1  1   10   \n## 2 0.55 1.5  2.73\n## 3 1    2    2\nd2    <- set_units(seq(0.1, .3, length=3), \"cm\")\n(tib2 <- tibble(t=t, d=d2, speed=d2/t))## # A tibble: 3 × 3\n##      t    d  speed\n##    [s] [cm] [cm/s]\n## 1 0.1   0.1  1    \n## 2 0.55  0.2  0.364\n## 3 1     0.3  0.3\nbind_rows(tib1,tib2)## # A tibble: 6 × 3\n##      t     d    speed\n##    [s]   [m]    [m/s]\n## 1 0.1  1     10      \n## 2 0.55 1.5    2.73   \n## 3 1    2      2      \n## 4 0.1  0.001  0.01   \n## 5 0.55 0.002  0.00364\n## 6 1    0.003  0.003\nT <- set_units(1, \"fs\")\nset_units(1/T, \"THz\")## 1000 [THz]\nunits(T) <- \"ns\"; T## 1e-06 [ns]\nUNIT <- \"m\"\nset_units(1:10, UNIT)## Error: In 'UNIT', 'UNIT' is not recognized by udunits.\n## \n## See a table of valid unit symbols and names with valid_udunits().\n## Custom user-defined units can be added with install_unit().\n## \n## See a table of valid unit prefixes with valid_udunits_prefixes().\n## Prefixes will automatically work with any user-defined unit.\nset_units(1:10, UNIT, mode=\"standard\")## Units: [m]\n##  [1]  1  2  3  4  5  6  7  8  9 10\nset_units(1:10, units(T), mode=\"standard\")## Units: [ns]\n##  [1]  1  2  3  4  5  6  7  8  9 10\nlibrary(tidyverse)\nstarwars## # A tibble: 87 × 14\n##    name     height  mass hair_color skin_color eye_color birth_year sex   gender\n##    <chr>     <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n##  1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n##  2 C-3PO       167    75 <NA>       gold       yellow         112   none  mascu…\n##  3 R2-D2        96    32 <NA>       white, bl… red             33   none  mascu…\n##  4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n##  5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n##  6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n##  7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n##  8 R5-D4        97    32 <NA>       white, red red             NA   none  mascu…\n##  9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n## 10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n## # … with 77 more rows, and 5 more variables: homeworld <chr>, species <chr>,\n## #   films <list>, vehicles <list>, starships <list>\nstarwars %>% \n    mutate(height = set_units(height,\"cm\"),\n           mass   = set_units(mass,\"kg\"))## # A tibble: 87 × 14\n##    name     height mass hair_color  skin_color eye_color birth_year sex   gender\n##    <chr>      [cm] [kg] <chr>       <chr>      <chr>          <dbl> <chr> <chr> \n##  1 Luke Sk…    172   77 blond       fair       blue            19   male  mascu…\n##  2 C-3PO       167   75 <NA>        gold       yellow         112   none  mascu…\n##  3 R2-D2        96   32 <NA>        white, bl… red             33   none  mascu…\n##  4 Darth V…    202  136 none        white      yellow          41.9 male  mascu…\n##  5 Leia Or…    150   49 brown       light      brown           19   fema… femin…\n##  6 Owen La…    178  120 brown, grey light      blue            52   male  mascu…\n##  7 Beru Wh…    165   75 brown       light      blue            47   fema… femin…\n##  8 R5-D4        97   32 <NA>        white, red red             NA   none  mascu…\n##  9 Biggs D…    183   84 black       light      brown           24   male  mascu…\n## 10 Obi-Wan…    182   77 auburn, wh… fair       blue-gray       57   male  mascu…\n## # … with 77 more rows, and 5 more variables: homeworld <chr>, species <chr>,\n## #   films <list>, vehicles <list>, starships <list>\np <- starwars %>% \n    mutate(height = set_units(height,\"cm\"),\n           mass   = set_units(mass,\"kg\")) %>% \n    filter(sex != \"hermaphroditic\") %>%\n    ggplot(aes(x=height, y=mass, color=sex))+\n        geom_point(size=2)+\n        labs(x=\"Height\", y=\"Mass\")\np\np + ggforce::scale_x_unit(unit = \"inches\") +\n    ggforce::scale_y_unit(unit = \"pounds\")"},{"path":"working-with-units-and-experimental-errors.html","id":"working-with-experimental-errors","chapter":"16 Working with units and experimental errors","heading":"16.2 Working with experimental errors","text":"working experimental science, account measurement errors error propagation along data treatment.\nmade really easy thanks quantities package gathers error units packages. importantly, allows propagating errors proper way. , input experimental error , don’t think anymore. Neat, isn’t ?gist :thus becomes easy plot error bars experimental data. recommend using ggforce library make ggplot2 work better quantities:","code":"\nlibrary(quantities)\noptions(errors.notation=\"plus-minus\", errors.digits=4)\na <- set_errors(1, 0.1)\nb <- set_errors(2, 0.2)\na+b## 3.0000 ± 0.2236\na*b## 2.0000 ± 0.2828\na^3## 1.0000 ± 0.3000\nerrors(a)## [1] 0.1\nerrors_min(a)## [1] 0.9\nerrors_max(a)## [1] 1.1\nlibrary(ggforce)\noptions(errors.notation=\"parenthesis\", errors.digits=1)\nstarwars %>% \n    mutate(height=set_quantities(height,\"cm\",height*.05),\n           mass=set_quantities(mass,\"kg\",mass*.05)\n           )## # A tibble: 87 × 14\n##    name         height     mass hair_color skin_color eye_color birth_year sex  \n##    <chr>      (err) [… (err) [… <chr>      <chr>      <chr>          <dbl> <chr>\n##  1 Luke Skyw…   172(9)    77(4) blond      fair       blue            19   male \n##  2 C-3PO        167(8)    75(4) <NA>       gold       yellow         112   none \n##  3 R2-D2         96(5)    32(2) <NA>       white, bl… red             33   none \n##  4 Darth Vad…  200(10)   136(7) none       white      yellow          41.9 male \n##  5 Leia Orga…   150(8)    49(2) brown      light      brown           19   fema…\n##  6 Owen Lars    178(9)   120(6) brown, gr… light      blue            52   male \n##  7 Beru Whit…   165(8)    75(4) brown      light      blue            47   fema…\n##  8 R5-D4         97(5)    32(2) <NA>       white, red red             NA   none \n##  9 Biggs Dar…   183(9)    84(4) black      light      brown           24   male \n## 10 Obi-Wan K…   182(9)    77(4) auburn, w… fair       blue-gray       57   male \n## # … with 77 more rows, and 6 more variables: gender <chr>, homeworld <chr>,\n## #   species <chr>, films <list>, vehicles <list>, starships <list>\nstarwars %>% \n    mutate(height=set_quantities(height,\"cm\",height*.05),\n           mass=set_quantities(mass,\"kg\",mass*.05)\n           ) %>% \n    filter(sex!=\"hermaphroditic\") %>% \n    ggplot(aes(x=height, y=mass, color=sex))+\n        geom_point(size=2)+\n        labs(x=\"Height\", y=\"Mass\")+\n        geom_errorbar(aes(ymin=errors_min(mass),\n                          ymax=errors_max(mass)))+\n        geom_errorbarh(aes(xmin=errors_min(height),\n                           xmax=errors_max(height)))"},{"path":"list-of-exercises.html","id":"list-of-exercises","chapter":"17 List of exercises","heading":"17 List of exercises","text":"solutions available correction done class.","code":""}]
