---
title : "R Exercises"
date  : "`r Sys.Date()`"
output: 
    html_document:
        toc            : true
        toc_float      : true
        toc_depth      : 4
        highlight      : tango
        number_sections: true
        code_download  : TRUE
params: 
    solution:
        value: FALSE
---

The COVID-19 pandemics is a lot of bad things, but it's also a source of data to play with...

Here we're gonna use the data gathered by the John's Hopkins Hospital and published on [GitHub](https://github.com/CSSEGISandData/COVID-19), for [confirmed cases](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv) and [deaths](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv).

In case the links above die at some point, here is a version of these files as of April 21st, 2020:

- [confirmed cases](Data/time_series_covid19_confirmed_global.csv)
- [deaths](Data/time_series_covid19_deaths_global.csv)

In fact, a [quick lookup](https://www.statsandr.com/blog/top-r-resources-on-covid-19-coronavirus/#r-shiny-apps) on the Internet will now return plenty of versions for this data, with even cleaner (tidy) versions, including country population, etc. There are even R packages to get this.
The point here is to learn how to read a given dataset, clean it and use it, so we'll stay with the JHU dataset.


# Data wrangling

- First, load the `tidyverse` and `lubridate` packages
- Load the raw .csv files from the links above and store them in `confirmed_raw` and `deaths_raw`. You can provide `read_csv()` with an url.
- Using successive operations with the pipe operator `%>%` create a function `tidyfy_jhh(df, name)`, that, given a data.frame `df` (_i.e._, the data from JHH we just loaded), will:
    + Rename the columns `Province/State` and `Country/Region` to `state` and `country`
    + remove the lines from the `Diamond Princess`
    + remove the columns from `state`, `Lat` and `Long`
    + remove any duplicated lines
    + make the table tidy by having 3 columns : `country`, `date` and `count`
    + using the `mdy()` function from the `lubridate` package, convert the `date` column to a R Date format
    + summarize the counts per country and per date as the total number of cases per country and per day. Give this column the name of the type of case we look at (confirmed or deaths)
- Apply this function to the raw tibbles to get tidy `confirmed` and `deaths` tibbles.
- Join these three tibbles in `alldata`, and successively:
    - filter rows to remove data for which the number of cases is lower than the minimum number of cases in China (for easier comparison)
    - filter rows to have only countries for which we have at least one week of data
    - mutate the `date` column to get it as a number of day

```{r include=params$solution, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
library(tidyverse)
library(lubridate)
# Load the raw csv files from the links above and store them in `confirmed_raw` and `deaths_raw`.
# urlConfirmed <- "Data/time_series_covid19_confirmed_global.csv"
# urlDeaths <- "Data/time_series_covid19_deaths_global.csv"
urlConfirmed <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
urlDeaths <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
confirmed_raw  <- read_csv(urlConfirmed)
deaths_raw     <- read_csv(urlDeaths)
# Using successive operations with the pipe operator `%>%`
# create a function `tidyfy_jhh(df, name)`, that, given a
# data.frame df (i.e., the data from JHH we just loaded), will:
# + Rename the columns `Province/State` and 
#   `Country/Region` to `state` and `country`
# + remove the lines from the `Diamond Princess`
# + remove the columns from `state`, `Lat` and `Long`
# + remove any duplicated lines
# + make the table tidy by having 3 columns : `country`, 
#   `date` and `count`
# + using the `mdy()` function from the `lubridate` 
#   package, convert the `date` column to a R Date format
# + summarize the counts per country and per date as the
#   total number of cases per country and per day. 
#   Give this column the name of the type of case 
#   we look at (confirmed or deaths)
tidyfy_jhh <- function(df, name) {
    df %>% 
        rename(state=`Province/State`,
             country=`Country/Region`) %>%
        filter(country != "Diamond Princess") %>%
        select(-c(state,Lat,Long)) %>%
        distinct() %>% 
        pivot_longer(cols=-country,
                     names_to="date",
                     values_to='count') %>% 
        mutate(date = mdy(date)) %>% 
        group_by(country, date) %>% 
        summarize(!!sym(name):=sum(count)) %>% 
        ungroup()
}
# Apply this function to `xx_raw` to get tidy
# `confirmed` and `deaths` tibbles.
confirmed <- tidyfy_jhh(confirmed_raw, 'confirmed')
deaths    <- tidyfy_jhh(deaths_raw, 'deaths')
# Join these three tibbles, and successively:
# - add a column `sick` containing the count of people
#   still sick.
# - filter rows to remove data for which the number of 
#   cases is lower than the minimum number of cases in
#   China (for easier comparison)
# - filter rows to have only countries for which we have
#   at least one week of data
# - mutate the `date` column to get it as a number of day
MIN <- min(confirmed$confirmed[confirmed$country == "China"])
alldata <- confirmed %>% 
            full_join(deaths) %>% 
            group_by(country) %>% 
            filter(confirmed>=MIN) %>% 
            filter(n() >= 7) %>% 
            mutate(date=1:n()) %>% 
            ungroup()
```

# Plotting

- Using `ggplot2`, plot (P1) side by side the number of confirmed cases and deaths vs time in China, Italy, France, Spain and the US.
    - Using `ggrepel`, add the country names as annotation
    - Use a log scale
- Plot (P2) the death ratio per country (averaged over time)
    + is there anything wrong?
- To better see the effect of confinement regulation, it's probably more interesting to plot the number of new confirmed cases. Plot as a barplot the number of new confirmed cases per day for 2 countries of your choice, and add a vertical line corresponding to the date of application of confinement rules.

```{r include=params$solution, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
# Plot side by side the number of confirmed cases and deaths 
# vs time in China, Italy, France, Spain and the US.
# Using `ggrepel`, add the country names as annotation
library(ggplot2)
library(ggrepel)

countries <- c("China","Italy","France","Spain","US")
colors <- c("black","red","seagreen","orange","royalblue")

labs <- alldata %>% 
            filter(country %in% countries) %>%
            group_by(country) %>% 
            filter(date==max(date)) %>% 
            ungroup()

P1a <- alldata %>% 
    filter(country %in% countries) %>%
    ggplot(aes(x=date, y=confirmed, color=country))+
        geom_line(size=1)+
        scale_color_manual(values=colors, name="")+
        xlab("Days")+
        ylab("Number of Confirmed cases ")+
        theme_bw()+
        theme(legend.position = 'none')+
        ggtitle("Confirmed cases")+
        scale_y_log10(
            breaks = 10^(-seq(-5, 5, by = 1)), 
            minor_breaks = rep(1:9, 2*5+1)*(10^rep(-5:5, each=9)), 
            labels = scales::trans_format("log10", 
                scales::math_format(10^.x)))+
        annotation_logticks(sides ='lr')+
        geom_label_repel(data=labs, 
            show.legend=FALSE, 
            force=10,nudge_x=2,
            aes(x=date, y=confirmed, 
                col=country, 
                label = country))

P1b <- alldata %>% 
    filter(country %in% countries) %>%
    ggplot(aes(x=date, y=deaths, color=country))+
        geom_line(size=1)+
        scale_color_manual(values=colors, name="")+
        xlab("Days")+
        ylab("Number of Sick people ")+
        theme_bw()+
        theme(legend.position = 'none')+
        ggtitle("Deaths")+
        scale_y_log10(
            breaks = 10^(-seq(-5, 5, by = 1)), 
            minor_breaks = rep(1:9, 2*5+1)*(10^rep(-5:5, each=9)), 
            labels = scales::trans_format("log10", 
                scales::math_format(10^.x)))+
        geom_label_repel(data=labs, 
            show.legend=FALSE, 
            force=10,nudge_x=2,
            aes(x=date, y=deaths, 
                col=country, 
                label = country))
# Plot (P2) the death ratio per country (averaged over time)
# + is there anything wrong?
P2 <- alldata %>% group_by(country) %>% 
    summarize(ratio=mean(deaths/confirmed*100)) %>% 
    ggplot(aes(x=reorder(country,-ratio), y=ratio, fill=country))+
        geom_bar(stat="identity", position="dodge") +
        xlab("Country")+
        ylab("Death ratio [%]")+
        theme_bw()+
        theme(legend.position = 'none',
              axis.text.x = element_text(angle = 45, hjust=1))+
        ggtitle("Death ratio")
library(patchwork)
(P1a + P1b) / P2
```

```{r include=params$solution, warning = FALSE, message=FALSE, cache=FALSE, fig.asp=1.5}
# To better see the effect of confinement regulation, it's probably more interesting to plot the number of new confirmed cases. Plot as a barplot the number of new confirmed cases per day for 2 countries of your choice, and add a vertical line corresponding to the date of application of confinement rules.
conf_france <- as.Date("2020-03-17")
conf_italy  <- as.Date("2020-03-10")
colors <- c('royalblue','orange')
confirmed %>% 
    filter(country %in% c("France", "Italy")) %>%
    mutate(newcases=confirmed-lag(confirmed)) %>% 
    filter(newcases>0) %>% 
    filter(newcases<12000) %>% #remove outliers
    filter(date>as.Date("2020-02-25")) %>% 
    ggplot(aes(x=date, y=newcases, fill=country))+
        scale_fill_manual(values=colors, name="")+
        geom_bar(stat = 'identity', position = 'dodge', alpha=.7)+
        geom_vline(xintercept=conf_france, col=colors[1], lty=2)+
        geom_vline(xintercept=conf_italy, col=colors[2], lty=2)+
        scale_x_date(minor_breaks='1 day')+
        theme(legend.position='top')+
        xlab("Date")+
        ylab("New confirmed cases")+
        ggtitle("New confirmed cases") -> P1
deaths %>% 
    filter(country %in% c("France", "Italy")) %>%
    mutate(newcases=deaths-lag(deaths)) %>% 
    filter(newcases>0) %>% 
    filter(date>as.Date("2020-02-25")) %>% 
    ggplot(aes(x=date, y=newcases, fill=country))+
        scale_fill_manual(values=colors, name="")+
        geom_bar(stat = 'identity', position = 'dodge', alpha=.7)+
        geom_vline(xintercept=conf_france, col=colors[1], lty=2)+
        geom_vline(xintercept=conf_italy, col=colors[2], lty=2)+
        scale_x_date(minor_breaks='1 day')+
        theme(legend.position='top')+
        xlab("Date")+
        ylab("New deaths")+
        ggtitle("New deaths") -> P2
P1/P2
```

# Fitting

+ Load the library `broom` ([vignette](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)). `broom` allows tidying the output of fit functions such as `lm()` or `nls()`, taking the text output and making it into a tibble. Example:

```{r include=TRUE, warning = FALSE, message=FALSE, cache=FALSE}
library(broom)
library(tidyverse)
library(ggplot2)
theme_set(theme_bw())
# Create fake data
a <- seq(-10,10,1)
d <- tibble(x=rep(a,3),
            y=c(a*runif(1)+runif(length(a)),
                a*runif(1)+1+runif(length(a)),
                a*runif(1)+2+runif(length(a))),
            T=factor(rep(1:3,each=length(a)))
            )
# Fit the data using nls() in a do() loop
d_fit <- d %>% group_by(T) %>% 
    do(fit=nls(data=.,
               y~x*A+B, 
               start=list(A=1, B=1)))
d_fit
d_fit %>% augment(fit)
d_fit %>% tidy(fit)
d_fit %>% tidy(fit) %>% 
  select(T, term, estimate, std.error) %>% 
  pivot_wider(names_from = term, 
              values_from = c(estimate,std.error))
ggplot(data=d, aes(x=x, y=y, col=T))+
    geom_point(alpha=0.5) + 
    geom_line(data=d_fit %>% augment(fit), 
        aes(x=x,y=.fitted, col=T))
```

Here, by using `do()`, we can apply the fit to each group. The result is a tibble containing the fit result for each group. Then, using `broom`'s function `augment()` and `tidy()`, we respectively get the fitted values and residues, and the fitting parameters.

- Now then, using the same procedure as in the example above, fit the 20 first days of the pandemic by an exponential (confirmed cases), and plot the data for the countries in the first plot (all days), plus the result of the fit. Here is the expected plot: 

```{r echo=params$solution, warning = FALSE, message=FALSE, cache=FALSE}
library(broom)
fits <- alldata %>% group_by(country) %>% 
    slice(1:21) %>% 
    do(fit=nls(log(confirmed)~a*date+b, 
               data = .,
               start=list(a=1, b=1)))
# Now then, using the same procedure as in the example above, fit the 20 first days of the pandemic by an exponential (confirmed cases), and plot the data for the countries in the first plot (all days), plus the result of the fit.
toplot <- fits %>% 
            filter(country %in% countries) %>%
            augment(fit)
pars <- fits %>% tidy(fit) %>% 
  select(country, term, estimate) %>% 
  pivot_wider(names_from = term, 
              values_from = estimate)
colors <- c("black","red","seagreen","orange","royalblue")
ggplot(data=alldata %>% filter(country %in% countries),
        aes(x=date, color=country))+
    geom_point(aes(y=confirmed), alpha=.5)+
    geom_line(data=toplot, aes(y=exp(.fitted)))+
    scale_color_manual(values=colors, name="")+
    geom_label_repel(data=labs, 
            show.legend=FALSE, 
            force=10,nudge_x=2,
            aes(x=date, y=confirmed, 
                col=country, 
                label = country))+
    theme(legend.position='none')+
    xlab("Date")+
    ylab("Confirmed cases")
```

In fact, this exponential model is rather wrong... A better model of epidemics dynamics is done by the SIR model, for Susceptible, Infectious, Recovered. A description of the SIR modeling through R can be found [here](https://staff.math.su.se/hoehle/blog/2020/03/16/flatteningthecurve.html).

